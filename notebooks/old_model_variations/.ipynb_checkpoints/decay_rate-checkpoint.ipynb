{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2203c2-df40-428c-ae4c-71b20ba050c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8bf88bb8-756d-47cb-ad74-88b3b302a462",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 0.022322,
     "end_time": "2025-03-05T18:49:06.250982",
     "exception": false,
     "start_time": "2025-03-05T18:49:06.228660",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "Parameters",
     "parameters",
     "  Parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "var_list = [\"default1\", \"default2\"]\n",
    "plevel_list = [False, 300]\n",
    "aew_subset = \"default_subset\"\n",
    "model_save_name = \"default_modelbase1.keras\"\n",
    "tuner_project_name = \"default_tuner_run1\"\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b6798e3f",
   "metadata": {
    "papermill": {
     "duration": 0.012789,
     "end_time": "2025-03-05T18:49:06.269446",
     "exception": false,
     "start_time": "2025-03-05T18:49:06.256657",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "# Parameters\n",
    "var_list = [\"cape\", \"crr\", \"d\", \"ie\", \"ishf\", \"lsrr\", \"pv\", \"q\",\"r\", \"sp\", \"sstk\", \"tcw\", \"tcwv\", \"t\", \"ttr\", \"u\",\"v\", \"vo\",\"w\"] #ERA5 variables\n",
    "\n",
    "\n",
    "\n",
    "plevel_list = [False, False,300, False, False, False, 300, 300, 300,False, False, False, False, 300,  False, 300,300  ,  300, 300] #pressure levels of variables\n",
    "\n",
    "aew_subset = \"12hr_before\"\n",
    "model_save_name = \"best_model_var(300)1234.keras\"\n",
    "tuner_project_name = \"tuner_run(300)1234\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe4b521-b034-49f0-a1ac-d961fe639066",
   "metadata": {
    "papermill": {
     "duration": 0.005028,
     "end_time": "2025-03-05T18:49:06.279538",
     "exception": false,
     "start_time": "2025-03-05T18:49:06.274510",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3d1aa354-4561-4486-9f61-73f2c1c81a31",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 13.973479,
     "end_time": "2025-03-05T18:49:20.258119",
     "exception": false,
     "start_time": "2025-03-05T18:49:06.284640",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "# coding: utf-8\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import xarray as xr\n",
    "\n",
    "import sklearn\n",
    "\n",
    "import sklearn.model_selection\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras import layers\n",
    "\n",
    "import keras_tuner\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "keras.utils.set_random_seed(812)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "32c4826e-dbc1-45c0-aca0-bc38d0254f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def focal_loss(gamma=2.0, alpha=0.25):\n",
    "    \"\"\"Focal Loss for binary classification.\"\"\"\n",
    "    def loss_fn(y_true, y_pred):\n",
    "        # Clip to prevent NaNs \n",
    "        y_pred = tf.clip_by_value(y_pred, tf.keras.backend.epsilon(), 1 - tf.keras.backend.epsilon())\n",
    "        bce = tf.keras.backend.binary_crossentropy(y_true, y_pred)\n",
    "        p_t = y_true * y_pred + (1 - y_true) * (1 - y_pred)\n",
    "        modulating_factor = tf.pow(1.0 - p_t, gamma)\n",
    "        alpha_factor = y_true * alpha + (1 - y_true) * (1 - alpha)\n",
    "        return alpha_factor * modulating_factor * bce\n",
    "    return loss_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c74c2082-8917-4d0d-a2d7-b39f8548bcbb",
   "metadata": {
    "papermill": {
     "duration": 0.014754,
     "end_time": "2025-03-05T18:49:20.282885",
     "exception": false,
     "start_time": "2025-03-05T18:49:20.268131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#functions to calculate f1 score as loss function\n",
    "\n",
    "def f1_loss_sigmoid(y_true, y_pred):\n",
    "    \"\"\"\n",
    "\n",
    "    F1 metric for sigmoid output and integer encoded labels.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    # compute tp, fp, and fn\n",
    "\n",
    "    tp = K.sum(K.cast(y_true * y_pred, 'float'), axis=0)\n",
    "\n",
    "    fp = K.sum(K.cast((1 - y_true) * y_pred, 'float'), axis=0)\n",
    "\n",
    "    fn = K.sum(K.cast(y_true * (1 - y_pred), 'float'), axis=0)\n",
    "\n",
    "\n",
    "    # precision (tp / (tp + fp))\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "\n",
    "   # recall (tp / (tp + fn))\n",
    "\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "\n",
    "# harmonic mean of precision and recall\n",
    "\n",
    "    f1 = (2 * p * r) / (p + r + K.epsilon())\n",
    "\n",
    "    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "\n",
    "    return 1 - K.mean(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "58fe83a8-b5b0-4a10-81f6-a5b9277e5a3a",
   "metadata": {
    "papermill": {
     "duration": 0.012029,
     "end_time": "2025-03-05T18:49:20.300625",
     "exception": false,
     "start_time": "2025-03-05T18:49:20.288596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def f1_loss_onehot(y_true, y_pred):\n",
    "\n",
    "   \"\"\"\n",
    "\n",
    "   F1 metric for two-class output and one-hot encoded labels.\n",
    "\n",
    "   \"\"\"\n",
    "\n",
    "   # compute tp, fp, and fn\n",
    "\n",
    "   tp = K.sum(K.cast(y_true[:, 1] * y_pred[:, 1], 'float'), axis=0)\n",
    "\n",
    "   fp = K.sum(K.cast((1 - y_true[:, 1]) * y_pred[:, 1], 'float'), axis=0)\n",
    "\n",
    "   fn = K.sum(K.cast(y_true[:, 0] * (1 - y_pred[:, 0]), 'float'), axis=0)\n",
    "\n",
    "\n",
    "   # precision (tp / (tp + fp))\n",
    "\n",
    "   p = tp / (tp + fp + K.epsilon())\n",
    "\n",
    "   # recall (tp / (tp + fn))\n",
    "\n",
    "   r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "\n",
    "   # harmonic mean of precision and recall\n",
    "\n",
    "   f1 = (2 * p * r) / (p + r + K.epsilon())\n",
    "\n",
    "   f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "\n",
    "   return 1 - K.mean(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "82e6df90-377d-4c27-ac1d-156b3bc34623",
   "metadata": {
    "papermill": {
     "duration": 0.012229,
     "end_time": "2025-03-05T18:49:20.319927",
     "exception": false,
     "start_time": "2025-03-05T18:49:20.307698",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def add_dim(ds):\n",
    "    # Extract the source file name from the dataset's encoding.\n",
    "    fname = ds.encoding.get('source', '')\n",
    "    # Use a regex to capture the central latitude and longitude from the filename.\n",
    "    m = re.search(r'_(\\-?\\d+\\.\\d+)_(-?\\d+\\.\\d+)\\.nc$', fname)\n",
    "    if m:\n",
    "        lat_center = float(m.group(1))\n",
    "        lon_center = float(m.group(2))\n",
    "        # Assign the central coordinates and the file name as new coordinates.\n",
    "        ds = ds.assign_coords(lat_center=lat_center, lon_center=lon_center, file_name=fname)\n",
    "    else:\n",
    "        print(\"File name does not match expected pattern:\", fname)\n",
    "    \n",
    "    # Expand dims to add the 'sample' dimension and drop unnecessary variables.\n",
    "    return ds.assign_coords({\"sample\": 1}).expand_dims(dim={\"sample\": 1}).drop_vars(\"utc_date\").drop_vars(\"latitude\").drop_vars(\"longitude\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ec3de133-3ed1-4df3-9444-a58e88716284",
   "metadata": {
    "papermill": {
     "duration": 0.017203,
     "end_time": "2025-03-05T18:49:20.344038",
     "exception": false,
     "start_time": "2025-03-05T18:49:20.326835",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import xarray as xr\n",
    "\n",
    "def open_files_zarr(list_of_vars, aew_subset=\"12hr_before\",\n",
    "                    directory=\"/glade/derecho/scratch/rmandava/AEW_time_location_files/\",\n",
    "                    plevel_list=None, zarr_store_path=\"zarr_data\"):\n",
    "    \"\"\"\n",
    "    Opens ERA5 NetCDF files for the given variables. For each variable (or pressure-level variant),\n",
    "    it checks if a corresponding Zarr store exists in 'zarr_store_path'. If so, it loads the dataset\n",
    "    from the Zarr store; if not, it opens the NetCDF files, preprocesses them, saves them to Zarr,\n",
    "    and then returns the dataset.\n",
    "    \"\"\"\n",
    "    # Create the zarr_store_path directory if it doesn't exist.\n",
    "    if not os.path.exists(zarr_store_path):\n",
    "        os.makedirs(zarr_store_path)\n",
    "    \n",
    "    datas = {}\n",
    "    for num, var in enumerate(list_of_vars):\n",
    "        # Determine the key and filename based on whether a pressure level is specified.\n",
    "        if plevel_list:\n",
    "            if plevel_list[num]:\n",
    "                key = f\"{var}_{int(plevel_list[num])}\"\n",
    "                file_pattern = f'{directory}/{var}/aew_{aew_subset}_{int(plevel_list[num])}_*.nc'\n",
    "            else:\n",
    "                key = var\n",
    "                file_pattern = f'{directory}/{var}/aew_{aew_subset}_*.nc'\n",
    "        else:\n",
    "            key = var\n",
    "            file_pattern = f'{directory}/{var}/aew_{aew_subset}_*.nc'\n",
    "        \n",
    "        # Define the zarr path for this variable.\n",
    "        zarr_path = os.path.join(zarr_store_path, f\"{key}.zarr\")\n",
    "        \n",
    "        # If the Zarr dataset exists, load from it; otherwise, create it.\n",
    "        if os.path.exists(zarr_path):\n",
    "            print(f\"Loading {key} from Zarr store.\")\n",
    "            ds = xr.open_zarr(zarr_path)\n",
    "        else:\n",
    "            print(f\"Creating Zarr store for {key} from NetCDF files.\")\n",
    "            ds = xr.open_mfdataset(\n",
    "                file_pattern,\n",
    "                preprocess=add_dim,\n",
    "                concat_dim=\"sample\",\n",
    "                combine=\"nested\",\n",
    "            )\n",
    "            ds.to_zarr(zarr_path, mode=\"w\")\n",
    "        datas[key] = ds\n",
    "    \n",
    "    return datas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20c80e6-2437-4626-be0b-4d82bebb4f73",
   "metadata": {
    "papermill": {
     "duration": 0.015473,
     "end_time": "2025-03-05T18:49:20.366598",
     "exception": false,
     "start_time": "2025-03-05T18:49:20.351125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ad1f231e-abc1-49e7-9bab-09ab1f3f4ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose_load_concat(data_dictionary):\n",
    "    # Instead of eagerly converting to NumPy arrays, keep the datasets as xarray objects.\n",
    "    transposed = {}\n",
    "    for key, ds in data_dictionary.items():\n",
    "        var_name = key.split('_')[0].upper()\n",
    "        # Do lazy transpose and add a 'features' dimension\n",
    "        transposed[key] = ds[var_name].expand_dims('features').transpose('sample', 'latitude', 'longitude', 'features')\n",
    "    # Concatenate along the new 'features' dimension (if multiple variables exist)\n",
    "    if len(transposed) > 1:\n",
    "        data = xr.concat(list(transposed.values()), dim='features',coords='minimal',compat='override')\n",
    "    else:\n",
    "        data = list(transposed.values())[0]\n",
    "    # Use the coordinates (lat_center, lon_center) from one of the datasets.\n",
    "    # They remain lazy and are not computed until needed.\n",
    "    first_key = next(iter(data_dictionary))\n",
    "    lat_center = data_dictionary[first_key]['lat_center']\n",
    "    lon_center = data_dictionary[first_key]['lon_center']\n",
    "    label = data_dictionary[first_key]['label']\n",
    "    return data, label, lat_center, lon_center\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bec2717c-8176-447f-82ea-5b15e038ace1",
   "metadata": {
    "papermill": {
     "duration": 0.010767,
     "end_time": "2025-03-05T18:49:20.384143",
     "exception": false,
     "start_time": "2025-03-05T18:49:20.373376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def omit_nans(data, label, lat, lon):\n",
    "    # If data is an xarray DataArray, convert it to a NumPy array\n",
    "    if hasattr(data, 'values'):\n",
    "        data = data.values\n",
    "    maskarray = np.full(data.shape[0], True)\n",
    "    # Find indices where NaNs occur\n",
    "    masker = np.unique(np.argwhere(np.isnan(data))[:, 0])\n",
    "    maskarray[masker] = False\n",
    "\n",
    "    traindata = data[maskarray, ...]\n",
    "    trainlabel = label[maskarray]\n",
    "    lat_filtered = lat[maskarray]\n",
    "    lon_filtered = lon[maskarray]\n",
    "    return traindata, trainlabel, lat_filtered, lon_filtered\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d02dbe1a-f1ba-4f9b-8fe0-d9126814ae62",
   "metadata": {
    "papermill": {
     "duration": 0.010866,
     "end_time": "2025-03-05T18:49:20.400498",
     "exception": false,
     "start_time": "2025-03-05T18:49:20.389632",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def zscore(data):\n",
    "\n",
    "  \"\"\"\n",
    "\n",
    "  Rescaling the data using zscore (mean/std).\n",
    "\n",
    "  Each variable gets scaled independently from others.\n",
    "\n",
    "  Note that we will need to remove test data for formal training.\n",
    "\n",
    "  \"\"\"\n",
    "\n",
    "  for i in range(0, data_.shape[-1]):\n",
    "\n",
    "      data_[:, :, :, i] = (\n",
    "\n",
    "               data_[:, :, :, i] - np.nanmean(\n",
    "\n",
    "                     data_[:, :, :, i])) / np.nanstd(data_[:, :, :, i])\n",
    "\n",
    "  return data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "332bc130-a4e7-465c-a135-687f543db181",
   "metadata": {
    "papermill": {
     "duration": 0.011066,
     "end_time": "2025-03-05T18:49:20.416849",
     "exception": false,
     "start_time": "2025-03-05T18:49:20.405783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def minmax(data):\n",
    "\n",
    "   \"\"\"\n",
    "\n",
    "   Rescaling the data using min-max.\n",
    "\n",
    "   Each variable gets scaled independently from others.\n",
    "\n",
    "   Note that we will need to remove test data for formal training.\n",
    "\n",
    "   \"\"\"\n",
    "\n",
    "   for i in range(0, data_.shape[-1]):\n",
    "\n",
    "          data_[:, :, :, i] = (\n",
    "\n",
    "              data_[:, :, :, i] - np.nanmin(data_[:, :, :, i])\n",
    "\n",
    "          ) / (np.nanmax(data_[:, :, :, i]) - np.nanmin(data_[:, :, :, i]))\n",
    "   return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f652c778-f81b-4c46-bf87-d60487903b73",
   "metadata": {
    "papermill": {
     "duration": 0.010904,
     "end_time": "2025-03-05T18:49:20.433062",
     "exception": false,
     "start_time": "2025-03-05T18:49:20.422158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def random_split(data, label, split=0.3, seed=0):\n",
    "\n",
    "   \"\"\"\n",
    "\n",
    "   Help spliting data randomly for training and testing.\n",
    "\n",
    "   \"\"\"\n",
    "\n",
    "   np.random.seed(0)\n",
    "\n",
    "   da_indx = np.random.permutation(data.shape[0])\n",
    "\n",
    "   data = data[da_indx.astype(int)]\n",
    "\n",
    "   label = label[da_indx.astype(int)]\n",
    "\n",
    "   init_range = int(data.shape[0] * (1 - 0.3))\n",
    "\n",
    "   return data[:init_range], label[:init_range], data[init_range:], label[init_range:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c9f970b2-2444-4dba-8e66-a850482d5ea4",
   "metadata": {
    "papermill": {
     "duration": 0.010837,
     "end_time": "2025-03-05T18:49:20.449475",
     "exception": false,
     "start_time": "2025-03-05T18:49:20.438638",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pick_loss(loss_string):\n",
    "    \n",
    "\n",
    "    lossdict = {\n",
    "        \"relu\": tf.nn.relu,\n",
    "        \"tanh\": tf.nn.tanh,\n",
    "        \"selu\": tf.nn.selu,\n",
    "        \"sigmoid\": tf.nn.sigmoid,\n",
    "        \"relu6\": tf.nn.relu6,\n",
    "        \"silu\": tf.nn.silu,\n",
    "        \"gelu\": tf.nn.gelu,\n",
    "        \"lrelu\": tf.nn.leaky_relu,\n",
    "    }\n",
    "\n",
    "    return lossdict[loss_string]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d3e0c99e-885a-4f64-b057-0056b0ef246f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_saliency_map(model, input_sample):\n",
    "    \"\"\"\n",
    "    Compute a saliency map for a given input sample using a gradient-based approach.\n",
    "    \n",
    "    Args:\n",
    "        model (tf.keras.Model): The trained Keras model.\n",
    "        input_sample (numpy array): A single input sample of shape (1, height, width, channels).\n",
    "    \n",
    "    Returns:\n",
    "        saliency (numpy array): The saliency map of shape (height, width).\n",
    "    \"\"\"\n",
    "    # Ensure the model is in inference mode\n",
    "    model.trainable = False\n",
    "    input_tensor = tf.convert_to_tensor(input_sample)\n",
    "    \n",
    "    # Use GradientTape to record operations for automatic differentiation\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Watch the input tensor\n",
    "        tape.watch(input_tensor)\n",
    "        # Get the model's prediction\n",
    "        prediction = model(input_tensor)\n",
    "    \n",
    "    # Compute gradients of the prediction with respect to the input\n",
    "    grads = tape.gradient(prediction, input_tensor)\n",
    "    \n",
    "    # If there are multiple channels, take the maximum absolute gradient across channels\n",
    "    saliency = np.max(np.abs(grads.numpy()), axis=-1)[0]\n",
    "    return saliency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9776cdc0-38bc-476f-b93d-3753a2eb6803",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_saliency_per_channel(model, input_sample):\n",
    "    \"\"\"\n",
    "    Computes the saliency map for each channel of a given input sample.\n",
    "    \n",
    "    Args:\n",
    "        model (tf.keras.Model): The trained Keras model.\n",
    "        input_sample (numpy array): A single input sample with shape (1, H, W, C).\n",
    "        \n",
    "    Returns:\n",
    "        saliency_maps (numpy array): Absolute gradients with shape (H, W, C) for each channel.\n",
    "        channel_importance (numpy array): Mean saliency per channel (shape: (C,)).\n",
    "    \"\"\"\n",
    "    # Set the model to inference mode\n",
    "    model.trainable = False\n",
    "    input_tensor = tf.convert_to_tensor(input_sample)\n",
    "    \n",
    "    # Compute gradients with respect to the input sample using GradientTape\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(input_tensor)\n",
    "        prediction = model(input_tensor)\n",
    "    \n",
    "    # Calculate gradients: shape (1, H, W, C)\n",
    "    grads = tape.gradient(prediction, input_tensor)\n",
    "    \n",
    "    # Remove the batch dimension: shape becomes (H, W, C)\n",
    "    grads = grads.numpy()[0]\n",
    "    \n",
    "    # Take absolute value to measure importance (magnitude of sensitivity)\n",
    "    saliency_maps = np.abs(grads)\n",
    "    \n",
    "    # Aggregate saliency per channel (e.g., using the mean over spatial dimensions)\n",
    "    channel_importance = np.mean(saliency_maps, axis=(0, 1))\n",
    "    \n",
    "    return saliency_maps, channel_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "81aa5f1b-5513-4496-9fae-a6cde06e1aaa",
   "metadata": {
    "papermill": {
     "duration": 0.00964,
     "end_time": "2025-03-05T18:49:20.464813",
     "exception": false,
     "start_time": "2025-03-05T18:49:20.455173",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "number_of_features = len(var_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3490622e-a626-42aa-9cfe-020ee54d21e0",
   "metadata": {
    "papermill": {
     "duration": 758.818091,
     "end_time": "2025-03-05T19:01:59.288567",
     "exception": false,
     "start_time": "2025-03-05T18:49:20.470476",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cape from Zarr store.\n",
      "Loading crr from Zarr store.\n",
      "Loading d_300 from Zarr store.\n",
      "Loading ie from Zarr store.\n",
      "Loading ishf from Zarr store.\n",
      "Loading lsrr from Zarr store.\n",
      "Loading pv_300 from Zarr store.\n",
      "Loading q_300 from Zarr store.\n",
      "Loading r_300 from Zarr store.\n",
      "Loading sp from Zarr store.\n",
      "Loading sstk from Zarr store.\n",
      "Loading tcw from Zarr store.\n",
      "Loading tcwv from Zarr store.\n",
      "Loading t_300 from Zarr store.\n",
      "Loading ttr from Zarr store.\n",
      "Loading u_300 from Zarr store.\n",
      "Loading v_300 from Zarr store.\n",
      "Loading vo_300 from Zarr store.\n",
      "Loading w_300 from Zarr store.\n"
     ]
    }
   ],
   "source": [
    "data = open_files_zarr(\n",
    "    list_of_vars=var_list,\n",
    "    aew_subset=aew_subset,\n",
    "    directory=\"/glade/derecho/scratch/rmandava/AEW_time_location_files/\",\n",
    "    plevel_list=plevel_list,\n",
    "    zarr_store_path=\"/glade/derecho/scratch/rmandava/AEW_time_location_files/Project1/zarr\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ddac3e-071b-4796-9ca6-9cb01deeb598",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f240d4af-46d1-4cef-a5ab-2e2527a1639f",
   "metadata": {
    "papermill": {
     "duration": 185.616237,
     "end_time": "2025-03-05T19:05:04.925249",
     "exception": false,
     "start_time": "2025-03-05T19:01:59.309012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2750, 32, 32, 19)\n"
     ]
    }
   ],
   "source": [
    "# transpose the data and concat variables\n",
    "\n",
    "#data_, labels_ = transpose_load_concat(data)\n",
    "data_, labels_, sample_lat, sample_lon = transpose_load_concat(data)\n",
    "\n",
    "print(np.shape(data_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a0e4f7b8-f9e0-4131-ae35-97e47bc557d0",
   "metadata": {
    "papermill": {
     "duration": 0.372532,
     "end_time": "2025-03-05T19:05:05.305951",
     "exception": false,
     "start_time": "2025-03-05T19:05:04.933419",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check / remove nans\n",
    "\n",
    "data_, labels_, sample_lat, sample_lon = omit_nans(data_, labels_, sample_lat, sample_lon)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0492935e-1f35-446b-ab16-aba0e667857b",
   "metadata": {
    "papermill": {
     "duration": 0.044227,
     "end_time": "2025-03-05T19:05:05.358050",
     "exception": false,
     "start_time": "2025-03-05T19:05:05.313823",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(560, 32, 32, 19) (140, 32, 32, 19) (560,) (140,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/u/home/rmandava/.local/lib/python3.10/site-packages/xarray/core/indexing.py:1642: PerformanceWarning: Slicing with an out-of-order index is generating 106 times more chunks\n",
      "  return self.array[key]\n",
      "/glade/u/home/rmandava/.local/lib/python3.10/site-packages/xarray/core/indexing.py:1642: PerformanceWarning: Slicing with an out-of-order index is generating 27 times more chunks\n",
      "  return self.array[key]\n"
     ]
    }
   ],
   "source": [
    "#split train and test set\n",
    "X_train, X_test, y_train, y_test, lat_train, lat_test, lon_train, lon_test = sklearn.model_selection.train_test_split(\n",
    "    data_, labels_, sample_lat, sample_lon, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "print (np.shape(X_train), np.shape(X_test), np.shape(y_train), np.shape(y_test))\n",
    "\n",
    "\n",
    "y_train = np.expand_dims(y_train, axis=1)\n",
    "\n",
    "y_test = np.expand_dims(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "164ee316-7c83-474b-bdb9-7c12ca165e1f",
   "metadata": {
    "papermill": {
     "duration": 0.312834,
     "end_time": "2025-03-05T19:05:05.678612",
     "exception": false,
     "start_time": "2025-03-05T19:05:05.365778",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [21]: Scaling code (fixed to prevent data leakage)\n",
    "\n",
    "# Create the scaler object\n",
    "scaler_input = sklearn.preprocessing.StandardScaler()\n",
    "\n",
    "# Reshape training data to 2D (samples, features)\n",
    "X_train_tmp = np.reshape(X_train, (-1, len(var_list)))\n",
    "\n",
    "# Fit the scaler ONLY on the training data\n",
    "scaler_input.fit(X_train_tmp)  # <-- Key change: Learn mean/std from training data\n",
    "\n",
    "# Transform BOTH training and test data using the SAME scaler\n",
    "input_train_scaled = scaler_input.transform(X_train_tmp)          # Train: transform only\n",
    "input_test_scaled = scaler_input.transform(                       # Test: transform only\n",
    "    np.reshape(X_test, (-1, len(var_list)))\n",
    ")\n",
    "\n",
    "# Reshape back to original dimensions (samples, height, width, features)\n",
    "input_train_scaled = np.reshape(input_train_scaled, X_train.shape)\n",
    "input_test_scaled = np.reshape(input_test_scaled, X_test.shape)\n",
    "\n",
    "# Labels remain unchanged\n",
    "label_train_scaled = y_train\n",
    "label_test_scaled = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6bed418e-264b-45e6-92ee-b72c2f7a04d7",
   "metadata": {
    "papermill": {
     "duration": 0.014239,
     "end_time": "2025-03-05T19:05:05.701116",
     "exception": false,
     "start_time": "2025-03-05T19:05:05.686877",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(560, 32, 32, 19) (560, 1) (140, 32, 32, 19) (140, 1)\n"
     ]
    }
   ],
   "source": [
    "# print the shapes to double check them\n",
    "\n",
    "print(\n",
    "\n",
    "input_train_scaled.shape,\n",
    "\n",
    "label_train_scaled.shape,\n",
    "\n",
    "input_test_scaled.shape,\n",
    "\n",
    "label_test_scaled.shape\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "10597eb7-f8fa-4523-a306-55d5a442d504",
   "metadata": {
    "papermill": {
     "duration": 0.017418,
     "end_time": "2025-03-05T19:05:05.726147",
     "exception": false,
     "start_time": "2025-03-05T19:05:05.708729",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive samples in training data: 91 (16.25% of total)\n"
     ]
    }
   ],
   "source": [
    "#generate class weights due to class imbalance issues\n",
    "\n",
    "counts = np.bincount(y_train[:, 0].astype(int))\n",
    "\n",
    "\n",
    "print(\n",
    "\n",
    "\"Number of positive samples in training data: {} ({:.2f}% of total)\".format(\n",
    "\n",
    "counts[1], 100 * float(counts[1]) / len(y_train))\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "557d98a2-07ba-4fa7-8ba2-9ce8baa53b63",
   "metadata": {
    "papermill": {
     "duration": 0.01967,
     "end_time": "2025-03-05T19:05:05.753659",
     "exception": false,
     "start_time": "2025-03-05T19:05:05.733989",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.1625, 1: 0.8375}\n"
     ]
    }
   ],
   "source": [
    "# old weights\n",
    "\n",
    "# weight_for_0 = 1.0 / counts[0]\n",
    "\n",
    "# weight_for_1 = 1.0 / counts[1]\n",
    "\n",
    "\n",
    "#new weights\n",
    "\n",
    "weight_for_0 = float(counts[1]) / len(y_train)\n",
    "\n",
    "weight_for_1 = 1 - (float(counts[1]) / len(y_train))\n",
    "\n",
    "\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "print(class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "700f978d-cc6f-484a-864f-dcb9e703eed4",
   "metadata": {
    "papermill": {
     "duration": 1.029155,
     "end_time": "2025-03-05T19:05:06.790734",
     "exception": false,
     "start_time": "2025-03-05T19:05:05.761579",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "\n",
    "keras.metrics.BinaryCrossentropy(name='cross entropy'),\n",
    "\n",
    "keras.metrics.MeanSquaredError(name='mean_squared_error'),\n",
    "\n",
    "keras.metrics.RootMeanSquaredError(name='root_mean_squared_error'),\n",
    "\n",
    "keras.metrics.TruePositives(name='tp'),\n",
    "\n",
    "keras.metrics.FalsePositives(name='fp'),\n",
    "\n",
    "keras.metrics.TrueNegatives(name='tn'),\n",
    "\n",
    "keras.metrics.FalseNegatives(name='fn'),\n",
    "\n",
    "keras.metrics.BinaryAccuracy(name='binary_accuracy'),\n",
    "\n",
    "keras.metrics.F1Score(threshold=0.5, name='f1_score'),\n",
    "\n",
    "keras.metrics.Precision(name='precision'),\n",
    "\n",
    "keras.metrics.Recall(name='recall'),\n",
    "\n",
    "keras.metrics.AUC(name='auc'),\n",
    "\n",
    "keras.metrics.AUC(name='prc', curve='PR'),\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9900636-a8fb-4b46-9282-66643c95cdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6bc9aab7-2558-4304-a6c7-5809d60e8437",
   "metadata": {
    "papermill": {
     "duration": 0.030448,
     "end_time": "2025-03-05T19:05:06.829775",
     "exception": false,
     "start_time": "2025-03-05T19:05:06.799327",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MyHyperModel(keras_tuner.HyperModel):\n",
    "    def build(self, hp):\n",
    "        model = keras.Sequential()\n",
    "\n",
    "        model.add(keras.Input(shape=(32, 32, number_of_features)))\n",
    "\n",
    "        # Data augmentation\n",
    "        model.add(layers.RandomFlip(\"horizontal_and_vertical\"))\n",
    "        model.add(layers.RandomRotation(factor=(-0.5, 0.5)))\n",
    "\n",
    "        # CNN layers (normal Conv2D, no BatchNorm)\n",
    "        featmaps1 = hp.Int('units_1', min_value=10, max_value=60)\n",
    "        featmaps2 = hp.Int('units_2', min_value=10, max_value=64)\n",
    "        featmaps3 = hp.Int('units_3', min_value=10, max_value=128)\n",
    "        featmaps4 = hp.Int('units_4', min_value=10, max_value=80)\n",
    "        learning_rate = hp.Float('lr', min_value=1e-5, max_value=1e-2, sampling=\"log\")\n",
    "        act_func = hp.Choice('activation', [\"relu\", \"tanh\", \"selu\", \"sigmoid\", \"relu6\", \"silu\", \"gelu\"])\n",
    "\n",
    "        model.add(layers.Conv2D(featmaps1, 3, strides=1, padding=\"same\", activation=pick_loss(act_func)))\n",
    "        model.add(layers.MaxPooling2D(2))\n",
    "        model.add(layers.Dropout(0.2))\n",
    "\n",
    "        model.add(layers.Conv2D(featmaps2, 3, strides=1, padding=\"same\", activation=pick_loss(act_func)))\n",
    "        model.add(layers.MaxPooling2D(2))\n",
    "        model.add(layers.Dropout(0.2))\n",
    "\n",
    "        model.add(layers.Conv2D(featmaps3, 3, strides=1, padding=\"same\", activation=pick_loss(act_func)))\n",
    "        model.add(layers.MaxPooling2D(2))\n",
    "        model.add(layers.Dropout(0.2))\n",
    "\n",
    "        model.add(layers.GlobalMaxPooling2D())\n",
    "        model.add(layers.Dense(featmaps4))\n",
    "        model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "        \n",
    "        lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "            initial_learning_rate=learning_rate,\n",
    "            decay_steps=2000,\n",
    "            decay_rate=0.9,\n",
    "            staircase=True\n",
    "        )\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "        # Compile with Fixed Focal Loss (gamma=2.0, alpha=0.25)\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=focal_loss(gamma=2.0, alpha=0.25),\n",
    "            metrics=METRICS\n",
    "        )\n",
    "\n",
    "        return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e68e967f-623f-4332-a38c-57359b8121c3",
   "metadata": {
    "papermill": {
     "duration": 0.018907,
     "end_time": "2025-03-05T19:05:06.856235",
     "exception": false,
     "start_time": "2025-03-05T19:05:06.837328",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fit(self, hp, model, *args, **kwargs):\n",
    "    batchsizenum = hp.Int('batch_size', min_value=10, max_value=60, step=5, sampling=\"linear\")\n",
    "\n",
    "    print({k: hp.get(k) if hp.is_active(k) else None for k in hp._hps})\n",
    "\n",
    "    return model.fit(\n",
    "        *args,\n",
    "        batch_size=batchsizenum,\n",
    "        # normally we might use early stopping, but not needed since\n",
    "        # callbacks saves checkpoints of the model during trials\n",
    "        # callbacks=keras.callbacks.EarlyStopping('val_loss', patience=5),\n",
    "        validation_split=0.1,\n",
    "        shuffle=True,\n",
    "        class_weight=class_weight,\n",
    "        **kwargs,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4b0947fd-6eb0-4f20-8b0f-2f5d11ab5b3b",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 0.379052,
     "end_time": "2025-03-05T19:05:07.243192",
     "exception": false,
     "start_time": "2025-03-05T19:05:06.864140",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "Parameters",
     "parameters"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 6\n",
      "units_1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 10, 'max_value': 60, 'step': 1, 'sampling': 'linear'}\n",
      "units_2 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 10, 'max_value': 64, 'step': 1, 'sampling': 'linear'}\n",
      "units_3 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 10, 'max_value': 128, 'step': 1, 'sampling': 'linear'}\n",
      "units_4 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 10, 'max_value': 80, 'step': 1, 'sampling': 'linear'}\n",
      "lr (Float)\n",
      "{'default': 1e-05, 'conditions': [], 'min_value': 1e-05, 'max_value': 0.01, 'step': None, 'sampling': 'log'}\n",
      "activation (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'tanh', 'selu', 'sigmoid', 'relu6', 'silu', 'gelu'], 'ordered': False}\n"
     ]
    }
   ],
   "source": [
    "# make the tuner object\n",
    "tuner = keras_tuner.BayesianOptimization(\n",
    "    hypermodel=MyHyperModel(),\n",
    "    objective=keras_tuner.Objective(\"val_f1_score\", direction=\"max\"),\n",
    "    max_trials=150,\n",
    "    project_name=tuner_project_name,\n",
    "    alpha=0.0001,\n",
    "    beta=2.6,\n",
    "    seed=123,\n",
    "    tune_new_entries=True,\n",
    "    allow_new_entries=True,\n",
    "    max_retries_per_trial=1,\n",
    "    max_consecutive_failed_trials=3,\n",
    "    overwrite=True,\n",
    ")\n",
    "\n",
    "# summary\n",
    "tuner.search_space_summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5a6396-3b45-4ae6-91ad-62b07260777e",
   "metadata": {
    "papermill": {
     "duration": 6055.188829,
     "end_time": "2025-03-05T20:46:02.439902",
     "exception": false,
     "start_time": "2025-03-05T19:05:07.251073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 Complete [00h 00m 23s]\n",
      "val_f1_score: 0.5\n",
      "\n",
      "Best val_f1_score So Far: 0.5\n",
      "Total elapsed time: 00h 00m 47s\n",
      "\n",
      "Search: Running Trial #3\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "44                |39                |units_1\n",
      "41                |38                |units_2\n",
      "18                |47                |units_3\n",
      "23                |39                |units_4\n",
      "1.0105e-05        |0.00030304        |lr\n",
      "silu              |sigmoid           |activation\n",
      "\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 2s 36ms/step - loss: 1.3443 - cross entropy: 1.9970 - mean_squared_error: 0.5516 - root_mean_squared_error: 0.7427 - tp: 87.0000 - fp: 420.0000 - tn: 49.0000 - fn: 4.0000 - binary_accuracy: 0.2429 - f1_score: 0.2910 - precision: 0.1716 - recall: 0.9560 - auc: 0.6199 - prc: 0.2029 - val_loss: 0.6528 - val_cross entropy: 1.3866 - val_mean_squared_error: 0.4922 - val_root_mean_squared_error: 0.7016 - val_tp: 6.0000 - val_fp: 50.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_binary_accuracy: 0.1071 - val_f1_score: 0.1935 - val_precision: 0.1071 - val_recall: 1.0000 - val_auc: 0.5400 - val_prc: 0.1092\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2211 - cross entropy: 2.0259 - mean_squared_error: 0.5821 - root_mean_squared_error: 0.7630 - tp: 85.0000 - fp: 419.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - binary_accuracy: 0.1687 - f1_score: 0.2886 - precision: 0.1687 - recall: 1.0000 - auc: 0.6354 - prc: 0.2175 - val_loss: 0.5855 - val_cross entropy: 1.3079 - val_mean_squared_error: 0.4726 - val_root_mean_squared_error: 0.6875 - val_tp: 6.0000 - val_fp: 50.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_binary_accuracy: 0.1071 - val_f1_score: 0.1935 - val_precision: 0.1071 - val_recall: 1.0000 - val_auc: 0.5283 - val_prc: 0.1079\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.1159 - cross entropy: 1.9051 - mean_squared_error: 0.5656 - root_mean_squared_error: 0.7521 - tp: 85.0000 - fp: 419.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - binary_accuracy: 0.1687 - f1_score: 0.2886 - precision: 0.1687 - recall: 1.0000 - auc: 0.6073 - prc: 0.2096 - val_loss: 0.5236 - val_cross entropy: 1.2350 - val_mean_squared_error: 0.4531 - val_root_mean_squared_error: 0.6731 - val_tp: 6.0000 - val_fp: 50.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_binary_accuracy: 0.1071 - val_f1_score: 0.1935 - val_precision: 0.1071 - val_recall: 1.0000 - val_auc: 0.5150 - val_prc: 0.1052\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.0026 - cross entropy: 1.7715 - mean_squared_error: 0.5461 - root_mean_squared_error: 0.7390 - tp: 85.0000 - fp: 418.0000 - tn: 1.0000 - fn: 0.0000e+00 - binary_accuracy: 0.1706 - f1_score: 0.2891 - precision: 0.1690 - recall: 1.0000 - auc: 0.5973 - prc: 0.1954 - val_loss: 0.4683 - val_cross entropy: 1.1690 - val_mean_squared_error: 0.4339 - val_root_mean_squared_error: 0.6587 - val_tp: 6.0000 - val_fp: 50.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_binary_accuracy: 0.1071 - val_f1_score: 0.1935 - val_precision: 0.1071 - val_recall: 1.0000 - val_auc: 0.5167 - val_prc: 0.1054\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.8606 - cross entropy: 1.6052 - mean_squared_error: 0.5212 - root_mean_squared_error: 0.7219 - tp: 85.0000 - fp: 419.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - binary_accuracy: 0.1687 - f1_score: 0.2886 - precision: 0.1687 - recall: 1.0000 - auc: 0.6040 - prc: 0.2062 - val_loss: 0.4188 - val_cross entropy: 1.1092 - val_mean_squared_error: 0.4155 - val_root_mean_squared_error: 0.6446 - val_tp: 6.0000 - val_fp: 50.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_binary_accuracy: 0.1071 - val_f1_score: 0.1935 - val_precision: 0.1071 - val_recall: 1.0000 - val_auc: 0.4967 - val_prc: 0.1019\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.7953 - cross entropy: 1.5315 - mean_squared_error: 0.5044 - root_mean_squared_error: 0.7102 - tp: 85.0000 - fp: 415.0000 - tn: 4.0000 - fn: 0.0000e+00 - binary_accuracy: 0.1766 - f1_score: 0.2906 - precision: 0.1700 - recall: 1.0000 - auc: 0.6026 - prc: 0.2050 - val_loss: 0.3753 - val_cross entropy: 1.0558 - val_mean_squared_error: 0.3980 - val_root_mean_squared_error: 0.6308 - val_tp: 6.0000 - val_fp: 49.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_binary_accuracy: 0.1250 - val_f1_score: 0.1967 - val_precision: 0.1091 - val_recall: 1.0000 - val_auc: 0.4867 - val_prc: 0.1011\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.6896 - cross entropy: 1.4043 - mean_squared_error: 0.4821 - root_mean_squared_error: 0.6943 - tp: 85.0000 - fp: 413.0000 - tn: 6.0000 - fn: 0.0000e+00 - binary_accuracy: 0.1806 - f1_score: 0.2916 - precision: 0.1707 - recall: 1.0000 - auc: 0.5915 - prc: 0.1979 - val_loss: 0.3370 - val_cross entropy: 1.0076 - val_mean_squared_error: 0.3812 - val_root_mean_squared_error: 0.6174 - val_tp: 5.0000 - val_fp: 49.0000 - val_tn: 1.0000 - val_fn: 1.0000 - val_binary_accuracy: 0.1071 - val_f1_score: 0.1667 - val_precision: 0.0926 - val_recall: 0.8333 - val_auc: 0.4750 - val_prc: 0.0982\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.6222 - cross entropy: 1.3324 - mean_squared_error: 0.4695 - root_mean_squared_error: 0.6852 - tp: 84.0000 - fp: 417.0000 - tn: 2.0000 - fn: 1.0000 - binary_accuracy: 0.1706 - f1_score: 0.2867 - precision: 0.1677 - recall: 0.9882 - auc: 0.5130 - prc: 0.1690 - val_loss: 0.3019 - val_cross entropy: 0.9626 - val_mean_squared_error: 0.3648 - val_root_mean_squared_error: 0.6040 - val_tp: 5.0000 - val_fp: 48.0000 - val_tn: 2.0000 - val_fn: 1.0000 - val_binary_accuracy: 0.1250 - val_f1_score: 0.1695 - val_precision: 0.0943 - val_recall: 0.8333 - val_auc: 0.4500 - val_prc: 0.0923\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.5328 - cross entropy: 1.2220 - mean_squared_error: 0.4403 - root_mean_squared_error: 0.6635 - tp: 84.0000 - fp: 408.0000 - tn: 11.0000 - fn: 1.0000 - binary_accuracy: 0.1885 - f1_score: 0.2912 - precision: 0.1707 - recall: 0.9882 - auc: 0.5866 - prc: 0.2052 - val_loss: 0.2706 - val_cross entropy: 0.9212 - val_mean_squared_error: 0.3490 - val_root_mean_squared_error: 0.5908 - val_tp: 5.0000 - val_fp: 45.0000 - val_tn: 5.0000 - val_fn: 1.0000 - val_binary_accuracy: 0.1786 - val_f1_score: 0.1786 - val_precision: 0.1000 - val_recall: 0.8333 - val_auc: 0.4117 - val_prc: 0.0852\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.4865 - cross entropy: 1.1738 - mean_squared_error: 0.4265 - root_mean_squared_error: 0.6531 - tp: 84.0000 - fp: 404.0000 - tn: 15.0000 - fn: 1.0000 - binary_accuracy: 0.1964 - f1_score: 0.2932 - precision: 0.1721 - recall: 0.9882 - auc: 0.4836 - prc: 0.1712 - val_loss: 0.2429 - val_cross entropy: 0.8835 - val_mean_squared_error: 0.3341 - val_root_mean_squared_error: 0.5780 - val_tp: 5.0000 - val_fp: 44.0000 - val_tn: 6.0000 - val_fn: 1.0000 - val_binary_accuracy: 0.1964 - val_f1_score: 0.1818 - val_precision: 0.1020 - val_recall: 0.8333 - val_auc: 0.3850 - val_prc: 0.0816\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.4230 - cross entropy: 1.0951 - mean_squared_error: 0.4049 - root_mean_squared_error: 0.6363 - tp: 84.0000 - fp: 401.0000 - tn: 18.0000 - fn: 1.0000 - binary_accuracy: 0.2024 - f1_score: 0.2947 - precision: 0.1732 - recall: 0.9882 - auc: 0.5110 - prc: 0.1712 - val_loss: 0.2189 - val_cross entropy: 0.8496 - val_mean_squared_error: 0.3201 - val_root_mean_squared_error: 0.5658 - val_tp: 4.0000 - val_fp: 39.0000 - val_tn: 11.0000 - val_fn: 2.0000 - val_binary_accuracy: 0.2679 - val_f1_score: 0.1633 - val_precision: 0.0930 - val_recall: 0.6667 - val_auc: 0.3433 - val_prc: 0.0753\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3778 - cross entropy: 1.0477 - mean_squared_error: 0.3906 - root_mean_squared_error: 0.6250 - tp: 78.0000 - fp: 386.0000 - tn: 33.0000 - fn: 7.0000 - binary_accuracy: 0.2202 - f1_score: 0.2842 - precision: 0.1681 - recall: 0.9176 - auc: 0.4322 - prc: 0.1523 - val_loss: 0.1979 - val_cross entropy: 0.8187 - val_mean_squared_error: 0.3070 - val_root_mean_squared_error: 0.5541 - val_tp: 3.0000 - val_fp: 37.0000 - val_tn: 13.0000 - val_fn: 3.0000 - val_binary_accuracy: 0.2857 - val_f1_score: 0.1304 - val_precision: 0.0750 - val_recall: 0.5000 - val_auc: 0.3050 - val_prc: 0.0715\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3490 - cross entropy: 1.0160 - mean_squared_error: 0.3788 - root_mean_squared_error: 0.6154 - tp: 72.0000 - fp: 376.0000 - tn: 43.0000 - fn: 13.0000 - binary_accuracy: 0.2282 - f1_score: 0.2702 - precision: 0.1607 - recall: 0.8471 - auc: 0.4000 - prc: 0.1425 - val_loss: 0.1797 - val_cross entropy: 0.7906 - val_mean_squared_error: 0.2947 - val_root_mean_squared_error: 0.5429 - val_tp: 3.0000 - val_fp: 33.0000 - val_tn: 17.0000 - val_fn: 3.0000 - val_binary_accuracy: 0.3571 - val_f1_score: 0.1429 - val_precision: 0.0833 - val_recall: 0.5000 - val_auc: 0.2717 - val_prc: 0.0693\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3060 - cross entropy: 0.9616 - mean_squared_error: 0.3619 - root_mean_squared_error: 0.6016 - tp: 62.0000 - fp: 373.0000 - tn: 46.0000 - fn: 23.0000 - binary_accuracy: 0.2143 - f1_score: 0.2385 - precision: 0.1425 - recall: 0.7294 - auc: 0.3828 - prc: 0.1391 - val_loss: 0.1643 - val_cross entropy: 0.7658 - val_mean_squared_error: 0.2836 - val_root_mean_squared_error: 0.5325 - val_tp: 3.0000 - val_fp: 33.0000 - val_tn: 17.0000 - val_fn: 3.0000 - val_binary_accuracy: 0.3571 - val_f1_score: 0.1429 - val_precision: 0.0833 - val_recall: 0.5000 - val_auc: 0.2367 - val_prc: 0.0676\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2731 - cross entropy: 0.9213 - mean_squared_error: 0.3469 - root_mean_squared_error: 0.5890 - tp: 58.0000 - fp: 359.0000 - tn: 60.0000 - fn: 27.0000 - binary_accuracy: 0.2341 - f1_score: 0.2311 - precision: 0.1391 - recall: 0.6824 - auc: 0.3683 - prc: 0.1318 - val_loss: 0.1509 - val_cross entropy: 0.7432 - val_mean_squared_error: 0.2733 - val_root_mean_squared_error: 0.5228 - val_tp: 1.0000 - val_fp: 31.0000 - val_tn: 19.0000 - val_fn: 5.0000 - val_binary_accuracy: 0.3571 - val_f1_score: 0.0526 - val_precision: 0.0312 - val_recall: 0.1667 - val_auc: 0.2317 - val_prc: 0.0670\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.2477 - cross entropy: 0.8819 - mean_squared_error: 0.3281 - root_mean_squared_error: 0.5728 - tp: 49.0000 - fp: 335.0000 - tn: 84.0000 - fn: 36.0000 - binary_accuracy: 0.2639 - f1_score: 0.2090 - precision: 0.1276 - recall: 0.5765 - auc: 0.3487 - prc: 0.1273 - val_loss: 0.1400 - val_cross entropy: 0.7238 - val_mean_squared_error: 0.2643 - val_root_mean_squared_error: 0.5141 - val_tp: 0.0000e+00 - val_fp: 27.0000 - val_tn: 23.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.4107 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.2300 - val_prc: 0.0666\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2176 - cross entropy: 0.8470 - mean_squared_error: 0.3178 - root_mean_squared_error: 0.5637 - tp: 46.0000 - fp: 333.0000 - tn: 86.0000 - fn: 39.0000 - binary_accuracy: 0.2619 - f1_score: 0.1983 - precision: 0.1214 - recall: 0.5412 - auc: 0.3796 - prc: 0.1350 - val_loss: 0.1307 - val_cross entropy: 0.7064 - val_mean_squared_error: 0.2562 - val_root_mean_squared_error: 0.5061 - val_tp: 0.0000e+00 - val_fp: 26.0000 - val_tn: 24.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.4286 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.2283 - val_prc: 0.0663\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1973 - cross entropy: 0.8152 - mean_squared_error: 0.3041 - root_mean_squared_error: 0.5515 - tp: 45.0000 - fp: 293.0000 - tn: 126.0000 - fn: 40.0000 - binary_accuracy: 0.3393 - f1_score: 0.2128 - precision: 0.1331 - recall: 0.5294 - auc: 0.3625 - prc: 0.1246 - val_loss: 0.1229 - val_cross entropy: 0.6911 - val_mean_squared_error: 0.2489 - val_root_mean_squared_error: 0.4989 - val_tp: 0.0000e+00 - val_fp: 23.0000 - val_tn: 27.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.4821 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.2250 - val_prc: 0.0666\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1796 - cross entropy: 0.7932 - mean_squared_error: 0.2957 - root_mean_squared_error: 0.5437 - tp: 32.0000 - fp: 281.0000 - tn: 138.0000 - fn: 53.0000 - binary_accuracy: 0.3373 - f1_score: 0.1608 - precision: 0.1022 - recall: 0.3765 - auc: 0.2976 - prc: 0.1175 - val_loss: 0.1166 - val_cross entropy: 0.6783 - val_mean_squared_error: 0.2428 - val_root_mean_squared_error: 0.4928 - val_tp: 0.0000e+00 - val_fp: 21.0000 - val_tn: 29.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.5179 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.2200 - val_prc: 0.0659\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1715 - cross entropy: 0.7744 - mean_squared_error: 0.2869 - root_mean_squared_error: 0.5357 - tp: 31.0000 - fp: 280.0000 - tn: 139.0000 - fn: 54.0000 - binary_accuracy: 0.3373 - f1_score: 0.1566 - precision: 0.0997 - recall: 0.3647 - auc: 0.3212 - prc: 0.1323 - val_loss: 0.1109 - val_cross entropy: 0.6661 - val_mean_squared_error: 0.2370 - val_root_mean_squared_error: 0.4868 - val_tp: 0.0000e+00 - val_fp: 20.0000 - val_tn: 30.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.5357 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.2167 - val_prc: 0.0657\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1564 - cross entropy: 0.7535 - mean_squared_error: 0.2771 - root_mean_squared_error: 0.5264 - tp: 24.0000 - fp: 250.0000 - tn: 169.0000 - fn: 61.0000 - binary_accuracy: 0.3829 - f1_score: 0.1337 - precision: 0.0876 - recall: 0.2824 - auc: 0.3301 - prc: 0.1271 - val_loss: 0.1064 - val_cross entropy: 0.6561 - val_mean_squared_error: 0.2322 - val_root_mean_squared_error: 0.4819 - val_tp: 0.0000e+00 - val_fp: 18.0000 - val_tn: 32.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.5714 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.2300 - val_prc: 0.0665\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1493 - cross entropy: 0.7503 - mean_squared_error: 0.2759 - root_mean_squared_error: 0.5253 - tp: 21.0000 - fp: 240.0000 - tn: 179.0000 - fn: 64.0000 - binary_accuracy: 0.3968 - f1_score: 0.1214 - precision: 0.0805 - recall: 0.2471 - auc: 0.2910 - prc: 0.1121 - val_loss: 0.1027 - val_cross entropy: 0.6477 - val_mean_squared_error: 0.2282 - val_root_mean_squared_error: 0.4777 - val_tp: 0.0000e+00 - val_fp: 18.0000 - val_tn: 32.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.5714 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.2333 - val_prc: 0.0669\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1367 - cross entropy: 0.7246 - mean_squared_error: 0.2649 - root_mean_squared_error: 0.5147 - tp: 24.0000 - fp: 224.0000 - tn: 195.0000 - fn: 61.0000 - binary_accuracy: 0.4345 - f1_score: 0.1441 - precision: 0.0968 - recall: 0.2824 - auc: 0.3273 - prc: 0.1233 - val_loss: 0.0993 - val_cross entropy: 0.6395 - val_mean_squared_error: 0.2242 - val_root_mean_squared_error: 0.4735 - val_tp: 0.0000e+00 - val_fp: 16.0000 - val_tn: 34.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.6071 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.2350 - val_prc: 0.0671\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1297 - cross entropy: 0.7113 - mean_squared_error: 0.2586 - root_mean_squared_error: 0.5085 - tp: 13.0000 - fp: 216.0000 - tn: 203.0000 - fn: 72.0000 - binary_accuracy: 0.4286 - f1_score: 0.0828 - precision: 0.0568 - recall: 0.1529 - auc: 0.3062 - prc: 0.1148 - val_loss: 0.0963 - val_cross entropy: 0.6322 - val_mean_squared_error: 0.2207 - val_root_mean_squared_error: 0.4698 - val_tp: 0.0000e+00 - val_fp: 13.0000 - val_tn: 37.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.6607 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.2317 - val_prc: 0.0667\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1355 - cross entropy: 0.7231 - mean_squared_error: 0.2634 - root_mean_squared_error: 0.5133 - tp: 14.0000 - fp: 215.0000 - tn: 204.0000 - fn: 71.0000 - binary_accuracy: 0.4325 - f1_score: 0.0892 - precision: 0.0611 - recall: 0.1647 - auc: 0.2949 - prc: 0.1141 - val_loss: 0.0937 - val_cross entropy: 0.6255 - val_mean_squared_error: 0.2175 - val_root_mean_squared_error: 0.4663 - val_tp: 0.0000e+00 - val_fp: 12.0000 - val_tn: 38.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.6786 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.2350 - val_prc: 0.0670\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1401 - cross entropy: 0.7304 - mean_squared_error: 0.2652 - root_mean_squared_error: 0.5150 - tp: 15.0000 - fp: 202.0000 - tn: 217.0000 - fn: 70.0000 - binary_accuracy: 0.4603 - f1_score: 0.0993 - precision: 0.0691 - recall: 0.1765 - auc: 0.2788 - prc: 0.1108 - val_loss: 0.0910 - val_cross entropy: 0.6184 - val_mean_squared_error: 0.2141 - val_root_mean_squared_error: 0.4627 - val_tp: 0.0000e+00 - val_fp: 7.0000 - val_tn: 43.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.7679 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.2400 - val_prc: 0.0673\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1212 - cross entropy: 0.6933 - mean_squared_error: 0.2490 - root_mean_squared_error: 0.4990 - tp: 14.0000 - fp: 182.0000 - tn: 237.0000 - fn: 71.0000 - binary_accuracy: 0.4980 - f1_score: 0.0996 - precision: 0.0714 - recall: 0.1647 - auc: 0.3261 - prc: 0.1186 - val_loss: 0.0887 - val_cross entropy: 0.6121 - val_mean_squared_error: 0.2110 - val_root_mean_squared_error: 0.4594 - val_tp: 0.0000e+00 - val_fp: 7.0000 - val_tn: 43.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.7679 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.2467 - val_prc: 0.0676\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1158 - cross entropy: 0.6846 - mean_squared_error: 0.2463 - root_mean_squared_error: 0.4963 - tp: 11.0000 - fp: 183.0000 - tn: 236.0000 - fn: 74.0000 - binary_accuracy: 0.4901 - f1_score: 0.0789 - precision: 0.0567 - recall: 0.1294 - auc: 0.3146 - prc: 0.1175 - val_loss: 0.0867 - val_cross entropy: 0.6065 - val_mean_squared_error: 0.2084 - val_root_mean_squared_error: 0.4565 - val_tp: 0.0000e+00 - val_fp: 6.0000 - val_tn: 44.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.7857 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.2467 - val_prc: 0.0677\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1087 - cross entropy: 0.6670 - mean_squared_error: 0.2378 - root_mean_squared_error: 0.4877 - tp: 11.0000 - fp: 149.0000 - tn: 270.0000 - fn: 74.0000 - binary_accuracy: 0.5575 - f1_score: 0.0898 - precision: 0.0688 - recall: 0.1294 - auc: 0.3386 - prc: 0.1257 - val_loss: 0.0851 - val_cross entropy: 0.6021 - val_mean_squared_error: 0.2063 - val_root_mean_squared_error: 0.4542 - val_tp: 0.0000e+00 - val_fp: 6.0000 - val_tn: 44.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.7857 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.2533 - val_prc: 0.0681\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1151 - cross entropy: 0.6799 - mean_squared_error: 0.2408 - root_mean_squared_error: 0.4908 - tp: 16.0000 - fp: 150.0000 - tn: 269.0000 - fn: 69.0000 - binary_accuracy: 0.5655 - f1_score: 0.1275 - precision: 0.0964 - recall: 0.1882 - auc: 0.3550 - prc: 0.1285 - val_loss: 0.0834 - val_cross entropy: 0.5974 - val_mean_squared_error: 0.2041 - val_root_mean_squared_error: 0.4518 - val_tp: 0.0000e+00 - val_fp: 5.0000 - val_tn: 45.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8036 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.2583 - val_prc: 0.0685\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1090 - cross entropy: 0.6747 - mean_squared_error: 0.2385 - root_mean_squared_error: 0.4884 - tp: 12.0000 - fp: 141.0000 - tn: 278.0000 - fn: 73.0000 - binary_accuracy: 0.5754 - f1_score: 0.1008 - precision: 0.0784 - recall: 0.1412 - auc: 0.3240 - prc: 0.1245 - val_loss: 0.0820 - val_cross entropy: 0.5932 - val_mean_squared_error: 0.2021 - val_root_mean_squared_error: 0.4495 - val_tp: 0.0000e+00 - val_fp: 4.0000 - val_tn: 46.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8214 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.2667 - val_prc: 0.0692\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1072 - cross entropy: 0.6675 - mean_squared_error: 0.2362 - root_mean_squared_error: 0.4860 - tp: 10.0000 - fp: 130.0000 - tn: 289.0000 - fn: 75.0000 - binary_accuracy: 0.5933 - f1_score: 0.0889 - precision: 0.0714 - recall: 0.1176 - auc: 0.3188 - prc: 0.1178 - val_loss: 0.0806 - val_cross entropy: 0.5892 - val_mean_squared_error: 0.2002 - val_root_mean_squared_error: 0.4474 - val_tp: 0.0000e+00 - val_fp: 4.0000 - val_tn: 46.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8214 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.2650 - val_prc: 0.0693\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1107 - cross entropy: 0.6729 - mean_squared_error: 0.2351 - root_mean_squared_error: 0.4848 - tp: 12.0000 - fp: 125.0000 - tn: 294.0000 - fn: 73.0000 - binary_accuracy: 0.6071 - f1_score: 0.1081 - precision: 0.0876 - recall: 0.1412 - auc: 0.3466 - prc: 0.1213 - val_loss: 0.0792 - val_cross entropy: 0.5854 - val_mean_squared_error: 0.1983 - val_root_mean_squared_error: 0.4453 - val_tp: 0.0000e+00 - val_fp: 3.0000 - val_tn: 47.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8393 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.2667 - val_prc: 0.0694\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1036 - cross entropy: 0.6572 - mean_squared_error: 0.2316 - root_mean_squared_error: 0.4812 - tp: 12.0000 - fp: 111.0000 - tn: 308.0000 - fn: 73.0000 - binary_accuracy: 0.6349 - f1_score: 0.1154 - precision: 0.0976 - recall: 0.1412 - auc: 0.3456 - prc: 0.1220 - val_loss: 0.0779 - val_cross entropy: 0.5814 - val_mean_squared_error: 0.1964 - val_root_mean_squared_error: 0.4432 - val_tp: 0.0000e+00 - val_fp: 2.0000 - val_tn: 48.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8571 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.2683 - val_prc: 0.0694\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1020 - cross entropy: 0.6547 - mean_squared_error: 0.2287 - root_mean_squared_error: 0.4782 - tp: 7.0000 - fp: 111.0000 - tn: 308.0000 - fn: 78.0000 - binary_accuracy: 0.6250 - f1_score: 0.0690 - precision: 0.0593 - recall: 0.0824 - auc: 0.3358 - prc: 0.1250 - val_loss: 0.0768 - val_cross entropy: 0.5779 - val_mean_squared_error: 0.1948 - val_root_mean_squared_error: 0.4413 - val_tp: 0.0000e+00 - val_fp: 2.0000 - val_tn: 48.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8571 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.2733 - val_prc: 0.0699\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0948 - cross entropy: 0.6336 - mean_squared_error: 0.2203 - root_mean_squared_error: 0.4693 - tp: 12.0000 - fp: 100.0000 - tn: 319.0000 - fn: 73.0000 - binary_accuracy: 0.6567 - f1_score: 0.1218 - precision: 0.1071 - recall: 0.1412 - auc: 0.3793 - prc: 0.1368 - val_loss: 0.0757 - val_cross entropy: 0.5748 - val_mean_squared_error: 0.1933 - val_root_mean_squared_error: 0.4397 - val_tp: 0.0000e+00 - val_fp: 2.0000 - val_tn: 48.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8571 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.2733 - val_prc: 0.0698\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0936 - cross entropy: 0.6284 - mean_squared_error: 0.2189 - root_mean_squared_error: 0.4679 - tp: 8.0000 - fp: 91.0000 - tn: 328.0000 - fn: 77.0000 - binary_accuracy: 0.6667 - f1_score: 0.0870 - precision: 0.0808 - recall: 0.0941 - auc: 0.3708 - prc: 0.1272 - val_loss: 0.0748 - val_cross entropy: 0.5718 - val_mean_squared_error: 0.1919 - val_root_mean_squared_error: 0.4380 - val_tp: 0.0000e+00 - val_fp: 1.0000 - val_tn: 49.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8750 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.2783 - val_prc: 0.0701\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0891 - cross entropy: 0.6207 - mean_squared_error: 0.2145 - root_mean_squared_error: 0.4631 - tp: 5.0000 - fp: 70.0000 - tn: 349.0000 - fn: 80.0000 - binary_accuracy: 0.7024 - f1_score: 0.0625 - precision: 0.0667 - recall: 0.0588 - auc: 0.3720 - prc: 0.1314 - val_loss: 0.0738 - val_cross entropy: 0.5691 - val_mean_squared_error: 0.1906 - val_root_mean_squared_error: 0.4366 - val_tp: 0.0000e+00 - val_fp: 1.0000 - val_tn: 49.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8750 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.2867 - val_prc: 0.0707\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0934 - cross entropy: 0.6283 - mean_squared_error: 0.2178 - root_mean_squared_error: 0.4667 - tp: 5.0000 - fp: 83.0000 - tn: 336.0000 - fn: 80.0000 - binary_accuracy: 0.6766 - f1_score: 0.0578 - precision: 0.0568 - recall: 0.0588 - auc: 0.3591 - prc: 0.1249 - val_loss: 0.0730 - val_cross entropy: 0.5664 - val_mean_squared_error: 0.1893 - val_root_mean_squared_error: 0.4351 - val_tp: 0.0000e+00 - val_fp: 1.0000 - val_tn: 49.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8750 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.2800 - val_prc: 0.0701\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0881 - cross entropy: 0.6180 - mean_squared_error: 0.2116 - root_mean_squared_error: 0.4599 - tp: 8.0000 - fp: 71.0000 - tn: 348.0000 - fn: 77.0000 - binary_accuracy: 0.7063 - f1_score: 0.0976 - precision: 0.1013 - recall: 0.0941 - auc: 0.3913 - prc: 0.1336 - val_loss: 0.0722 - val_cross entropy: 0.5642 - val_mean_squared_error: 0.1883 - val_root_mean_squared_error: 0.4339 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 50.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.2867 - val_prc: 0.0706\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0882 - cross entropy: 0.6140 - mean_squared_error: 0.2104 - root_mean_squared_error: 0.4587 - tp: 8.0000 - fp: 65.0000 - tn: 354.0000 - fn: 77.0000 - binary_accuracy: 0.7183 - f1_score: 0.1013 - precision: 0.1096 - recall: 0.0941 - auc: 0.4037 - prc: 0.1372 - val_loss: 0.0714 - val_cross entropy: 0.5619 - val_mean_squared_error: 0.1872 - val_root_mean_squared_error: 0.4326 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 50.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.2900 - val_prc: 0.0708\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0850 - cross entropy: 0.6029 - mean_squared_error: 0.2075 - root_mean_squared_error: 0.4555 - tp: 6.0000 - fp: 65.0000 - tn: 354.0000 - fn: 79.0000 - binary_accuracy: 0.7143 - f1_score: 0.0769 - precision: 0.0845 - recall: 0.0706 - auc: 0.3963 - prc: 0.1441 - val_loss: 0.0707 - val_cross entropy: 0.5597 - val_mean_squared_error: 0.1861 - val_root_mean_squared_error: 0.4314 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 50.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.2883 - val_prc: 0.0706\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0975 - cross entropy: 0.6320 - mean_squared_error: 0.2160 - root_mean_squared_error: 0.4647 - tp: 5.0000 - fp: 66.0000 - tn: 353.0000 - fn: 80.0000 - binary_accuracy: 0.7103 - f1_score: 0.0641 - precision: 0.0704 - recall: 0.0588 - auc: 0.3744 - prc: 0.1255 - val_loss: 0.0698 - val_cross entropy: 0.5570 - val_mean_squared_error: 0.1848 - val_root_mean_squared_error: 0.4299 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 50.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.2933 - val_prc: 0.0710\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0870 - cross entropy: 0.6087 - mean_squared_error: 0.2084 - root_mean_squared_error: 0.4565 - tp: 9.0000 - fp: 62.0000 - tn: 357.0000 - fn: 76.0000 - binary_accuracy: 0.7262 - f1_score: 0.1154 - precision: 0.1268 - recall: 0.1059 - auc: 0.4039 - prc: 0.1412 - val_loss: 0.0691 - val_cross entropy: 0.5544 - val_mean_squared_error: 0.1836 - val_root_mean_squared_error: 0.4284 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 50.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.2933 - val_prc: 0.0710\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0865 - cross entropy: 0.6102 - mean_squared_error: 0.2084 - root_mean_squared_error: 0.4565 - tp: 6.0000 - fp: 50.0000 - tn: 369.0000 - fn: 79.0000 - binary_accuracy: 0.7440 - f1_score: 0.0851 - precision: 0.1071 - recall: 0.0706 - auc: 0.3955 - prc: 0.1383 - val_loss: 0.0683 - val_cross entropy: 0.5519 - val_mean_squared_error: 0.1824 - val_root_mean_squared_error: 0.4271 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 50.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.2933 - val_prc: 0.0710\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0820 - cross entropy: 0.5989 - mean_squared_error: 0.2024 - root_mean_squared_error: 0.4498 - tp: 5.0000 - fp: 43.0000 - tn: 376.0000 - fn: 80.0000 - binary_accuracy: 0.7560 - f1_score: 0.0752 - precision: 0.1042 - recall: 0.0588 - auc: 0.4073 - prc: 0.1345 - val_loss: 0.0677 - val_cross entropy: 0.5498 - val_mean_squared_error: 0.1814 - val_root_mean_squared_error: 0.4259 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 50.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.2983 - val_prc: 0.0715\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0818 - cross entropy: 0.5957 - mean_squared_error: 0.2014 - root_mean_squared_error: 0.4488 - tp: 6.0000 - fp: 45.0000 - tn: 374.0000 - fn: 79.0000 - binary_accuracy: 0.7540 - f1_score: 0.0882 - precision: 0.1176 - recall: 0.0706 - auc: 0.4215 - prc: 0.1381 - val_loss: 0.0670 - val_cross entropy: 0.5475 - val_mean_squared_error: 0.1803 - val_root_mean_squared_error: 0.4246 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 50.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.3033 - val_prc: 0.0719\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0820 - cross entropy: 0.5915 - mean_squared_error: 0.2022 - root_mean_squared_error: 0.4496 - tp: 4.0000 - fp: 45.0000 - tn: 374.0000 - fn: 81.0000 - binary_accuracy: 0.7500 - f1_score: 0.0597 - precision: 0.0816 - recall: 0.0471 - auc: 0.3972 - prc: 0.1301 - val_loss: 0.0663 - val_cross entropy: 0.5452 - val_mean_squared_error: 0.1793 - val_root_mean_squared_error: 0.4234 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 50.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.3067 - val_prc: 0.0722\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0810 - cross entropy: 0.5956 - mean_squared_error: 0.2014 - root_mean_squared_error: 0.4488 - tp: 5.0000 - fp: 47.0000 - tn: 372.0000 - fn: 80.0000 - binary_accuracy: 0.7480 - f1_score: 0.0730 - precision: 0.0962 - recall: 0.0588 - auc: 0.4180 - prc: 0.1373 - val_loss: 0.0656 - val_cross entropy: 0.5430 - val_mean_squared_error: 0.1782 - val_root_mean_squared_error: 0.4222 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 50.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.3100 - val_prc: 0.0723\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0799 - cross entropy: 0.5895 - mean_squared_error: 0.2002 - root_mean_squared_error: 0.4474 - tp: 5.0000 - fp: 39.0000 - tn: 380.0000 - fn: 80.0000 - binary_accuracy: 0.7639 - f1_score: 0.0775 - precision: 0.1136 - recall: 0.0588 - auc: 0.4046 - prc: 0.1343 - val_loss: 0.0650 - val_cross entropy: 0.5409 - val_mean_squared_error: 0.1772 - val_root_mean_squared_error: 0.4210 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 50.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.3117 - val_prc: 0.0724\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0773 - cross entropy: 0.5844 - mean_squared_error: 0.1970 - root_mean_squared_error: 0.4438 - tp: 4.0000 - fp: 33.0000 - tn: 386.0000 - fn: 81.0000 - binary_accuracy: 0.7738 - f1_score: 0.0656 - precision: 0.1081 - recall: 0.0471 - auc: 0.4205 - prc: 0.1434 - val_loss: 0.0645 - val_cross entropy: 0.5393 - val_mean_squared_error: 0.1765 - val_root_mean_squared_error: 0.4201 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 50.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.3183 - val_prc: 0.0732\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0808 - cross entropy: 0.5892 - mean_squared_error: 0.1982 - root_mean_squared_error: 0.4452 - tp: 3.0000 - fp: 35.0000 - tn: 384.0000 - fn: 82.0000 - binary_accuracy: 0.7679 - f1_score: 0.0488 - precision: 0.0789 - recall: 0.0353 - auc: 0.4229 - prc: 0.1379 - val_loss: 0.0639 - val_cross entropy: 0.5372 - val_mean_squared_error: 0.1755 - val_root_mean_squared_error: 0.4189 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 50.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.3233 - val_prc: 0.0736\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0787 - cross entropy: 0.5831 - mean_squared_error: 0.1952 - root_mean_squared_error: 0.4419 - tp: 7.0000 - fp: 38.0000 - tn: 381.0000 - fn: 78.0000 - binary_accuracy: 0.7698 - f1_score: 0.1077 - precision: 0.1556 - recall: 0.0824 - auc: 0.4526 - prc: 0.1566 - val_loss: 0.0634 - val_cross entropy: 0.5354 - val_mean_squared_error: 0.1746 - val_root_mean_squared_error: 0.4179 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 50.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.3300 - val_prc: 0.0741\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0753 - cross entropy: 0.5726 - mean_squared_error: 0.1915 - root_mean_squared_error: 0.4376 - tp: 8.0000 - fp: 29.0000 - tn: 390.0000 - fn: 77.0000 - binary_accuracy: 0.7897 - f1_score: 0.1311 - precision: 0.2162 - recall: 0.0941 - auc: 0.4741 - prc: 0.1842 - val_loss: 0.0628 - val_cross entropy: 0.5335 - val_mean_squared_error: 0.1737 - val_root_mean_squared_error: 0.4168 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 50.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.3367 - val_prc: 0.0748\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0744 - cross entropy: 0.5701 - mean_squared_error: 0.1902 - root_mean_squared_error: 0.4361 - tp: 6.0000 - fp: 27.0000 - tn: 392.0000 - fn: 79.0000 - binary_accuracy: 0.7897 - f1_score: 0.1017 - precision: 0.1818 - recall: 0.0706 - auc: 0.4544 - prc: 0.1646 - val_loss: 0.0623 - val_cross entropy: 0.5320 - val_mean_squared_error: 0.1730 - val_root_mean_squared_error: 0.4159 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 50.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.3450 - val_prc: 0.0757\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0714 - cross entropy: 0.5573 - mean_squared_error: 0.1859 - root_mean_squared_error: 0.4312 - tp: 7.0000 - fp: 29.0000 - tn: 390.0000 - fn: 78.0000 - binary_accuracy: 0.7877 - f1_score: 0.1157 - precision: 0.1944 - recall: 0.0824 - auc: 0.5094 - prc: 0.1953 - val_loss: 0.0618 - val_cross entropy: 0.5302 - val_mean_squared_error: 0.1722 - val_root_mean_squared_error: 0.4149 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 50.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.3417 - val_prc: 0.0753\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0753 - cross entropy: 0.5619 - mean_squared_error: 0.1877 - root_mean_squared_error: 0.4332 - tp: 6.0000 - fp: 22.0000 - tn: 397.0000 - fn: 79.0000 - binary_accuracy: 0.7996 - f1_score: 0.1062 - precision: 0.2143 - recall: 0.0706 - auc: 0.4902 - prc: 0.1669 - val_loss: 0.0613 - val_cross entropy: 0.5285 - val_mean_squared_error: 0.1714 - val_root_mean_squared_error: 0.4139 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 50.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.3467 - val_prc: 0.0760\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0718 - cross entropy: 0.5583 - mean_squared_error: 0.1867 - root_mean_squared_error: 0.4321 - tp: 5.0000 - fp: 28.0000 - tn: 391.0000 - fn: 80.0000 - binary_accuracy: 0.7857 - f1_score: 0.0847 - precision: 0.1515 - recall: 0.0588 - auc: 0.4828 - prc: 0.1589 - val_loss: 0.0608 - val_cross entropy: 0.5264 - val_mean_squared_error: 0.1704 - val_root_mean_squared_error: 0.4128 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 50.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.3550 - val_prc: 0.0769\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0671 - cross entropy: 0.5425 - mean_squared_error: 0.1791 - root_mean_squared_error: 0.4233 - tp: 9.0000 - fp: 17.0000 - tn: 402.0000 - fn: 76.0000 - binary_accuracy: 0.8155 - f1_score: 0.1622 - precision: 0.3462 - recall: 0.1059 - auc: 0.5241 - prc: 0.2204 - val_loss: 0.0603 - val_cross entropy: 0.5249 - val_mean_squared_error: 0.1697 - val_root_mean_squared_error: 0.4119 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 50.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.3700 - val_prc: 0.0798\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0677 - cross entropy: 0.5418 - mean_squared_error: 0.1793 - root_mean_squared_error: 0.4234 - tp: 8.0000 - fp: 24.0000 - tn: 395.0000 - fn: 77.0000 - binary_accuracy: 0.7996 - f1_score: 0.1368 - precision: 0.2500 - recall: 0.0941 - auc: 0.5229 - prc: 0.1986 - val_loss: 0.0599 - val_cross entropy: 0.5230 - val_mean_squared_error: 0.1688 - val_root_mean_squared_error: 0.4108 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 50.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.3783 - val_prc: 0.0811\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0675 - cross entropy: 0.5431 - mean_squared_error: 0.1811 - root_mean_squared_error: 0.4255 - tp: 9.0000 - fp: 22.0000 - tn: 397.0000 - fn: 76.0000 - binary_accuracy: 0.8056 - f1_score: 0.1552 - precision: 0.2903 - recall: 0.1059 - auc: 0.5141 - prc: 0.1938 - val_loss: 0.0594 - val_cross entropy: 0.5213 - val_mean_squared_error: 0.1680 - val_root_mean_squared_error: 0.4099 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 50.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.3867 - val_prc: 0.0827\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0708 - cross entropy: 0.5544 - mean_squared_error: 0.1826 - root_mean_squared_error: 0.4273 - tp: 2.0000 - fp: 23.0000 - tn: 396.0000 - fn: 83.0000 - binary_accuracy: 0.7897 - f1_score: 0.0364 - precision: 0.0800 - recall: 0.0235 - auc: 0.4914 - prc: 0.1667 - val_loss: 0.0590 - val_cross entropy: 0.5197 - val_mean_squared_error: 0.1673 - val_root_mean_squared_error: 0.4090 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 50.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.3917 - val_prc: 0.0839\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0633 - cross entropy: 0.5272 - mean_squared_error: 0.1731 - root_mean_squared_error: 0.4160 - tp: 9.0000 - fp: 11.0000 - tn: 408.0000 - fn: 76.0000 - binary_accuracy: 0.8274 - f1_score: 0.1714 - precision: 0.4500 - recall: 0.1059 - auc: 0.5561 - prc: 0.2380 - val_loss: 0.0585 - val_cross entropy: 0.5182 - val_mean_squared_error: 0.1665 - val_root_mean_squared_error: 0.4081 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 50.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.3917 - val_prc: 0.0839\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0660 - cross entropy: 0.5330 - mean_squared_error: 0.1765 - root_mean_squared_error: 0.4202 - tp: 6.0000 - fp: 19.0000 - tn: 400.0000 - fn: 79.0000 - binary_accuracy: 0.8056 - f1_score: 0.1091 - precision: 0.2400 - recall: 0.0706 - auc: 0.5344 - prc: 0.1843 - val_loss: 0.0581 - val_cross entropy: 0.5165 - val_mean_squared_error: 0.1658 - val_root_mean_squared_error: 0.4072 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 50.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4000 - val_prc: 0.0887\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0687 - cross entropy: 0.5438 - mean_squared_error: 0.1803 - root_mean_squared_error: 0.4247 - tp: 5.0000 - fp: 21.0000 - tn: 398.0000 - fn: 80.0000 - binary_accuracy: 0.7996 - f1_score: 0.0901 - precision: 0.1923 - recall: 0.0588 - auc: 0.5060 - prc: 0.1673 - val_loss: 0.0577 - val_cross entropy: 0.5148 - val_mean_squared_error: 0.1650 - val_root_mean_squared_error: 0.4062 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 50.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4100 - val_prc: 0.0900\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0661 - cross entropy: 0.5352 - mean_squared_error: 0.1775 - root_mean_squared_error: 0.4213 - tp: 4.0000 - fp: 27.0000 - tn: 392.0000 - fn: 81.0000 - binary_accuracy: 0.7857 - f1_score: 0.0690 - precision: 0.1290 - recall: 0.0471 - auc: 0.5321 - prc: 0.1747 - val_loss: 0.0572 - val_cross entropy: 0.5130 - val_mean_squared_error: 0.1642 - val_root_mean_squared_error: 0.4052 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 50.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4150 - val_prc: 0.0906\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0653 - cross entropy: 0.5336 - mean_squared_error: 0.1759 - root_mean_squared_error: 0.4193 - tp: 2.0000 - fp: 22.0000 - tn: 397.0000 - fn: 83.0000 - binary_accuracy: 0.7917 - f1_score: 0.0367 - precision: 0.0833 - recall: 0.0235 - auc: 0.5304 - prc: 0.1803 - val_loss: 0.0568 - val_cross entropy: 0.5113 - val_mean_squared_error: 0.1634 - val_root_mean_squared_error: 0.4043 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 50.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4183 - val_prc: 0.0930\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0661 - cross entropy: 0.5317 - mean_squared_error: 0.1749 - root_mean_squared_error: 0.4182 - tp: 7.0000 - fp: 17.0000 - tn: 402.0000 - fn: 78.0000 - binary_accuracy: 0.8115 - f1_score: 0.1284 - precision: 0.2917 - recall: 0.0824 - auc: 0.5554 - prc: 0.2217 - val_loss: 0.0564 - val_cross entropy: 0.5098 - val_mean_squared_error: 0.1627 - val_root_mean_squared_error: 0.4034 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 50.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4183 - val_prc: 0.0930\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0663 - cross entropy: 0.5362 - mean_squared_error: 0.1778 - root_mean_squared_error: 0.4217 - tp: 5.0000 - fp: 16.0000 - tn: 403.0000 - fn: 80.0000 - binary_accuracy: 0.8095 - f1_score: 0.0943 - precision: 0.2381 - recall: 0.0588 - auc: 0.5152 - prc: 0.1747 - val_loss: 0.0560 - val_cross entropy: 0.5081 - val_mean_squared_error: 0.1620 - val_root_mean_squared_error: 0.4024 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 50.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4317 - val_prc: 0.0955\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0579 - cross entropy: 0.5030 - mean_squared_error: 0.1648 - root_mean_squared_error: 0.4060 - tp: 7.0000 - fp: 16.0000 - tn: 403.0000 - fn: 78.0000 - binary_accuracy: 0.8135 - f1_score: 0.1296 - precision: 0.3043 - recall: 0.0824 - auc: 0.5955 - prc: 0.2334 - val_loss: 0.0556 - val_cross entropy: 0.5064 - val_mean_squared_error: 0.1612 - val_root_mean_squared_error: 0.4015 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 50.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4367 - val_prc: 0.0963\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0590 - cross entropy: 0.5070 - mean_squared_error: 0.1645 - root_mean_squared_error: 0.4055 - tp: 6.0000 - fp: 16.0000 - tn: 403.0000 - fn: 79.0000 - binary_accuracy: 0.8115 - f1_score: 0.1121 - precision: 0.2727 - recall: 0.0706 - auc: 0.6099 - prc: 0.2192 - val_loss: 0.0552 - val_cross entropy: 0.5049 - val_mean_squared_error: 0.1605 - val_root_mean_squared_error: 0.4006 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 50.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4450 - val_prc: 0.0975\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0596 - cross entropy: 0.5105 - mean_squared_error: 0.1679 - root_mean_squared_error: 0.4097 - tp: 4.0000 - fp: 16.0000 - tn: 403.0000 - fn: 81.0000 - binary_accuracy: 0.8075 - f1_score: 0.0762 - precision: 0.2000 - recall: 0.0471 - auc: 0.5662 - prc: 0.1868 - val_loss: 0.0548 - val_cross entropy: 0.5035 - val_mean_squared_error: 0.1599 - val_root_mean_squared_error: 0.3999 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 50.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4550 - val_prc: 0.0986\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0585 - cross entropy: 0.5053 - mean_squared_error: 0.1653 - root_mean_squared_error: 0.4066 - tp: 7.0000 - fp: 11.0000 - tn: 408.0000 - fn: 78.0000 - binary_accuracy: 0.8234 - f1_score: 0.1359 - precision: 0.3889 - recall: 0.0824 - auc: 0.5857 - prc: 0.2408 - val_loss: 0.0545 - val_cross entropy: 0.5020 - val_mean_squared_error: 0.1592 - val_root_mean_squared_error: 0.3990 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 50.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4617 - val_prc: 0.1004\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0598 - cross entropy: 0.5071 - mean_squared_error: 0.1662 - root_mean_squared_error: 0.4077 - tp: 7.0000 - fp: 20.0000 - tn: 399.0000 - fn: 78.0000 - binary_accuracy: 0.8056 - f1_score: 0.1250 - precision: 0.2593 - recall: 0.0824 - auc: 0.6076 - prc: 0.2246 - val_loss: 0.0541 - val_cross entropy: 0.5004 - val_mean_squared_error: 0.1585 - val_root_mean_squared_error: 0.3981 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 50.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4650 - val_prc: 0.1013\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0608 - cross entropy: 0.5100 - mean_squared_error: 0.1669 - root_mean_squared_error: 0.4085 - tp: 7.0000 - fp: 21.0000 - tn: 398.0000 - fn: 78.0000 - binary_accuracy: 0.8036 - f1_score: 0.1239 - precision: 0.2500 - recall: 0.0824 - auc: 0.5806 - prc: 0.2217 - val_loss: 0.0536 - val_cross entropy: 0.4983 - val_mean_squared_error: 0.1576 - val_root_mean_squared_error: 0.3970 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 50.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4633 - val_prc: 0.1023\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0576 - cross entropy: 0.4997 - mean_squared_error: 0.1634 - root_mean_squared_error: 0.4042 - tp: 4.0000 - fp: 15.0000 - tn: 404.0000 - fn: 81.0000 - binary_accuracy: 0.8095 - f1_score: 0.0769 - precision: 0.2105 - recall: 0.0471 - auc: 0.6080 - prc: 0.2293 - val_loss: 0.0532 - val_cross entropy: 0.4965 - val_mean_squared_error: 0.1568 - val_root_mean_squared_error: 0.3959 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 50.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4667 - val_prc: 0.1030\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0573 - cross entropy: 0.4990 - mean_squared_error: 0.1622 - root_mean_squared_error: 0.4027 - tp: 5.0000 - fp: 18.0000 - tn: 401.0000 - fn: 80.0000 - binary_accuracy: 0.8056 - f1_score: 0.0926 - precision: 0.2174 - recall: 0.0588 - auc: 0.5981 - prc: 0.2339 - val_loss: 0.0529 - val_cross entropy: 0.4949 - val_mean_squared_error: 0.1561 - val_root_mean_squared_error: 0.3951 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 50.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4750 - val_prc: 0.1043\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0562 - cross entropy: 0.4926 - mean_squared_error: 0.1600 - root_mean_squared_error: 0.4001 - tp: 6.0000 - fp: 16.0000 - tn: 403.0000 - fn: 79.0000 - binary_accuracy: 0.8115 - f1_score: 0.1121 - precision: 0.2727 - recall: 0.0706 - auc: 0.6254 - prc: 0.2382 - val_loss: 0.0525 - val_cross entropy: 0.4934 - val_mean_squared_error: 0.1554 - val_root_mean_squared_error: 0.3942 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 50.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4750 - val_prc: 0.1051\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0564 - cross entropy: 0.4973 - mean_squared_error: 0.1610 - root_mean_squared_error: 0.4013 - tp: 0.0000e+00 - fp: 11.0000 - tn: 408.0000 - fn: 85.0000 - binary_accuracy: 0.8095 - f1_score: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6183 - prc: 0.2186 - val_loss: 0.0522 - val_cross entropy: 0.4918 - val_mean_squared_error: 0.1547 - val_root_mean_squared_error: 0.3933 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 50.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4800 - val_prc: 0.1071\n"
     ]
    }
   ],
   "source": [
    "# Begin the search\n",
    "EPOCHS = 100\n",
    "\n",
    "tuner.search(\n",
    "    input_train_scaled,\n",
    "    label_train_scaled,\n",
    "    epochs=EPOCHS,\n",
    "    validation_split=0.1\n",
    ")\n",
    "\n",
    "# Query the tuner object to grab the best models\n",
    "models = tuner.get_best_models(num_models=5)\n",
    "\n",
    "# Here is the best model from the tuner\n",
    "best_model = models[0]\n",
    "print(best_model.summary())\n",
    "\n",
    "# Get the top hyperparameters.\n",
    "best_hps = tuner.get_best_hyperparameters()\n",
    "\n",
    "# Build the model with the best hyperparameters.\n",
    "# Assuming your MyHyperModel has a build method that takes a hyperparameter object.\n",
    "model = MyHyperModel().build(best_hps[0])\n",
    "\n",
    "# Save the best model (architecture and weights)\n",
    "\n",
    "save_dir = \"/glade/derecho/scratch/rmandava/AEW_time_location_files/models\"\n",
    "model_save_path = os.path.join(save_dir, model_save_name)\n",
    "\n",
    "model.save(model_save_path)\n",
    "\n",
    "\n",
    "# Retrain using \"best\" model hyperparameters\n",
    "history = model.fit(\n",
    "    input_train_scaled,\n",
    "    label_train_scaled,\n",
    "    epochs=EPOCHS,\n",
    "    validation_split=0.1,\n",
    "    batch_size= 32,\n",
    "    # callbacks=keras.callbacks.EarlyStopping('val_loss', patience=3),\n",
    "    shuffle=True,\n",
    "    class_weight=class_weight,  # Ensure 'class_weight' is defined in your scope\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test data using `evaluate`\n",
    "results = model.evaluate(input_test_scaled, label_test_scaled, batch_size=label_test_scaled.shape[0])\n",
    "print(results)\n",
    "\n",
    "# Generate predictions (probabilitiesthe output of the last layer)\n",
    "predictions = model.predict(input_test_scaled)\n",
    "print(\"predictions shape:\", predictions.shape)\n",
    "\n",
    "# Compute confusion matrix elements\n",
    "tn, fp, fn, tp = sklearn.metrics.confusion_matrix(\n",
    "    label_test_scaled, np.round(predictions)\n",
    ").ravel()\n",
    "print(\"tn:\", tn)\n",
    "print(\"fp:\", fp)\n",
    "print(\"fn:\", fn)\n",
    "print(\"tp:\", tp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8883c1-4450-444a-88a5-18ed3d94d588",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Ensemble top K models  \n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "# 1) Grab the top K hyperparameters\n",
    "top_hps = tuner.get_best_hyperparameters(num_trials=5)\n",
    "\n",
    "# 2) Rebuild each best model\n",
    "models = [ MyHyperModel().build(hp) for hp in top_hps ]\n",
    "# (Or, if you saved weights per trial, load them here onto each model.)\n",
    "\n",
    "# 3) Run each model on the test set\n",
    "all_preds = np.stack([m.predict(input_test_scaled).flatten() for m in models], axis=0)\n",
    "\n",
    "# 4) Average their probabilities & threshold\n",
    "ensemble_probs = all_preds.mean(axis=0)\n",
    "ensemble_preds = (ensemble_probs >= 0.5).astype(int)\n",
    "\n",
    "# 5) Compute & print ensemble F1\n",
    "print(\"Ensemble F1:\", f1_score(label_test_scaled, ensemble_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d463e2-12e7-474b-95c1-ae20c22a093c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = np.round(predictions.flatten())\n",
    "true_labels = label_test_scaled.flatten()\n",
    "false_neg_idx = np.where((true_labels == 1) & (pred_labels == 0))[0]\n",
    "false_pos_idx = np.where((true_labels == 0) & (pred_labels == 1))[0]\n",
    "true_pos_idx = np.where((true_labels == 1) & (pred_labels == 1))[0]\n",
    "true_neg_idx = np.where((true_labels == 0) & (pred_labels == 0))[0]\n",
    "\n",
    "print(\"Number of false negatives:\", len(false_neg_idx))\n",
    "print(\"Number of false positives:\", len(false_pos_idx))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6ddefd-a847-4a5c-a028-ca25e1e1d87c",
   "metadata": {
    "papermill": {
     "duration": 0.042059,
     "end_time": "2025-03-05T20:46:02.526276",
     "exception": false,
     "start_time": "2025-03-05T20:46:02.484217",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming lat_test and lon_test are arrays with shape (num_samples, height, width)\n",
    "#central_lat = lat_test[:, lat_test.shape[1]//2, lat_test.shape[2]//2]\n",
    "#central_lon = lon_test[:, lon_test.shape[1]//2, lon_test.shape[2]//2]\n",
    "\n",
    "#lats_false_neg = central_lat[false_neg_idx]\n",
    "#lons_false_neg = central_lon[false_neg_idx]\n",
    "\n",
    "#lats_false_pos = central_lat[false_pos_idx]\n",
    "#lons_false_pos = central_lon[false_pos_idx]\n",
    "# Assuming lat_test and lon_test are 1D arrays with one coordinate per sample\n",
    "lat_false_neg = lat_test[false_neg_idx]\n",
    "lon_false_neg = lon_test[false_neg_idx]\n",
    "\n",
    "lat_false_pos = lat_test[false_pos_idx]\n",
    "lon_false_pos = lon_test[false_pos_idx]\n",
    "\n",
    "lat_true_pos = lat_test[true_pos_idx]\n",
    "lon_true_pos = lon_test[true_pos_idx]\n",
    "\n",
    "lat_true_neg = lat_test[true_neg_idx]\n",
    "lon_true_neg = lon_test[true_neg_idx]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798796b5-b155-48c8-bd46-4c1a1f5fedba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Unique latitudes in test set:\", np.unique(lat_test))\n",
    "print(\"Unique longitudes in test set:\", np.unique(lon_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0f4581-4248-48f1-bd51-5d4bb476f030",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(lon_false_neg, lat_false_neg, marker='x', color='red', label='False Negatives')\n",
    "plt.scatter(lon_false_pos, lat_false_pos, marker='o', color='blue', label='False Positives')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.title('Geographic Distribution of Misclassifications')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f3eb33-d853-48b3-8416-46e48cd99444",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512e75d1-8ea6-4a7e-90c9-aaf6ad6d5a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "\n",
    "\n",
    "\n",
    "lon_min, lon_max = np.min(lon_test)-15, np.max(lon_test)+15\n",
    "lat_min, lat_max = np.min(lat_test)-15, np.max(lat_test)+15\n",
    "ax.set_extent([lon_min, lon_max, lat_min, lat_max], crs=ccrs.PlateCarree())\n",
    "\n",
    "# Add map features\n",
    "ax.add_feature(cfeature.COASTLINE, linewidth=0.5)\n",
    "ax.add_feature(cfeature.BORDERS, linestyle=':', linewidth=0.5)\n",
    "ax.add_feature(cfeature.LAND, edgecolor='black', facecolor='lightgray')\n",
    "ax.add_feature(cfeature.OCEAN, facecolor='lightblue')\n",
    "\n",
    "# Plot misclassified points:\n",
    "ax.scatter(lon_false_neg, lat_false_neg, color='red', marker='x', s=100,\n",
    "           transform=ccrs.PlateCarree(), label='False Negatives')\n",
    "ax.scatter(lon_false_pos, lat_false_pos, color='blue', marker='o', s=100,\n",
    "           transform=ccrs.PlateCarree(), label='False Positives')\n",
    "\n",
    "plt.title(\"Misclassified Test Samples on Map\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4561912c-9788-442a-a527-f125871dbce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "\n",
    "# Set map extent (adjust margins as desired)\n",
    "lon_min, lon_max = np.min(lon_test) - 10, np.max(lon_test) + 10\n",
    "lat_min, lat_max = np.min(lat_test) - 10, np.max(lat_test) + 10\n",
    "ax.set_extent([lon_min, lon_max, lat_min, lat_max], crs=ccrs.PlateCarree())\n",
    "\n",
    "# Add map features\n",
    "ax.add_feature(cfeature.COASTLINE, linewidth=0.5)\n",
    "ax.add_feature(cfeature.BORDERS, linestyle=':', linewidth=0.5)\n",
    "ax.add_feature(cfeature.LAND, facecolor='lightgray', edgecolor='black')\n",
    "ax.add_feature(cfeature.OCEAN, facecolor='lightblue')\n",
    "# Plot misclassified points\n",
    "ax.scatter(lon_false_neg, lat_false_neg, color='red', marker='x', s=100,\n",
    "           transform=ccrs.PlateCarree(), label='False Negatives')\n",
    "ax.scatter(lon_false_pos, lat_false_pos, color='blue', marker='o', s=100,\n",
    "           transform=ccrs.PlateCarree(), label='False Positives')\n",
    "\n",
    "\n",
    "\n",
    "# Plot correctly classified points\n",
    "ax.scatter(lon_true_pos, lat_true_pos, color='green', marker='^', s=100,\n",
    "           transform=ccrs.PlateCarree(), label='True Positives')\n",
    "ax.scatter(lon_true_neg, lat_true_neg, color='orange', marker='s', s=100,\n",
    "           transform=ccrs.PlateCarree(), label='True Negatives')\n",
    "\n",
    "plt.title(\"Test Set Classification Results on Map\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffe393f-a6c9-440d-b648-78010a1d0ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total samples:\", len(sample_lat))\n",
    "print(\"Unique latitudes:\", len(np.unique(sample_lat)))\n",
    "print(\"Unique longitudes:\", len(np.unique(sample_lon)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e932dda-37e1-4158-8655-7d2a041a1a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First 10 latitudes:\", sample_lat[:10])\n",
    "print(\"First 10 longitudes:\", sample_lon[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe686778-d179-4dec-8b2e-472700d70e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(sample_lon, sample_lat, c='green', marker='o')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.title('Per-Sample Weighted Centroid Coordinates')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5563a928-7d7f-402d-94e1-63dd0cff0982",
   "metadata": {
    "papermill": {
     "duration": 13.848113,
     "end_time": "2025-03-05T20:46:16.415723",
     "exception": false,
     "start_time": "2025-03-05T20:46:02.567610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# --- Permutation Importance ---\n",
    "# Evaluate baseline performance using your loss metric (here, the custom f1_loss_sigmoid)\n",
    "# model.metrics_names gives a list where index 0 is 'loss'\n",
    "baseline_results = model.evaluate(input_test_scaled, label_test_scaled,\n",
    "                                  batch_size=label_test_scaled.shape[0],\n",
    "                                  verbose=0)\n",
    "baseline_loss = baseline_results[model.metrics_names.index('loss')]\n",
    "print(\"Baseline loss:\", baseline_loss)\n",
    "\n",
    "# Set the number of repetitions for averaging\n",
    "n_repeats = 5\n",
    "n_features = input_test_scaled.shape[-1]\n",
    "permutation_importances = np.zeros(n_features)\n",
    "\n",
    "# Loop over each feature (channel)\n",
    "for feature_idx in range(n_features):\n",
    "    permuted_losses = []\n",
    "    for _ in range(n_repeats):\n",
    "        # Copy the test set to avoid modifying the original\n",
    "        X_permuted = np.copy(input_test_scaled)\n",
    "        # Permute the values of the selected feature across samples\n",
    "        perm = np.random.permutation(X_permuted.shape[0])\n",
    "        X_permuted[:, :, :, feature_idx] = X_permuted[perm, :, :, feature_idx]\n",
    "        \n",
    "        # Evaluate the model on the permuted test set\n",
    "        permuted_results = model.evaluate(X_permuted, label_test_scaled,\n",
    "                                          batch_size=label_test_scaled.shape[0],\n",
    "                                          verbose=0)\n",
    "        permuted_loss = permuted_results[model.metrics_names.index('loss')]\n",
    "        permuted_losses.append(permuted_loss)\n",
    "    \n",
    "    avg_permuted_loss = np.mean(permuted_losses)\n",
    "    # The difference between the permuted loss and baseline loss indicates feature importance:\n",
    "    # A larger increase means the feature is more important.\n",
    "    permutation_importances[feature_idx] = avg_permuted_loss - baseline_loss\n",
    "    print(f\"Feature {feature_idx} - Increase in Loss: {permutation_importances[feature_idx]}\")\n",
    "\n",
    "print(\"Permutation Importances (increase in loss) for all features:\", permutation_importances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23e4f15-e79e-4040-b328-2096906415f9",
   "metadata": {
    "papermill": {
     "duration": 0.467125,
     "end_time": "2025-03-05T20:46:16.925109",
     "exception": false,
     "start_time": "2025-03-05T20:46:16.457984",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Suppose permutation_importances is the numpy array you printed:\n",
    "# e.g., [0.0820, 0.0824, 0.0815, 0.0864, 0.0121, ...]\n",
    "\n",
    "feature_indices = np.arange(len(permutation_importances))\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(feature_indices, permutation_importances)\n",
    "plt.xlabel(\"Feature Index\")\n",
    "plt.ylabel(\"Increase in Loss (Permutation Importance)\")\n",
    "plt.title(\"Permutation Importance by Feature\")\n",
    "plt.xticks(feature_indices, [f\"F{i}\" for i in feature_indices], rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1765f8b0-69ed-4917-82f7-f15ef12cc837",
   "metadata": {
    "papermill": {
     "duration": 0.043518,
     "end_time": "2025-03-05T20:46:17.012058",
     "exception": false,
     "start_time": "2025-03-05T20:46:16.968540",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_index = 0\n",
    "sample_input = input_test_scaled[sample_index:sample_index+1]\n",
    "\n",
    "# Compute the saliency map for the selected test sample\n",
    "saliency_map = compute_saliency_map(model, sample_input)\n",
    "\n",
    "# Plot the saliency map\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(saliency_map, cmap='hot')\n",
    "plt.colorbar()\n",
    "plt.title(f\"Saliency Map for Sample Index {sample_index}\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa54c93-f08a-46e2-a610-95424eb79806",
   "metadata": {
    "papermill": {
     "duration": 0.042628,
     "end_time": "2025-03-05T20:46:17.098037",
     "exception": false,
     "start_time": "2025-03-05T20:46:17.055409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_index = 1\n",
    "sample_input = input_test_scaled[sample_index:sample_index+1]\n",
    "\n",
    "# Compute saliency maps per channel for the selected input sample\n",
    "saliency_maps, channel_importance = compute_saliency_per_channel(model, sample_input)\n",
    "\n",
    "# Plot the saliency maps for each channel\n",
    "num_channels = saliency_maps.shape[-1]\n",
    "cols = 5  # Set number of columns for plotting\n",
    "rows = int(np.ceil(num_channels / cols))\n",
    "plt.figure(figsize=(15, rows * 3))\n",
    "for c in range(num_channels):\n",
    "    plt.subplot(rows, cols, c + 1)\n",
    "    plt.imshow(saliency_maps[:, :, c], cmap='hot')\n",
    "    plt.title(f'Channel {c}\\nMean: {channel_importance[c]:.4f}')\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print aggregated channel importance values\n",
    "print(\"Channel importance (mean saliency per channel):\")\n",
    "for c, imp in enumerate(channel_importance):\n",
    "    print(f\"Channel {c}: {imp:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfec3979-63a3-4211-9475-3445ad530009",
   "metadata": {
    "papermill": {
     "duration": 0.043201,
     "end_time": "2025-03-05T20:46:17.184585",
     "exception": false,
     "start_time": "2025-03-05T20:46:17.141384",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1) Compute persample, perchannel saliency importances\n",
    "all_imps = []\n",
    "for x in input_test_scaled:             # each x has shape (32,32,channels)\n",
    "    _, imp = compute_saliency_per_channel(best_model, x[np.newaxis,...])\n",
    "    all_imps.append(imp)               # imp.shape == (channels,)\n",
    "all_imps = np.stack(all_imps)          # shape (N_samples, channels)\n",
    "\n",
    "# 2) Average importance across samples\n",
    "mean_imp = all_imps.mean(axis=0)       # shape (channels,)\n",
    "\n",
    "# 3) Build a DataFrame mapping featureplevelimportance\n",
    "df = pd.DataFrame({\n",
    "    \"feature\": var_list,\n",
    "    \"plevel\": plevel_list,\n",
    "    \"importance\": mean_imp\n",
    "})\n",
    "\n",
    "# 4) Group by pressure level and plot\n",
    "grouped = df.groupby(\"plevel\")[\"importance\"].mean().reset_index()\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.bar(grouped[\"plevel\"].astype(str), grouped[\"importance\"])\n",
    "plt.xlabel(\"Pressure level (hPa or False=surface)\")\n",
    "plt.ylabel(\"Mean saliency importance\")\n",
    "plt.title(\"Average feature importance by pressure level\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f421b06b-75d2-4e23-beb0-dbb5f6c6240f",
   "metadata": {
    "papermill": {
     "duration": 0.041979,
     "end_time": "2025-03-05T20:46:17.268705",
     "exception": false,
     "start_time": "2025-03-05T20:46:17.226726",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1) Print out full testset metrics by name\n",
    "test_results = model.evaluate(\n",
    "    input_test_scaled,\n",
    "    label_test_scaled,\n",
    "    batch_size=label_test_scaled.shape[0],\n",
    "    verbose=0\n",
    ")\n",
    "print(dict(zip(model.metrics_names, test_results)))\n",
    "\n",
    "# 2) Peek at the end of your training history for F1 improvements\n",
    "import pandas as pd\n",
    "hist_df = pd.DataFrame(history.history)\n",
    "print(hist_df[['f1_score','val_f1_score']].tail())\n",
    "\n",
    "# 3) (Optional) Plot train vs. val F1 over epochs\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(hist_df['f1_score'],    label='train F1')\n",
    "plt.plot(hist_df['val_f1_score'],label='val F1')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.legend()\n",
    "plt.title('FocalLoss Training F1 Curves')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b46d58-ad34-4817-a519-c9152372b7d4",
   "metadata": {
    "papermill": {
     "duration": 0.047731,
     "end_time": "2025-03-05T20:46:17.359595",
     "exception": false,
     "start_time": "2025-03-05T20:46:17.311864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replace your rebuild logic:\n",
    "# top_hps = tuner.get_best_hyperparameters(num_trials=5)\n",
    "# models  = [MyHyperModel().build(hp) for hp in top_hps]\n",
    "\n",
    "# With this single line:\n",
    "models = tuner.get_best_models(num_models=5)\n",
    "\n",
    "# Then stack and average as before:\n",
    "all_preds     = np.stack([m.predict(input_test_scaled).flatten() for m in models], axis=0)\n",
    "ensemble_probs= all_preds.mean(axis=0)\n",
    "ensemble_preds= (ensemble_probs >= 0.5).astype(int)\n",
    "print(\"Ensemble F1:\", f1_score(label_test_scaled, ensemble_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae3ef17-24f6-4569-8095-2bdee2e67245",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d420057-7c8e-4daf-9eda-a4a3b4cf11ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcba43d-dd0b-4f79-b140-bce612bcd0b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7035.678234,
   "end_time": "2025-03-05T20:46:20.341478",
   "environment_variables": {},
   "exception": null,
   "input_path": "Hurricaneoriginal(300).ipynb",
   "output_path": "output_notebook_var(second)0.ipynb",
   "parameters": {
    "aew_subset": "12hr_before",
    "model_save_name": "best_model_var0.keras",
    "plevel_list": [
     false,
     false,
     300,
     false,
     false,
     false,
     300,
     300,
     850,
     300,
     850,
     false,
     false,
     false,
     false,
     300,
     850,
     false,
     300,
     850,
     300,
     850,
     300,
     300,
     850
    ],
    "tuner_project_name": "tuner_run(second)_0",
    "var_list": [
     "cape",
     "crr",
     "d",
     "ie",
     "ishf",
     "lsrr",
     "pv",
     "q",
     "q",
     "r",
     "r",
     "sp",
     "sstk",
     "tcw",
     "tcwv",
     "t",
     "t",
     "ttr",
     "u",
     "u",
     "v",
     "v",
     "vo",
     "w",
     "w"
    ]
   },
   "start_time": "2025-03-05T18:49:04.663244",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
