{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2203c2-df40-428c-ae4c-71b20ba050c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bf88bb8-756d-47cb-ad74-88b3b302a462",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 0.022322,
     "end_time": "2025-03-05T18:49:06.250982",
     "exception": false,
     "start_time": "2025-03-05T18:49:06.228660",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "Parameters",
     "parameters",
     "  Parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "var_list = [\"default1\", \"default2\"]\n",
    "plevel_list = [False, 300]\n",
    "aew_subset = \"default_subset\"\n",
    "model_save_name = \"default_modelbase1.keras\"\n",
    "tuner_project_name = \"default_tuner_run1\"\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6798e3f",
   "metadata": {
    "papermill": {
     "duration": 0.012789,
     "end_time": "2025-03-05T18:49:06.269446",
     "exception": false,
     "start_time": "2025-03-05T18:49:06.256657",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "# Parameters\n",
    "var_list = [\"cape\", \"crr\", \"d\", \"ie\", \"ishf\", \"lsrr\", \"pv\", \"q\",\"r\", \"sp\", \"sstk\", \"tcw\", \"tcwv\", \"t\", \"ttr\", \"u\",\"v\", \"vo\",\"w\"] #ERA5 variables\n",
    "\n",
    "\n",
    "\n",
    "plevel_list = [False, False,300, False, False, False, 300, 300, 300,False, False, False, False, 300,  False, 300,300  ,  300, 300] #pressure levels of variables\n",
    "\n",
    "aew_subset = \"12hr_before\"\n",
    "model_save_name = \"best_model_var(300)123456.keras\"\n",
    "tuner_project_name = \"tuner_run(300)123456\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe4b521-b034-49f0-a1ac-d961fe639066",
   "metadata": {
    "papermill": {
     "duration": 0.005028,
     "end_time": "2025-03-05T18:49:06.279538",
     "exception": false,
     "start_time": "2025-03-05T18:49:06.274510",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d1aa354-4561-4486-9f61-73f2c1c81a31",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 13.973479,
     "end_time": "2025-03-05T18:49:20.258119",
     "exception": false,
     "start_time": "2025-03-05T18:49:06.284640",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-29 09:43:20.367549: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-29 09:43:20.440011: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-29 09:43:20.584025: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-29 09:43:20.584102: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-29 09:43:20.590153: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-29 09:43:20.641760: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-29 09:43:20.642367: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-29 09:43:31.788598: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "# coding: utf-8\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import xarray as xr\n",
    "\n",
    "import sklearn\n",
    "\n",
    "import sklearn.model_selection\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras import layers\n",
    "\n",
    "import keras_tuner\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "keras.utils.set_random_seed(812)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32c4826e-dbc1-45c0-aca0-bc38d0254f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def focal_loss(gamma=2.0, alpha=0.25):\n",
    "    \"\"\"Focal Loss for binary classification.\"\"\"\n",
    "    def loss_fn(y_true, y_pred):\n",
    "        # Clip to prevent NaNs \n",
    "        y_pred = tf.clip_by_value(y_pred, tf.keras.backend.epsilon(), 1 - tf.keras.backend.epsilon())\n",
    "        bce = tf.keras.backend.binary_crossentropy(y_true, y_pred)\n",
    "        p_t = y_true * y_pred + (1 - y_true) * (1 - y_pred)\n",
    "        modulating_factor = tf.pow(1.0 - p_t, gamma)\n",
    "        alpha_factor = y_true * alpha + (1 - y_true) * (1 - alpha)\n",
    "        return alpha_factor * modulating_factor * bce\n",
    "    return loss_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c74c2082-8917-4d0d-a2d7-b39f8548bcbb",
   "metadata": {
    "papermill": {
     "duration": 0.014754,
     "end_time": "2025-03-05T18:49:20.282885",
     "exception": false,
     "start_time": "2025-03-05T18:49:20.268131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#functions to calculate f1 score as loss function\n",
    "\n",
    "def f1_loss_sigmoid(y_true, y_pred):\n",
    "    \"\"\"\n",
    "\n",
    "    F1 metric for sigmoid output and integer encoded labels.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    # compute tp, fp, and fn\n",
    "\n",
    "    tp = K.sum(K.cast(y_true * y_pred, 'float'), axis=0)\n",
    "\n",
    "    fp = K.sum(K.cast((1 - y_true) * y_pred, 'float'), axis=0)\n",
    "\n",
    "    fn = K.sum(K.cast(y_true * (1 - y_pred), 'float'), axis=0)\n",
    "\n",
    "\n",
    "    # precision (tp / (tp + fp))\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "\n",
    "   # recall (tp / (tp + fn))\n",
    "\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "\n",
    "# harmonic mean of precision and recall\n",
    "\n",
    "    f1 = (2 * p * r) / (p + r + K.epsilon())\n",
    "\n",
    "    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "\n",
    "    return 1 - K.mean(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58fe83a8-b5b0-4a10-81f6-a5b9277e5a3a",
   "metadata": {
    "papermill": {
     "duration": 0.012029,
     "end_time": "2025-03-05T18:49:20.300625",
     "exception": false,
     "start_time": "2025-03-05T18:49:20.288596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def f1_loss_onehot(y_true, y_pred):\n",
    "\n",
    "   \"\"\"\n",
    "\n",
    "   F1 metric for two-class output and one-hot encoded labels.\n",
    "\n",
    "   \"\"\"\n",
    "\n",
    "   # compute tp, fp, and fn\n",
    "\n",
    "   tp = K.sum(K.cast(y_true[:, 1] * y_pred[:, 1], 'float'), axis=0)\n",
    "\n",
    "   fp = K.sum(K.cast((1 - y_true[:, 1]) * y_pred[:, 1], 'float'), axis=0)\n",
    "\n",
    "   fn = K.sum(K.cast(y_true[:, 0] * (1 - y_pred[:, 0]), 'float'), axis=0)\n",
    "\n",
    "\n",
    "   # precision (tp / (tp + fp))\n",
    "\n",
    "   p = tp / (tp + fp + K.epsilon())\n",
    "\n",
    "   # recall (tp / (tp + fn))\n",
    "\n",
    "   r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "\n",
    "   # harmonic mean of precision and recall\n",
    "\n",
    "   f1 = (2 * p * r) / (p + r + K.epsilon())\n",
    "\n",
    "   f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "\n",
    "   return 1 - K.mean(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82e6df90-377d-4c27-ac1d-156b3bc34623",
   "metadata": {
    "papermill": {
     "duration": 0.012229,
     "end_time": "2025-03-05T18:49:20.319927",
     "exception": false,
     "start_time": "2025-03-05T18:49:20.307698",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def add_dim(ds):\n",
    "    # Extract the source file name from the dataset's encoding.\n",
    "    fname = ds.encoding.get('source', '')\n",
    "    # Use a regex to capture the central latitude and longitude from the filename.\n",
    "    m = re.search(r'_(\\-?\\d+\\.\\d+)_(-?\\d+\\.\\d+)\\.nc$', fname)\n",
    "    if m:\n",
    "        lat_center = float(m.group(1))\n",
    "        lon_center = float(m.group(2))\n",
    "        # Assign the central coordinates and the file name as new coordinates.\n",
    "        ds = ds.assign_coords(lat_center=lat_center, lon_center=lon_center, file_name=fname)\n",
    "    else:\n",
    "        print(\"File name does not match expected pattern:\", fname)\n",
    "    \n",
    "    # Expand dims to add the 'sample' dimension and drop unnecessary variables.\n",
    "    return ds.assign_coords({\"sample\": 1}).expand_dims(dim={\"sample\": 1}).drop_vars(\"utc_date\").drop_vars(\"latitude\").drop_vars(\"longitude\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec3de133-3ed1-4df3-9444-a58e88716284",
   "metadata": {
    "papermill": {
     "duration": 0.017203,
     "end_time": "2025-03-05T18:49:20.344038",
     "exception": false,
     "start_time": "2025-03-05T18:49:20.326835",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import xarray as xr\n",
    "\n",
    "def open_files_zarr(list_of_vars, aew_subset=\"12hr_before\",\n",
    "                    directory=\"/glade/derecho/scratch/rmandava/AEW_time_location_files/\",\n",
    "                    plevel_list=None, zarr_store_path=\"zarr_data\"):\n",
    "    \"\"\"\n",
    "    Opens ERA5 NetCDF files for the given variables. For each variable (or pressure-level variant),\n",
    "    it checks if a corresponding Zarr store exists in 'zarr_store_path'. If so, it loads the dataset\n",
    "    from the Zarr store; if not, it opens the NetCDF files, preprocesses them, saves them to Zarr,\n",
    "    and then returns the dataset.\n",
    "    \"\"\"\n",
    "    # Create the zarr_store_path directory if it doesn't exist.\n",
    "    if not os.path.exists(zarr_store_path):\n",
    "        os.makedirs(zarr_store_path)\n",
    "    \n",
    "    datas = {}\n",
    "    for num, var in enumerate(list_of_vars):\n",
    "        # Determine the key and filename based on whether a pressure level is specified.\n",
    "        if plevel_list:\n",
    "            if plevel_list[num]:\n",
    "                key = f\"{var}_{int(plevel_list[num])}\"\n",
    "                file_pattern = f'{directory}/{var}/aew_{aew_subset}_{int(plevel_list[num])}_*.nc'\n",
    "            else:\n",
    "                key = var\n",
    "                file_pattern = f'{directory}/{var}/aew_{aew_subset}_*.nc'\n",
    "        else:\n",
    "            key = var\n",
    "            file_pattern = f'{directory}/{var}/aew_{aew_subset}_*.nc'\n",
    "        \n",
    "        # Define the zarr path for this variable.\n",
    "        zarr_path = os.path.join(zarr_store_path, f\"{key}.zarr\")\n",
    "        \n",
    "        # If the Zarr dataset exists, load from it; otherwise, create it.\n",
    "        if os.path.exists(zarr_path):\n",
    "            print(f\"Loading {key} from Zarr store.\")\n",
    "            ds = xr.open_zarr(zarr_path)\n",
    "        else:\n",
    "            print(f\"Creating Zarr store for {key} from NetCDF files.\")\n",
    "            ds = xr.open_mfdataset(\n",
    "                file_pattern,\n",
    "                preprocess=add_dim,\n",
    "                concat_dim=\"sample\",\n",
    "                combine=\"nested\",\n",
    "            )\n",
    "            ds.to_zarr(zarr_path, mode=\"w\")\n",
    "        datas[key] = ds\n",
    "    \n",
    "    return datas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20c80e6-2437-4626-be0b-4d82bebb4f73",
   "metadata": {
    "papermill": {
     "duration": 0.015473,
     "end_time": "2025-03-05T18:49:20.366598",
     "exception": false,
     "start_time": "2025-03-05T18:49:20.351125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad1f231e-abc1-49e7-9bab-09ab1f3f4ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose_load_concat(data_dictionary):\n",
    "    # Instead of eagerly converting to NumPy arrays, keep the datasets as xarray objects.\n",
    "    transposed = {}\n",
    "    for key, ds in data_dictionary.items():\n",
    "        var_name = key.split('_')[0].upper()\n",
    "        # Do lazy transpose and add a 'features' dimension\n",
    "        transposed[key] = ds[var_name].expand_dims('features').transpose('sample', 'latitude', 'longitude', 'features')\n",
    "    # Concatenate along the new 'features' dimension (if multiple variables exist)\n",
    "    if len(transposed) > 1:\n",
    "        data = xr.concat(list(transposed.values()), dim='features',coords='minimal',compat='override')\n",
    "    else:\n",
    "        data = list(transposed.values())[0]\n",
    "    # Use the coordinates (lat_center, lon_center) from one of the datasets.\n",
    "    # They remain lazy and are not computed until needed.\n",
    "    first_key = next(iter(data_dictionary))\n",
    "    lat_center = data_dictionary[first_key]['lat_center']\n",
    "    lon_center = data_dictionary[first_key]['lon_center']\n",
    "    label = data_dictionary[first_key]['label']\n",
    "    return data, label, lat_center, lon_center\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bec2717c-8176-447f-82ea-5b15e038ace1",
   "metadata": {
    "papermill": {
     "duration": 0.010767,
     "end_time": "2025-03-05T18:49:20.384143",
     "exception": false,
     "start_time": "2025-03-05T18:49:20.373376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def omit_nans(data, label, lat, lon):\n",
    "    # If data is an xarray DataArray, convert it to a NumPy array\n",
    "    if hasattr(data, 'values'):\n",
    "        data = data.values\n",
    "    maskarray = np.full(data.shape[0], True)\n",
    "    # Find indices where NaNs occur\n",
    "    masker = np.unique(np.argwhere(np.isnan(data))[:, 0])\n",
    "    maskarray[masker] = False\n",
    "\n",
    "    traindata = data[maskarray, ...]\n",
    "    trainlabel = label[maskarray]\n",
    "    lat_filtered = lat[maskarray]\n",
    "    lon_filtered = lon[maskarray]\n",
    "    return traindata, trainlabel, lat_filtered, lon_filtered\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d02dbe1a-f1ba-4f9b-8fe0-d9126814ae62",
   "metadata": {
    "papermill": {
     "duration": 0.010866,
     "end_time": "2025-03-05T18:49:20.400498",
     "exception": false,
     "start_time": "2025-03-05T18:49:20.389632",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def zscore(data):\n",
    "\n",
    "  \"\"\"\n",
    "\n",
    "  Rescaling the data using zscore (mean/std).\n",
    "\n",
    "  Each variable gets scaled independently from others.\n",
    "\n",
    "  Note that we will need to remove test data for formal training.\n",
    "\n",
    "  \"\"\"\n",
    "\n",
    "  for i in range(0, data_.shape[-1]):\n",
    "\n",
    "      data_[:, :, :, i] = (\n",
    "\n",
    "               data_[:, :, :, i] - np.nanmean(\n",
    "\n",
    "                     data_[:, :, :, i])) / np.nanstd(data_[:, :, :, i])\n",
    "\n",
    "  return data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "332bc130-a4e7-465c-a135-687f543db181",
   "metadata": {
    "papermill": {
     "duration": 0.011066,
     "end_time": "2025-03-05T18:49:20.416849",
     "exception": false,
     "start_time": "2025-03-05T18:49:20.405783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def minmax(data):\n",
    "\n",
    "   \"\"\"\n",
    "\n",
    "   Rescaling the data using min-max.\n",
    "\n",
    "   Each variable gets scaled independently from others.\n",
    "\n",
    "   Note that we will need to remove test data for formal training.\n",
    "\n",
    "   \"\"\"\n",
    "\n",
    "   for i in range(0, data_.shape[-1]):\n",
    "\n",
    "          data_[:, :, :, i] = (\n",
    "\n",
    "              data_[:, :, :, i] - np.nanmin(data_[:, :, :, i])\n",
    "\n",
    "          ) / (np.nanmax(data_[:, :, :, i]) - np.nanmin(data_[:, :, :, i]))\n",
    "   return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f652c778-f81b-4c46-bf87-d60487903b73",
   "metadata": {
    "papermill": {
     "duration": 0.010904,
     "end_time": "2025-03-05T18:49:20.433062",
     "exception": false,
     "start_time": "2025-03-05T18:49:20.422158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def random_split(data, label, split=0.3, seed=0):\n",
    "\n",
    "   \"\"\"\n",
    "\n",
    "   Help spliting data randomly for training and testing.\n",
    "\n",
    "   \"\"\"\n",
    "\n",
    "   np.random.seed(0)\n",
    "\n",
    "   da_indx = np.random.permutation(data.shape[0])\n",
    "\n",
    "   data = data[da_indx.astype(int)]\n",
    "\n",
    "   label = label[da_indx.astype(int)]\n",
    "\n",
    "   init_range = int(data.shape[0] * (1 - 0.3))\n",
    "\n",
    "   return data[:init_range], label[:init_range], data[init_range:], label[init_range:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9f970b2-2444-4dba-8e66-a850482d5ea4",
   "metadata": {
    "papermill": {
     "duration": 0.010837,
     "end_time": "2025-03-05T18:49:20.449475",
     "exception": false,
     "start_time": "2025-03-05T18:49:20.438638",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pick_loss(loss_string):\n",
    "    \n",
    "\n",
    "    lossdict = {\n",
    "        \"relu\": tf.nn.relu,\n",
    "        \"tanh\": tf.nn.tanh,\n",
    "        \"selu\": tf.nn.selu,\n",
    "        \"sigmoid\": tf.nn.sigmoid,\n",
    "        \"relu6\": tf.nn.relu6,\n",
    "        \"silu\": tf.nn.silu,\n",
    "        \"gelu\": tf.nn.gelu,\n",
    "        \"lrelu\": tf.nn.leaky_relu,\n",
    "    }\n",
    "\n",
    "    return lossdict[loss_string]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3e0c99e-885a-4f64-b057-0056b0ef246f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_saliency_map(model, input_sample):\n",
    "    \"\"\"\n",
    "    Compute a saliency map for a given input sample using a gradient-based approach.\n",
    "    \n",
    "    Args:\n",
    "        model (tf.keras.Model): The trained Keras model.\n",
    "        input_sample (numpy array): A single input sample of shape (1, height, width, channels).\n",
    "    \n",
    "    Returns:\n",
    "        saliency (numpy array): The saliency map of shape (height, width).\n",
    "    \"\"\"\n",
    "    # Ensure the model is in inference mode\n",
    "    model.trainable = False\n",
    "    input_tensor = tf.convert_to_tensor(input_sample)\n",
    "    \n",
    "    # Use GradientTape to record operations for automatic differentiation\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Watch the input tensor\n",
    "        tape.watch(input_tensor)\n",
    "        # Get the model's prediction\n",
    "        prediction = model(input_tensor)\n",
    "    \n",
    "    # Compute gradients of the prediction with respect to the input\n",
    "    grads = tape.gradient(prediction, input_tensor)\n",
    "    \n",
    "    # If there are multiple channels, take the maximum absolute gradient across channels\n",
    "    saliency = np.max(np.abs(grads.numpy()), axis=-1)[0]\n",
    "    return saliency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9776cdc0-38bc-476f-b93d-3753a2eb6803",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_saliency_per_channel(model, input_sample):\n",
    "    \"\"\"\n",
    "    Computes the saliency map for each channel of a given input sample.\n",
    "    \n",
    "    Args:\n",
    "        model (tf.keras.Model): The trained Keras model.\n",
    "        input_sample (numpy array): A single input sample with shape (1, H, W, C).\n",
    "        \n",
    "    Returns:\n",
    "        saliency_maps (numpy array): Absolute gradients with shape (H, W, C) for each channel.\n",
    "        channel_importance (numpy array): Mean saliency per channel (shape: (C,)).\n",
    "    \"\"\"\n",
    "    # Set the model to inference mode\n",
    "    model.trainable = False\n",
    "    input_tensor = tf.convert_to_tensor(input_sample)\n",
    "    \n",
    "    # Compute gradients with respect to the input sample using GradientTape\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(input_tensor)\n",
    "        prediction = model(input_tensor)\n",
    "    \n",
    "    # Calculate gradients: shape (1, H, W, C)\n",
    "    grads = tape.gradient(prediction, input_tensor)\n",
    "    \n",
    "    # Remove the batch dimension: shape becomes (H, W, C)\n",
    "    grads = grads.numpy()[0]\n",
    "    \n",
    "    # Take absolute value to measure importance (magnitude of sensitivity)\n",
    "    saliency_maps = np.abs(grads)\n",
    "    \n",
    "    # Aggregate saliency per channel (e.g., using the mean over spatial dimensions)\n",
    "    channel_importance = np.mean(saliency_maps, axis=(0, 1))\n",
    "    \n",
    "    return saliency_maps, channel_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81aa5f1b-5513-4496-9fae-a6cde06e1aaa",
   "metadata": {
    "papermill": {
     "duration": 0.00964,
     "end_time": "2025-03-05T18:49:20.464813",
     "exception": false,
     "start_time": "2025-03-05T18:49:20.455173",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "number_of_features = len(var_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3490622e-a626-42aa-9cfe-020ee54d21e0",
   "metadata": {
    "papermill": {
     "duration": 758.818091,
     "end_time": "2025-03-05T19:01:59.288567",
     "exception": false,
     "start_time": "2025-03-05T18:49:20.470476",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cape from Zarr store.\n",
      "Loading crr from Zarr store.\n",
      "Loading d_300 from Zarr store.\n",
      "Loading ie from Zarr store.\n",
      "Loading ishf from Zarr store.\n",
      "Loading lsrr from Zarr store.\n",
      "Loading pv_300 from Zarr store.\n",
      "Loading q_300 from Zarr store.\n",
      "Loading r_300 from Zarr store.\n",
      "Loading sp from Zarr store.\n",
      "Loading sstk from Zarr store.\n",
      "Loading tcw from Zarr store.\n",
      "Loading tcwv from Zarr store.\n",
      "Loading t_300 from Zarr store.\n",
      "Loading ttr from Zarr store.\n",
      "Loading u_300 from Zarr store.\n",
      "Loading v_300 from Zarr store.\n",
      "Loading vo_300 from Zarr store.\n",
      "Loading w_300 from Zarr store.\n"
     ]
    }
   ],
   "source": [
    "data = open_files_zarr(\n",
    "    list_of_vars=var_list,\n",
    "    aew_subset=aew_subset,\n",
    "    directory=\"/glade/derecho/scratch/rmandava/AEW_time_location_files/\",\n",
    "    plevel_list=plevel_list,\n",
    "    zarr_store_path=\"/glade/derecho/scratch/rmandava/AEW_time_location_files/Project1/zarr\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ddac3e-071b-4796-9ca6-9cb01deeb598",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f240d4af-46d1-4cef-a5ab-2e2527a1639f",
   "metadata": {
    "papermill": {
     "duration": 185.616237,
     "end_time": "2025-03-05T19:05:04.925249",
     "exception": false,
     "start_time": "2025-03-05T19:01:59.309012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2750, 32, 32, 19)\n"
     ]
    }
   ],
   "source": [
    "# transpose the data and concat variables\n",
    "\n",
    "#data_, labels_ = transpose_load_concat(data)\n",
    "data_, labels_, sample_lat, sample_lon = transpose_load_concat(data)\n",
    "\n",
    "print(np.shape(data_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0e4f7b8-f9e0-4131-ae35-97e47bc557d0",
   "metadata": {
    "papermill": {
     "duration": 0.372532,
     "end_time": "2025-03-05T19:05:05.305951",
     "exception": false,
     "start_time": "2025-03-05T19:05:04.933419",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check / remove nans\n",
    "\n",
    "data_, labels_, sample_lat, sample_lon = omit_nans(data_, labels_, sample_lat, sample_lon)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0492935e-1f35-446b-ab16-aba0e667857b",
   "metadata": {
    "papermill": {
     "duration": 0.044227,
     "end_time": "2025-03-05T19:05:05.358050",
     "exception": false,
     "start_time": "2025-03-05T19:05:05.313823",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(560, 32, 32, 19) (140, 32, 32, 19) (560,) (140,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/u/home/rmandava/.local/lib/python3.10/site-packages/xarray/core/indexing.py:1642: PerformanceWarning: Slicing with an out-of-order index is generating 106 times more chunks\n",
      "  return self.array[key]\n",
      "/glade/u/home/rmandava/.local/lib/python3.10/site-packages/xarray/core/indexing.py:1642: PerformanceWarning: Slicing with an out-of-order index is generating 27 times more chunks\n",
      "  return self.array[key]\n"
     ]
    }
   ],
   "source": [
    "#split train and test set\n",
    "X_train, X_test, y_train, y_test, lat_train, lat_test, lon_train, lon_test = sklearn.model_selection.train_test_split(\n",
    "    data_, labels_, sample_lat, sample_lon, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "print (np.shape(X_train), np.shape(X_test), np.shape(y_train), np.shape(y_test))\n",
    "\n",
    "\n",
    "y_train = np.expand_dims(y_train, axis=1)\n",
    "\n",
    "y_test = np.expand_dims(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "164ee316-7c83-474b-bdb9-7c12ca165e1f",
   "metadata": {
    "papermill": {
     "duration": 0.312834,
     "end_time": "2025-03-05T19:05:05.678612",
     "exception": false,
     "start_time": "2025-03-05T19:05:05.365778",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [21]: Scaling code (fixed to prevent data leakage)\n",
    "\n",
    "# Create the scaler object\n",
    "scaler_input = sklearn.preprocessing.StandardScaler()\n",
    "\n",
    "# Reshape training data to 2D (samples, features)\n",
    "X_train_tmp = np.reshape(X_train, (-1, len(var_list)))\n",
    "\n",
    "# Fit the scaler ONLY on the training data\n",
    "scaler_input.fit(X_train_tmp)  # <-- Key change: Learn mean/std from training data\n",
    "\n",
    "# Transform BOTH training and test data using the SAME scaler\n",
    "input_train_scaled = scaler_input.transform(X_train_tmp)          # Train: transform only\n",
    "input_test_scaled = scaler_input.transform(                       # Test: transform only\n",
    "    np.reshape(X_test, (-1, len(var_list)))\n",
    ")\n",
    "\n",
    "# Reshape back to original dimensions (samples, height, width, features)\n",
    "input_train_scaled = np.reshape(input_train_scaled, X_train.shape)\n",
    "input_test_scaled = np.reshape(input_test_scaled, X_test.shape)\n",
    "\n",
    "# Labels remain unchanged\n",
    "label_train_scaled = y_train\n",
    "label_test_scaled = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6bed418e-264b-45e6-92ee-b72c2f7a04d7",
   "metadata": {
    "papermill": {
     "duration": 0.014239,
     "end_time": "2025-03-05T19:05:05.701116",
     "exception": false,
     "start_time": "2025-03-05T19:05:05.686877",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(560, 32, 32, 19) (560, 1) (140, 32, 32, 19) (140, 1)\n"
     ]
    }
   ],
   "source": [
    "# print the shapes to double check them\n",
    "\n",
    "print(\n",
    "\n",
    "input_train_scaled.shape,\n",
    "\n",
    "label_train_scaled.shape,\n",
    "\n",
    "input_test_scaled.shape,\n",
    "\n",
    "label_test_scaled.shape\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10597eb7-f8fa-4523-a306-55d5a442d504",
   "metadata": {
    "papermill": {
     "duration": 0.017418,
     "end_time": "2025-03-05T19:05:05.726147",
     "exception": false,
     "start_time": "2025-03-05T19:05:05.708729",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive samples in training data: 91 (16.25% of total)\n"
     ]
    }
   ],
   "source": [
    "#generate class weights due to class imbalance issues\n",
    "\n",
    "counts = np.bincount(y_train[:, 0].astype(int))\n",
    "\n",
    "\n",
    "print(\n",
    "\n",
    "\"Number of positive samples in training data: {} ({:.2f}% of total)\".format(\n",
    "\n",
    "counts[1], 100 * float(counts[1]) / len(y_train))\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "557d98a2-07ba-4fa7-8ba2-9ce8baa53b63",
   "metadata": {
    "papermill": {
     "duration": 0.01967,
     "end_time": "2025-03-05T19:05:05.753659",
     "exception": false,
     "start_time": "2025-03-05T19:05:05.733989",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.1625, 1: 0.8375}\n"
     ]
    }
   ],
   "source": [
    "# old weights\n",
    "\n",
    "# weight_for_0 = 1.0 / counts[0]\n",
    "\n",
    "# weight_for_1 = 1.0 / counts[1]\n",
    "\n",
    "\n",
    "#new weights\n",
    "\n",
    "weight_for_0 = float(counts[1]) / len(y_train)\n",
    "\n",
    "weight_for_1 = 1 - (float(counts[1]) / len(y_train))\n",
    "\n",
    "\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "print(class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "700f978d-cc6f-484a-864f-dcb9e703eed4",
   "metadata": {
    "papermill": {
     "duration": 1.029155,
     "end_time": "2025-03-05T19:05:06.790734",
     "exception": false,
     "start_time": "2025-03-05T19:05:05.761579",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-29 09:45:45.226187: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "METRICS = [\n",
    "\n",
    "keras.metrics.BinaryCrossentropy(name='cross entropy'),\n",
    "\n",
    "keras.metrics.MeanSquaredError(name='mean_squared_error'),\n",
    "\n",
    "keras.metrics.RootMeanSquaredError(name='root_mean_squared_error'),\n",
    "\n",
    "keras.metrics.TruePositives(name='tp'),\n",
    "\n",
    "keras.metrics.FalsePositives(name='fp'),\n",
    "\n",
    "keras.metrics.TrueNegatives(name='tn'),\n",
    "\n",
    "keras.metrics.FalseNegatives(name='fn'),\n",
    "\n",
    "keras.metrics.BinaryAccuracy(name='binary_accuracy'),\n",
    "\n",
    "keras.metrics.F1Score(threshold=0.5, name='f1_score'),\n",
    "\n",
    "keras.metrics.Precision(name='precision'),\n",
    "\n",
    "keras.metrics.Recall(name='recall'),\n",
    "\n",
    "keras.metrics.AUC(name='auc'),\n",
    "\n",
    "keras.metrics.AUC(name='prc', curve='PR'),\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9900636-a8fb-4b46-9282-66643c95cdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6bc9aab7-2558-4304-a6c7-5809d60e8437",
   "metadata": {
    "papermill": {
     "duration": 0.030448,
     "end_time": "2025-03-05T19:05:06.829775",
     "exception": false,
     "start_time": "2025-03-05T19:05:06.799327",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MyHyperModel(keras_tuner.HyperModel):\n",
    "    def build(self, hp):\n",
    "        model = keras.Sequential()\n",
    "        model.add(keras.Input(shape=(32, 32, number_of_features)))\n",
    "\n",
    "        # Data augmentation\n",
    "        model.add(layers.RandomFlip(\"horizontal_and_vertical\"))\n",
    "        model.add(layers.RandomRotation(factor=(-0.5, 0.5)))\n",
    "\n",
    "        # Hyperparameters\n",
    "        featmaps1 = hp.Int('units_1', min_value=10, max_value=60)\n",
    "        featmaps2 = hp.Int('units_2', min_value=10, max_value=64)\n",
    "        featmaps3 = hp.Int('units_3', min_value=10, max_value=128)\n",
    "        featmaps4 = hp.Int('units_4', min_value=10, max_value=80)\n",
    "        featmaps5 = hp.Int('units_5', min_value=10, max_value=80)  # New block\n",
    "        learning_rate = hp.Float('lr', min_value=1e-5, max_value=1e-2, sampling=\"log\")\n",
    "        act_func = hp.Choice('activation', [\"relu\", \"tanh\", \"selu\", \"sigmoid\", \"relu6\", \"silu\", \"gelu\"])\n",
    "\n",
    "        # Conv Block 1\n",
    "        model.add(layers.SeparableConv2D(featmaps1, 3, padding=\"same\"))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Activation(pick_loss(act_func)))\n",
    "        model.add(layers.MaxPooling2D(2))\n",
    "        model.add(layers.Dropout(0.2))\n",
    "\n",
    "        # Conv Block 2\n",
    "        model.add(layers.SeparableConv2D(featmaps2, 3, padding=\"same\"))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Activation(pick_loss(act_func)))\n",
    "        model.add(layers.MaxPooling2D(2))\n",
    "        model.add(layers.Dropout(0.2))\n",
    "\n",
    "        # Conv Block 3\n",
    "        model.add(layers.SeparableConv2D(featmaps3, 3, padding=\"same\"))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Activation(pick_loss(act_func)))\n",
    "        model.add(layers.MaxPooling2D(2))\n",
    "        model.add(layers.Dropout(0.2))\n",
    "\n",
    "        # New Conv Block 4\n",
    "        model.add(layers.SeparableConv2D(featmaps5, 3, padding=\"same\"))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Activation(pick_loss(act_func)))\n",
    "        model.add(layers.MaxPooling2D(2))\n",
    "        model.add(layers.Dropout(0.2))\n",
    "\n",
    "        # Dense layers\n",
    "        model.add(layers.GlobalMaxPooling2D())\n",
    "        model.add(layers.Dense(featmaps4))\n",
    "        model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "        \n",
    "\n",
    "        model.compile(\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "            loss=focal_loss(gamma=2.0, alpha=0.25),\n",
    "            metrics=METRICS\n",
    "        )\n",
    "\n",
    "        return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e68e967f-623f-4332-a38c-57359b8121c3",
   "metadata": {
    "papermill": {
     "duration": 0.018907,
     "end_time": "2025-03-05T19:05:06.856235",
     "exception": false,
     "start_time": "2025-03-05T19:05:06.837328",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fit(self, hp, model, *args, **kwargs):\n",
    "    batchsizenum = hp.Int('batch_size', min_value=10, max_value=60, step=5, sampling=\"linear\")\n",
    "\n",
    "    print({k: hp.get(k) if hp.is_active(k) else None for k in hp._hps})\n",
    "\n",
    "    return model.fit(\n",
    "        *args,\n",
    "        batch_size=batchsizenum,\n",
    "        # normally we might use early stopping, but not needed since\n",
    "        # callbacks saves checkpoints of the model during trials\n",
    "        # callbacks=keras.callbacks.EarlyStopping('val_loss', patience=5),\n",
    "        validation_split=0.1,\n",
    "        shuffle=True,\n",
    "        class_weight=class_weight,\n",
    "        **kwargs,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b0947fd-6eb0-4f20-8b0f-2f5d11ab5b3b",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 0.379052,
     "end_time": "2025-03-05T19:05:07.243192",
     "exception": false,
     "start_time": "2025-03-05T19:05:06.864140",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "Parameters",
     "parameters"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 7\n",
      "units_1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 10, 'max_value': 60, 'step': 1, 'sampling': 'linear'}\n",
      "units_2 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 10, 'max_value': 64, 'step': 1, 'sampling': 'linear'}\n",
      "units_3 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 10, 'max_value': 128, 'step': 1, 'sampling': 'linear'}\n",
      "units_4 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 10, 'max_value': 80, 'step': 1, 'sampling': 'linear'}\n",
      "units_5 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 10, 'max_value': 80, 'step': 1, 'sampling': 'linear'}\n",
      "lr (Float)\n",
      "{'default': 1e-05, 'conditions': [], 'min_value': 1e-05, 'max_value': 0.01, 'step': None, 'sampling': 'log'}\n",
      "activation (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'tanh', 'selu', 'sigmoid', 'relu6', 'silu', 'gelu'], 'ordered': False}\n"
     ]
    }
   ],
   "source": [
    "# make the tuner object\n",
    "tuner = keras_tuner.BayesianOptimization(\n",
    "    hypermodel=MyHyperModel(),\n",
    "    objective=keras_tuner.Objective(\"val_f1_score\", direction=\"max\"),\n",
    "    max_trials=150,\n",
    "    project_name=tuner_project_name,\n",
    "    alpha=0.0001,\n",
    "    beta=2.6,\n",
    "    seed=123,\n",
    "    tune_new_entries=True,\n",
    "    allow_new_entries=True,\n",
    "    max_retries_per_trial=1,\n",
    "    max_consecutive_failed_trials=3,\n",
    "    overwrite=True,\n",
    ")\n",
    "\n",
    "# summary\n",
    "tuner.search_space_summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5a6396-3b45-4ae6-91ad-62b07260777e",
   "metadata": {
    "papermill": {
     "duration": 6055.188829,
     "end_time": "2025-03-05T20:46:02.439902",
     "exception": false,
     "start_time": "2025-03-05T19:05:07.251073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 7 Complete [00h 00m 26s]\n",
      "val_f1_score: 0.5454545617103577\n",
      "\n",
      "Best val_f1_score So Far: 0.6666666865348816\n",
      "Total elapsed time: 00h 03m 24s\n",
      "\n",
      "Search: Running Trial #8\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "27                |44                |units_1\n",
      "27                |31                |units_2\n",
      "105               |24                |units_3\n",
      "41                |46                |units_4\n",
      "12                |13                |units_5\n",
      "0.0080079         |0.00042098        |lr\n",
      "gelu              |relu              |activation\n",
      "\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 2s 46ms/step - loss: 0.0511 - cross entropy: 0.4489 - mean_squared_error: 0.1393 - root_mean_squared_error: 0.3732 - tp: 7.0000 - fp: 12.0000 - tn: 457.0000 - fn: 84.0000 - binary_accuracy: 0.8286 - f1_score: 0.1273 - precision: 0.3684 - recall: 0.0769 - auc: 0.6542 - prc: 0.2931 - val_loss: 0.0783 - val_cross entropy: 0.5959 - val_mean_squared_error: 0.2017 - val_root_mean_squared_error: 0.4491 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 50.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5167 - val_prc: 0.1108\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0384 - cross entropy: 0.3925 - mean_squared_error: 0.1220 - root_mean_squared_error: 0.3493 - tp: 3.0000 - fp: 7.0000 - tn: 412.0000 - fn: 82.0000 - binary_accuracy: 0.8234 - f1_score: 0.0632 - precision: 0.3000 - recall: 0.0353 - auc: 0.7969 - prc: 0.3851 - val_loss: 0.0605 - val_cross entropy: 0.5444 - val_mean_squared_error: 0.1767 - val_root_mean_squared_error: 0.4204 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 50.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5617 - val_prc: 0.1977\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0366 - cross entropy: 0.3944 - mean_squared_error: 0.1220 - root_mean_squared_error: 0.3493 - tp: 4.0000 - fp: 7.0000 - tn: 412.0000 - fn: 81.0000 - binary_accuracy: 0.8254 - f1_score: 0.0833 - precision: 0.3636 - recall: 0.0471 - auc: 0.8227 - prc: 0.4010 - val_loss: 0.0529 - val_cross entropy: 0.5186 - val_mean_squared_error: 0.1646 - val_root_mean_squared_error: 0.4057 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 50.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6533 - val_prc: 0.3448\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0317 - cross entropy: 0.3672 - mean_squared_error: 0.1122 - root_mean_squared_error: 0.3349 - tp: 1.0000 - fp: 0.0000e+00 - tn: 419.0000 - fn: 84.0000 - binary_accuracy: 0.8333 - f1_score: 0.0233 - precision: 1.0000 - recall: 0.0118 - auc: 0.8660 - prc: 0.6101 - val_loss: 0.0478 - val_cross entropy: 0.4986 - val_mean_squared_error: 0.1553 - val_root_mean_squared_error: 0.3941 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 50.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7033 - val_prc: 0.4325\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0322 - cross entropy: 0.3572 - mean_squared_error: 0.1086 - root_mean_squared_error: 0.3295 - tp: 5.0000 - fp: 3.0000 - tn: 416.0000 - fn: 80.0000 - binary_accuracy: 0.8353 - f1_score: 0.1075 - precision: 0.6250 - recall: 0.0588 - auc: 0.8684 - prc: 0.5366 - val_loss: 0.0480 - val_cross entropy: 0.4988 - val_mean_squared_error: 0.1554 - val_root_mean_squared_error: 0.3943 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 50.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6850 - val_prc: 0.4255\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0318 - cross entropy: 0.3695 - mean_squared_error: 0.1123 - root_mean_squared_error: 0.3351 - tp: 2.0000 - fp: 2.0000 - tn: 417.0000 - fn: 83.0000 - binary_accuracy: 0.8313 - f1_score: 0.0449 - precision: 0.5000 - recall: 0.0235 - auc: 0.8670 - prc: 0.5457 - val_loss: 0.0432 - val_cross entropy: 0.4787 - val_mean_squared_error: 0.1464 - val_root_mean_squared_error: 0.3826 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 50.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7000 - val_prc: 0.5191\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0314 - cross entropy: 0.3581 - mean_squared_error: 0.1078 - root_mean_squared_error: 0.3284 - tp: 14.0000 - fp: 6.0000 - tn: 413.0000 - fn: 71.0000 - binary_accuracy: 0.8472 - f1_score: 0.2667 - precision: 0.7000 - recall: 0.1647 - auc: 0.8725 - prc: 0.5634 - val_loss: 0.0358 - val_cross entropy: 0.4371 - val_mean_squared_error: 0.1287 - val_root_mean_squared_error: 0.3588 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 50.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6750 - val_prc: 0.4686\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0290 - cross entropy: 0.3423 - mean_squared_error: 0.1035 - root_mean_squared_error: 0.3217 - tp: 12.0000 - fp: 4.0000 - tn: 415.0000 - fn: 73.0000 - binary_accuracy: 0.8472 - f1_score: 0.2376 - precision: 0.7500 - recall: 0.1412 - auc: 0.8970 - prc: 0.6242 - val_loss: 0.0339 - val_cross entropy: 0.4182 - val_mean_squared_error: 0.1210 - val_root_mean_squared_error: 0.3479 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 50.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6667 - val_prc: 0.4872\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0293 - cross entropy: 0.3330 - mean_squared_error: 0.1005 - root_mean_squared_error: 0.3170 - tp: 20.0000 - fp: 9.0000 - tn: 410.0000 - fn: 65.0000 - binary_accuracy: 0.8532 - f1_score: 0.3509 - precision: 0.6897 - recall: 0.2353 - auc: 0.8950 - prc: 0.6242 - val_loss: 0.0311 - val_cross entropy: 0.4024 - val_mean_squared_error: 0.1149 - val_root_mean_squared_error: 0.3390 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 50.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7317 - val_prc: 0.5864\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0318 - cross entropy: 0.3627 - mean_squared_error: 0.1107 - root_mean_squared_error: 0.3328 - tp: 13.0000 - fp: 8.0000 - tn: 411.0000 - fn: 72.0000 - binary_accuracy: 0.8413 - f1_score: 0.2453 - precision: 0.6190 - recall: 0.1529 - auc: 0.8763 - prc: 0.5215 - val_loss: 0.0316 - val_cross entropy: 0.3864 - val_mean_squared_error: 0.1093 - val_root_mean_squared_error: 0.3306 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 50.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6733 - val_prc: 0.4749\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.0301 - cross entropy: 0.3321 - mean_squared_error: 0.1029 - root_mean_squared_error: 0.3208 - tp: 7.0000 - fp: 4.0000 - tn: 415.0000 - fn: 78.0000 - binary_accuracy: 0.8373 - f1_score: 0.1458 - precision: 0.6364 - recall: 0.0824 - auc: 0.8961 - prc: 0.5522 - val_loss: 0.0349 - val_cross entropy: 0.3824 - val_mean_squared_error: 0.1063 - val_root_mean_squared_error: 0.3260 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 50.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6817 - val_prc: 0.5919\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0280 - cross entropy: 0.3309 - mean_squared_error: 0.0997 - root_mean_squared_error: 0.3158 - tp: 24.0000 - fp: 8.0000 - tn: 411.0000 - fn: 61.0000 - binary_accuracy: 0.8631 - f1_score: 0.4103 - precision: 0.7500 - recall: 0.2824 - auc: 0.9084 - prc: 0.6381 - val_loss: 0.0359 - val_cross entropy: 0.3763 - val_mean_squared_error: 0.1049 - val_root_mean_squared_error: 0.3239 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 50.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6883 - val_prc: 0.5925\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0287 - cross entropy: 0.3351 - mean_squared_error: 0.1042 - root_mean_squared_error: 0.3228 - tp: 2.0000 - fp: 0.0000e+00 - tn: 419.0000 - fn: 83.0000 - binary_accuracy: 0.8353 - f1_score: 0.0460 - precision: 1.0000 - recall: 0.0235 - auc: 0.9048 - prc: 0.6056 - val_loss: 0.0371 - val_cross entropy: 0.3749 - val_mean_squared_error: 0.1048 - val_root_mean_squared_error: 0.3237 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 50.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6833 - val_prc: 0.3854\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.0281 - cross entropy: 0.3229 - mean_squared_error: 0.0982 - root_mean_squared_error: 0.3134 - tp: 21.0000 - fp: 8.0000 - tn: 411.0000 - fn: 64.0000 - binary_accuracy: 0.8571 - f1_score: 0.3684 - precision: 0.7241 - recall: 0.2471 - auc: 0.9072 - prc: 0.6376 - val_loss: 0.0369 - val_cross entropy: 0.3764 - val_mean_squared_error: 0.1014 - val_root_mean_squared_error: 0.3185 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 50.0000 - val_fn: 5.0000 - val_binary_accuracy: 0.9107 - val_f1_score: 0.2857 - val_precision: 1.0000 - val_recall: 0.1667 - val_auc: 0.6700 - val_prc: 0.5710\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0257 - cross entropy: 0.3017 - mean_squared_error: 0.0918 - root_mean_squared_error: 0.3030 - tp: 22.0000 - fp: 3.0000 - tn: 416.0000 - fn: 63.0000 - binary_accuracy: 0.8690 - f1_score: 0.4000 - precision: 0.8800 - recall: 0.2588 - auc: 0.9229 - prc: 0.7132 - val_loss: 0.0299 - val_cross entropy: 0.3583 - val_mean_squared_error: 0.1008 - val_root_mean_squared_error: 0.3175 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 50.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7150 - val_prc: 0.4726\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0275 - cross entropy: 0.3210 - mean_squared_error: 0.0965 - root_mean_squared_error: 0.3106 - tp: 29.0000 - fp: 5.0000 - tn: 414.0000 - fn: 56.0000 - binary_accuracy: 0.8790 - f1_score: 0.4874 - precision: 0.8529 - recall: 0.3412 - auc: 0.9066 - prc: 0.7106 - val_loss: 0.0422 - val_cross entropy: 0.3695 - val_mean_squared_error: 0.0989 - val_root_mean_squared_error: 0.3145 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 50.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6400 - val_prc: 0.4889\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0283 - cross entropy: 0.3193 - mean_squared_error: 0.0974 - root_mean_squared_error: 0.3121 - tp: 15.0000 - fp: 4.0000 - tn: 415.0000 - fn: 70.0000 - binary_accuracy: 0.8532 - f1_score: 0.2885 - precision: 0.7895 - recall: 0.1765 - auc: 0.9020 - prc: 0.6521 - val_loss: 0.0436 - val_cross entropy: 0.3676 - val_mean_squared_error: 0.0979 - val_root_mean_squared_error: 0.3129 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 50.0000 - val_fn: 5.0000 - val_binary_accuracy: 0.9107 - val_f1_score: 0.2857 - val_precision: 1.0000 - val_recall: 0.1667 - val_auc: 0.6533 - val_prc: 0.4074\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0261 - cross entropy: 0.3092 - mean_squared_error: 0.0911 - root_mean_squared_error: 0.3019 - tp: 34.0000 - fp: 8.0000 - tn: 411.0000 - fn: 51.0000 - binary_accuracy: 0.8829 - f1_score: 0.5354 - precision: 0.8095 - recall: 0.4000 - auc: 0.9215 - prc: 0.7193 - val_loss: 0.0419 - val_cross entropy: 0.3336 - val_mean_squared_error: 0.0878 - val_root_mean_squared_error: 0.2964 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 50.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6367 - val_prc: 0.4841\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.0252 - cross entropy: 0.3011 - mean_squared_error: 0.0912 - root_mean_squared_error: 0.3019 - tp: 18.0000 - fp: 2.0000 - tn: 417.0000 - fn: 67.0000 - binary_accuracy: 0.8631 - f1_score: 0.3429 - precision: 0.9000 - recall: 0.2118 - auc: 0.9284 - prc: 0.7453 - val_loss: 0.0622 - val_cross entropy: 0.3913 - val_mean_squared_error: 0.1080 - val_root_mean_squared_error: 0.3287 - val_tp: 3.0000 - val_fp: 4.0000 - val_tn: 46.0000 - val_fn: 3.0000 - val_binary_accuracy: 0.8750 - val_f1_score: 0.4615 - val_precision: 0.4286 - val_recall: 0.5000 - val_auc: 0.6500 - val_prc: 0.3732\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0284 - cross entropy: 0.3171 - mean_squared_error: 0.0968 - root_mean_squared_error: 0.3111 - tp: 20.0000 - fp: 7.0000 - tn: 412.0000 - fn: 65.0000 - binary_accuracy: 0.8571 - f1_score: 0.3571 - precision: 0.7407 - recall: 0.2353 - auc: 0.9099 - prc: 0.6408 - val_loss: 0.0378 - val_cross entropy: 0.3319 - val_mean_squared_error: 0.0914 - val_root_mean_squared_error: 0.3022 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 50.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6967 - val_prc: 0.4706\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0289 - cross entropy: 0.3340 - mean_squared_error: 0.1020 - root_mean_squared_error: 0.3193 - tp: 18.0000 - fp: 6.0000 - tn: 413.0000 - fn: 67.0000 - binary_accuracy: 0.8552 - f1_score: 0.3303 - precision: 0.7500 - recall: 0.2118 - auc: 0.9006 - prc: 0.6399 - val_loss: 0.0518 - val_cross entropy: 0.3813 - val_mean_squared_error: 0.0969 - val_root_mean_squared_error: 0.3113 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 49.0000 - val_fn: 5.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.2500 - val_precision: 0.5000 - val_recall: 0.1667 - val_auc: 0.6483 - val_prc: 0.3833\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0272 - cross entropy: 0.3116 - mean_squared_error: 0.0961 - root_mean_squared_error: 0.3100 - tp: 20.0000 - fp: 4.0000 - tn: 415.0000 - fn: 65.0000 - binary_accuracy: 0.8631 - f1_score: 0.3670 - precision: 0.8333 - recall: 0.2353 - auc: 0.9120 - prc: 0.6709 - val_loss: 0.0460 - val_cross entropy: 0.3384 - val_mean_squared_error: 0.0876 - val_root_mean_squared_error: 0.2959 - val_tp: 2.0000 - val_fp: 0.0000e+00 - val_tn: 50.0000 - val_fn: 4.0000 - val_binary_accuracy: 0.9286 - val_f1_score: 0.5000 - val_precision: 1.0000 - val_recall: 0.3333 - val_auc: 0.6717 - val_prc: 0.4810\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0260 - cross entropy: 0.3055 - mean_squared_error: 0.0923 - root_mean_squared_error: 0.3037 - tp: 20.0000 - fp: 4.0000 - tn: 415.0000 - fn: 65.0000 - binary_accuracy: 0.8631 - f1_score: 0.3670 - precision: 0.8333 - recall: 0.2353 - auc: 0.9234 - prc: 0.7023 - val_loss: 0.0498 - val_cross entropy: 0.3619 - val_mean_squared_error: 0.0914 - val_root_mean_squared_error: 0.3023 - val_tp: 2.0000 - val_fp: 0.0000e+00 - val_tn: 50.0000 - val_fn: 4.0000 - val_binary_accuracy: 0.9286 - val_f1_score: 0.5000 - val_precision: 1.0000 - val_recall: 0.3333 - val_auc: 0.6783 - val_prc: 0.4852\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0235 - cross entropy: 0.2945 - mean_squared_error: 0.0873 - root_mean_squared_error: 0.2954 - tp: 28.0000 - fp: 2.0000 - tn: 417.0000 - fn: 57.0000 - binary_accuracy: 0.8829 - f1_score: 0.4870 - precision: 0.9333 - recall: 0.3294 - auc: 0.9368 - prc: 0.7736 - val_loss: 0.0497 - val_cross entropy: 0.3577 - val_mean_squared_error: 0.0964 - val_root_mean_squared_error: 0.3104 - val_tp: 2.0000 - val_fp: 2.0000 - val_tn: 48.0000 - val_fn: 4.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.4000 - val_precision: 0.5000 - val_recall: 0.3333 - val_auc: 0.6600 - val_prc: 0.4574\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0265 - cross entropy: 0.2817 - mean_squared_error: 0.0836 - root_mean_squared_error: 0.2891 - tp: 38.0000 - fp: 10.0000 - tn: 409.0000 - fn: 47.0000 - binary_accuracy: 0.8869 - f1_score: 0.5714 - precision: 0.7917 - recall: 0.4471 - auc: 0.9263 - prc: 0.7282 - val_loss: 0.0495 - val_cross entropy: 0.3589 - val_mean_squared_error: 0.1000 - val_root_mean_squared_error: 0.3162 - val_tp: 0.0000e+00 - val_fp: 1.0000 - val_tn: 49.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8750 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6483 - val_prc: 0.1982\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0287 - cross entropy: 0.3389 - mean_squared_error: 0.1049 - root_mean_squared_error: 0.3239 - tp: 7.0000 - fp: 2.0000 - tn: 417.0000 - fn: 78.0000 - binary_accuracy: 0.8413 - f1_score: 0.1489 - precision: 0.7778 - recall: 0.0824 - auc: 0.8974 - prc: 0.6243 - val_loss: 0.0581 - val_cross entropy: 0.3929 - val_mean_squared_error: 0.0952 - val_root_mean_squared_error: 0.3085 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 50.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6500 - val_prc: 0.3088\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0256 - cross entropy: 0.3060 - mean_squared_error: 0.0942 - root_mean_squared_error: 0.3070 - tp: 14.0000 - fp: 2.0000 - tn: 417.0000 - fn: 71.0000 - binary_accuracy: 0.8552 - f1_score: 0.2772 - precision: 0.8750 - recall: 0.1647 - auc: 0.9253 - prc: 0.6999 - val_loss: 0.0583 - val_cross entropy: 0.3718 - val_mean_squared_error: 0.0986 - val_root_mean_squared_error: 0.3140 - val_tp: 2.0000 - val_fp: 3.0000 - val_tn: 47.0000 - val_fn: 4.0000 - val_binary_accuracy: 0.8750 - val_f1_score: 0.3636 - val_precision: 0.4000 - val_recall: 0.3333 - val_auc: 0.6650 - val_prc: 0.4619\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0250 - cross entropy: 0.2888 - mean_squared_error: 0.0894 - root_mean_squared_error: 0.2990 - tp: 23.0000 - fp: 6.0000 - tn: 413.0000 - fn: 62.0000 - binary_accuracy: 0.8651 - f1_score: 0.4035 - precision: 0.7931 - recall: 0.2706 - auc: 0.9338 - prc: 0.6691 - val_loss: 0.0591 - val_cross entropy: 0.3872 - val_mean_squared_error: 0.0977 - val_root_mean_squared_error: 0.3126 - val_tp: 2.0000 - val_fp: 3.0000 - val_tn: 47.0000 - val_fn: 4.0000 - val_binary_accuracy: 0.8750 - val_f1_score: 0.3636 - val_precision: 0.4000 - val_recall: 0.3333 - val_auc: 0.6700 - val_prc: 0.4754\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0249 - cross entropy: 0.2858 - mean_squared_error: 0.0867 - root_mean_squared_error: 0.2945 - tp: 32.0000 - fp: 12.0000 - tn: 407.0000 - fn: 53.0000 - binary_accuracy: 0.8710 - f1_score: 0.4961 - precision: 0.7273 - recall: 0.3765 - auc: 0.9344 - prc: 0.7191 - val_loss: 0.0607 - val_cross entropy: 0.3720 - val_mean_squared_error: 0.0910 - val_root_mean_squared_error: 0.3017 - val_tp: 2.0000 - val_fp: 1.0000 - val_tn: 49.0000 - val_fn: 4.0000 - val_binary_accuracy: 0.9107 - val_f1_score: 0.4444 - val_precision: 0.6667 - val_recall: 0.3333 - val_auc: 0.6717 - val_prc: 0.4616\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0262 - cross entropy: 0.2964 - mean_squared_error: 0.0938 - root_mean_squared_error: 0.3063 - tp: 7.0000 - fp: 0.0000e+00 - tn: 419.0000 - fn: 78.0000 - binary_accuracy: 0.8452 - f1_score: 0.1522 - precision: 1.0000 - recall: 0.0824 - auc: 0.9307 - prc: 0.7382 - val_loss: 0.0721 - val_cross entropy: 0.4149 - val_mean_squared_error: 0.0876 - val_root_mean_squared_error: 0.2960 - val_tp: 2.0000 - val_fp: 0.0000e+00 - val_tn: 50.0000 - val_fn: 4.0000 - val_binary_accuracy: 0.9286 - val_f1_score: 0.5000 - val_precision: 1.0000 - val_recall: 0.3333 - val_auc: 0.6617 - val_prc: 0.4712\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0264 - cross entropy: 0.2877 - mean_squared_error: 0.0874 - root_mean_squared_error: 0.2956 - tp: 34.0000 - fp: 10.0000 - tn: 409.0000 - fn: 51.0000 - binary_accuracy: 0.8790 - f1_score: 0.5271 - precision: 0.7727 - recall: 0.4000 - auc: 0.9281 - prc: 0.7022 - val_loss: 0.0634 - val_cross entropy: 0.3811 - val_mean_squared_error: 0.0839 - val_root_mean_squared_error: 0.2896 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 49.0000 - val_fn: 5.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.2500 - val_precision: 0.5000 - val_recall: 0.1667 - val_auc: 0.6733 - val_prc: 0.4410\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0244 - cross entropy: 0.3048 - mean_squared_error: 0.0926 - root_mean_squared_error: 0.3044 - tp: 20.0000 - fp: 2.0000 - tn: 417.0000 - fn: 65.0000 - binary_accuracy: 0.8671 - f1_score: 0.3738 - precision: 0.9091 - recall: 0.2353 - auc: 0.9325 - prc: 0.7553 - val_loss: 0.0624 - val_cross entropy: 0.3856 - val_mean_squared_error: 0.0876 - val_root_mean_squared_error: 0.2961 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 49.0000 - val_fn: 5.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.2500 - val_precision: 0.5000 - val_recall: 0.1667 - val_auc: 0.6850 - val_prc: 0.4212\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0207 - cross entropy: 0.2662 - mean_squared_error: 0.0794 - root_mean_squared_error: 0.2817 - tp: 31.0000 - fp: 4.0000 - tn: 415.0000 - fn: 54.0000 - binary_accuracy: 0.8849 - f1_score: 0.5167 - precision: 0.8857 - recall: 0.3647 - auc: 0.9543 - prc: 0.8175 - val_loss: 0.0578 - val_cross entropy: 0.3675 - val_mean_squared_error: 0.0966 - val_root_mean_squared_error: 0.3108 - val_tp: 2.0000 - val_fp: 3.0000 - val_tn: 47.0000 - val_fn: 4.0000 - val_binary_accuracy: 0.8750 - val_f1_score: 0.3636 - val_precision: 0.4000 - val_recall: 0.3333 - val_auc: 0.6600 - val_prc: 0.4562\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0216 - cross entropy: 0.2412 - mean_squared_error: 0.0715 - root_mean_squared_error: 0.2674 - tp: 45.0000 - fp: 4.0000 - tn: 415.0000 - fn: 40.0000 - binary_accuracy: 0.9127 - f1_score: 0.6716 - precision: 0.9184 - recall: 0.5294 - auc: 0.9512 - prc: 0.8167 - val_loss: 0.0688 - val_cross entropy: 0.3845 - val_mean_squared_error: 0.1074 - val_root_mean_squared_error: 0.3277 - val_tp: 2.0000 - val_fp: 5.0000 - val_tn: 45.0000 - val_fn: 4.0000 - val_binary_accuracy: 0.8393 - val_f1_score: 0.3077 - val_precision: 0.2857 - val_recall: 0.3333 - val_auc: 0.6867 - val_prc: 0.4047\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0229 - cross entropy: 0.2705 - mean_squared_error: 0.0812 - root_mean_squared_error: 0.2849 - tp: 39.0000 - fp: 7.0000 - tn: 412.0000 - fn: 46.0000 - binary_accuracy: 0.8948 - f1_score: 0.5954 - precision: 0.8478 - recall: 0.4588 - auc: 0.9420 - prc: 0.7774 - val_loss: 0.0584 - val_cross entropy: 0.3965 - val_mean_squared_error: 0.1044 - val_root_mean_squared_error: 0.3231 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 48.0000 - val_fn: 5.0000 - val_binary_accuracy: 0.8750 - val_f1_score: 0.2222 - val_precision: 0.3333 - val_recall: 0.1667 - val_auc: 0.7017 - val_prc: 0.2127\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0261 - cross entropy: 0.2971 - mean_squared_error: 0.0915 - root_mean_squared_error: 0.3025 - tp: 18.0000 - fp: 3.0000 - tn: 416.0000 - fn: 67.0000 - binary_accuracy: 0.8611 - f1_score: 0.3396 - precision: 0.8571 - recall: 0.2118 - auc: 0.9281 - prc: 0.7035 - val_loss: 0.0575 - val_cross entropy: 0.3671 - val_mean_squared_error: 0.1005 - val_root_mean_squared_error: 0.3170 - val_tp: 1.0000 - val_fp: 4.0000 - val_tn: 46.0000 - val_fn: 5.0000 - val_binary_accuracy: 0.8393 - val_f1_score: 0.1818 - val_precision: 0.2000 - val_recall: 0.1667 - val_auc: 0.7133 - val_prc: 0.2440\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0213 - cross entropy: 0.2674 - mean_squared_error: 0.0788 - root_mean_squared_error: 0.2808 - tp: 44.0000 - fp: 4.0000 - tn: 415.0000 - fn: 41.0000 - binary_accuracy: 0.9107 - f1_score: 0.6617 - precision: 0.9167 - recall: 0.5176 - auc: 0.9511 - prc: 0.8093 - val_loss: 0.0666 - val_cross entropy: 0.4002 - val_mean_squared_error: 0.0926 - val_root_mean_squared_error: 0.3043 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 49.0000 - val_fn: 5.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.2500 - val_precision: 0.5000 - val_recall: 0.1667 - val_auc: 0.6867 - val_prc: 0.2591\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0210 - cross entropy: 0.2605 - mean_squared_error: 0.0784 - root_mean_squared_error: 0.2800 - tp: 33.0000 - fp: 4.0000 - tn: 415.0000 - fn: 52.0000 - binary_accuracy: 0.8889 - f1_score: 0.5410 - precision: 0.8919 - recall: 0.3882 - auc: 0.9509 - prc: 0.8154 - val_loss: 0.0664 - val_cross entropy: 0.3577 - val_mean_squared_error: 0.0970 - val_root_mean_squared_error: 0.3114 - val_tp: 2.0000 - val_fp: 3.0000 - val_tn: 47.0000 - val_fn: 4.0000 - val_binary_accuracy: 0.8750 - val_f1_score: 0.3636 - val_precision: 0.4000 - val_recall: 0.3333 - val_auc: 0.6967 - val_prc: 0.3498\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0227 - cross entropy: 0.2547 - mean_squared_error: 0.0771 - root_mean_squared_error: 0.2776 - tp: 36.0000 - fp: 6.0000 - tn: 413.0000 - fn: 49.0000 - binary_accuracy: 0.8909 - f1_score: 0.5669 - precision: 0.8571 - recall: 0.4235 - auc: 0.9456 - prc: 0.7993 - val_loss: 0.0611 - val_cross entropy: 0.3765 - val_mean_squared_error: 0.1024 - val_root_mean_squared_error: 0.3199 - val_tp: 0.0000e+00 - val_fp: 3.0000 - val_tn: 47.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8393 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6733 - val_prc: 0.1940\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0234 - cross entropy: 0.2911 - mean_squared_error: 0.0865 - root_mean_squared_error: 0.2941 - tp: 30.0000 - fp: 8.0000 - tn: 411.0000 - fn: 55.0000 - binary_accuracy: 0.8750 - f1_score: 0.4878 - precision: 0.7895 - recall: 0.3529 - auc: 0.9418 - prc: 0.7548 - val_loss: 0.0762 - val_cross entropy: 0.4156 - val_mean_squared_error: 0.0878 - val_root_mean_squared_error: 0.2964 - val_tp: 0.0000e+00 - val_fp: 1.0000 - val_tn: 49.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8750 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6350 - val_prc: 0.2473\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0239 - cross entropy: 0.2783 - mean_squared_error: 0.0835 - root_mean_squared_error: 0.2889 - tp: 31.0000 - fp: 5.0000 - tn: 414.0000 - fn: 54.0000 - binary_accuracy: 0.8829 - f1_score: 0.5124 - precision: 0.8611 - recall: 0.3647 - auc: 0.9362 - prc: 0.7623 - val_loss: 0.0678 - val_cross entropy: 0.4013 - val_mean_squared_error: 0.0954 - val_root_mean_squared_error: 0.3088 - val_tp: 0.0000e+00 - val_fp: 2.0000 - val_tn: 48.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8571 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6333 - val_prc: 0.2297\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0218 - cross entropy: 0.2750 - mean_squared_error: 0.0820 - root_mean_squared_error: 0.2863 - tp: 29.0000 - fp: 4.0000 - tn: 415.0000 - fn: 56.0000 - binary_accuracy: 0.8810 - f1_score: 0.4915 - precision: 0.8788 - recall: 0.3412 - auc: 0.9505 - prc: 0.8113 - val_loss: 0.0645 - val_cross entropy: 0.3720 - val_mean_squared_error: 0.0922 - val_root_mean_squared_error: 0.3036 - val_tp: 1.0000 - val_fp: 3.0000 - val_tn: 47.0000 - val_fn: 5.0000 - val_binary_accuracy: 0.8571 - val_f1_score: 0.2000 - val_precision: 0.2500 - val_recall: 0.1667 - val_auc: 0.6733 - val_prc: 0.3888\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0218 - cross entropy: 0.2695 - mean_squared_error: 0.0791 - root_mean_squared_error: 0.2813 - tp: 41.0000 - fp: 5.0000 - tn: 414.0000 - fn: 44.0000 - binary_accuracy: 0.9028 - f1_score: 0.6260 - precision: 0.8913 - recall: 0.4824 - auc: 0.9537 - prc: 0.7820 - val_loss: 0.0778 - val_cross entropy: 0.4295 - val_mean_squared_error: 0.0873 - val_root_mean_squared_error: 0.2954 - val_tp: 0.0000e+00 - val_fp: 2.0000 - val_tn: 48.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8571 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6533 - val_prc: 0.2840\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0212 - cross entropy: 0.2588 - mean_squared_error: 0.0788 - root_mean_squared_error: 0.2807 - tp: 35.0000 - fp: 4.0000 - tn: 415.0000 - fn: 50.0000 - binary_accuracy: 0.8929 - f1_score: 0.5645 - precision: 0.8974 - recall: 0.4118 - auc: 0.9518 - prc: 0.8086 - val_loss: 0.0660 - val_cross entropy: 0.3787 - val_mean_squared_error: 0.0922 - val_root_mean_squared_error: 0.3037 - val_tp: 2.0000 - val_fp: 3.0000 - val_tn: 47.0000 - val_fn: 4.0000 - val_binary_accuracy: 0.8750 - val_f1_score: 0.3636 - val_precision: 0.4000 - val_recall: 0.3333 - val_auc: 0.6650 - val_prc: 0.3160\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0205 - cross entropy: 0.2390 - mean_squared_error: 0.0705 - root_mean_squared_error: 0.2654 - tp: 46.0000 - fp: 9.0000 - tn: 410.0000 - fn: 39.0000 - binary_accuracy: 0.9048 - f1_score: 0.6571 - precision: 0.8364 - recall: 0.5412 - auc: 0.9560 - prc: 0.8228 - val_loss: 0.0577 - val_cross entropy: 0.3546 - val_mean_squared_error: 0.0815 - val_root_mean_squared_error: 0.2855 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 50.0000 - val_fn: 5.0000 - val_binary_accuracy: 0.9107 - val_f1_score: 0.2857 - val_precision: 1.0000 - val_recall: 0.1667 - val_auc: 0.6850 - val_prc: 0.5322\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0215 - cross entropy: 0.2553 - mean_squared_error: 0.0774 - root_mean_squared_error: 0.2782 - tp: 36.0000 - fp: 5.0000 - tn: 414.0000 - fn: 49.0000 - binary_accuracy: 0.8929 - f1_score: 0.5714 - precision: 0.8780 - recall: 0.4235 - auc: 0.9514 - prc: 0.7900 - val_loss: 0.0651 - val_cross entropy: 0.3832 - val_mean_squared_error: 0.0827 - val_root_mean_squared_error: 0.2876 - val_tp: 2.0000 - val_fp: 1.0000 - val_tn: 49.0000 - val_fn: 4.0000 - val_binary_accuracy: 0.9107 - val_f1_score: 0.4444 - val_precision: 0.6667 - val_recall: 0.3333 - val_auc: 0.6983 - val_prc: 0.4463\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0204 - cross entropy: 0.2524 - mean_squared_error: 0.0763 - root_mean_squared_error: 0.2761 - tp: 36.0000 - fp: 3.0000 - tn: 416.0000 - fn: 49.0000 - binary_accuracy: 0.8968 - f1_score: 0.5806 - precision: 0.9231 - recall: 0.4235 - auc: 0.9574 - prc: 0.8304 - val_loss: 0.0572 - val_cross entropy: 0.3532 - val_mean_squared_error: 0.0841 - val_root_mean_squared_error: 0.2900 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 49.0000 - val_fn: 5.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.2500 - val_precision: 0.5000 - val_recall: 0.1667 - val_auc: 0.6867 - val_prc: 0.4337\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0193 - cross entropy: 0.2368 - mean_squared_error: 0.0685 - root_mean_squared_error: 0.2617 - tp: 46.0000 - fp: 7.0000 - tn: 412.0000 - fn: 39.0000 - binary_accuracy: 0.9087 - f1_score: 0.6667 - precision: 0.8679 - recall: 0.5412 - auc: 0.9627 - prc: 0.8518 - val_loss: 0.0595 - val_cross entropy: 0.3362 - val_mean_squared_error: 0.0838 - val_root_mean_squared_error: 0.2894 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 49.0000 - val_fn: 5.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.2500 - val_precision: 0.5000 - val_recall: 0.1667 - val_auc: 0.6950 - val_prc: 0.4283\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0210 - cross entropy: 0.2527 - mean_squared_error: 0.0742 - root_mean_squared_error: 0.2723 - tp: 46.0000 - fp: 7.0000 - tn: 412.0000 - fn: 39.0000 - binary_accuracy: 0.9087 - f1_score: 0.6667 - precision: 0.8679 - recall: 0.5412 - auc: 0.9551 - prc: 0.8145 - val_loss: 0.0560 - val_cross entropy: 0.3642 - val_mean_squared_error: 0.0895 - val_root_mean_squared_error: 0.2992 - val_tp: 0.0000e+00 - val_fp: 1.0000 - val_tn: 49.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8750 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7083 - val_prc: 0.2871\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0237 - cross entropy: 0.2773 - mean_squared_error: 0.0865 - root_mean_squared_error: 0.2941 - tp: 21.0000 - fp: 0.0000e+00 - tn: 419.0000 - fn: 64.0000 - binary_accuracy: 0.8730 - f1_score: 0.3962 - precision: 1.0000 - recall: 0.2471 - auc: 0.9387 - prc: 0.7598 - val_loss: 0.0809 - val_cross entropy: 0.4109 - val_mean_squared_error: 0.0846 - val_root_mean_squared_error: 0.2909 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 50.0000 - val_fn: 5.0000 - val_binary_accuracy: 0.9107 - val_f1_score: 0.2857 - val_precision: 1.0000 - val_recall: 0.1667 - val_auc: 0.6883 - val_prc: 0.3830\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0221 - cross entropy: 0.2614 - mean_squared_error: 0.0778 - root_mean_squared_error: 0.2790 - tp: 41.0000 - fp: 7.0000 - tn: 412.0000 - fn: 44.0000 - binary_accuracy: 0.8988 - f1_score: 0.6165 - precision: 0.8542 - recall: 0.4824 - auc: 0.9508 - prc: 0.7949 - val_loss: 0.0871 - val_cross entropy: 0.4253 - val_mean_squared_error: 0.0891 - val_root_mean_squared_error: 0.2984 - val_tp: 3.0000 - val_fp: 3.0000 - val_tn: 47.0000 - val_fn: 3.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000 - val_auc: 0.6367 - val_prc: 0.4719\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0246 - cross entropy: 0.2717 - mean_squared_error: 0.0813 - root_mean_squared_error: 0.2851 - tp: 32.0000 - fp: 2.0000 - tn: 417.0000 - fn: 53.0000 - binary_accuracy: 0.8909 - f1_score: 0.5378 - precision: 0.9412 - recall: 0.3765 - auc: 0.9321 - prc: 0.7819 - val_loss: 0.1227 - val_cross entropy: 0.5102 - val_mean_squared_error: 0.1260 - val_root_mean_squared_error: 0.3550 - val_tp: 3.0000 - val_fp: 6.0000 - val_tn: 44.0000 - val_fn: 3.0000 - val_binary_accuracy: 0.8393 - val_f1_score: 0.4000 - val_precision: 0.3333 - val_recall: 0.5000 - val_auc: 0.6467 - val_prc: 0.2930\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0219 - cross entropy: 0.2778 - mean_squared_error: 0.0820 - root_mean_squared_error: 0.2864 - tp: 29.0000 - fp: 5.0000 - tn: 414.0000 - fn: 56.0000 - binary_accuracy: 0.8790 - f1_score: 0.4874 - precision: 0.8529 - recall: 0.3412 - auc: 0.9520 - prc: 0.7839 - val_loss: 0.0655 - val_cross entropy: 0.3515 - val_mean_squared_error: 0.0856 - val_root_mean_squared_error: 0.2926 - val_tp: 1.0000 - val_fp: 3.0000 - val_tn: 47.0000 - val_fn: 5.0000 - val_binary_accuracy: 0.8571 - val_f1_score: 0.2000 - val_precision: 0.2500 - val_recall: 0.1667 - val_auc: 0.6683 - val_prc: 0.3883\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0200 - cross entropy: 0.2531 - mean_squared_error: 0.0750 - root_mean_squared_error: 0.2739 - tp: 32.0000 - fp: 4.0000 - tn: 415.0000 - fn: 53.0000 - binary_accuracy: 0.8869 - f1_score: 0.5289 - precision: 0.8889 - recall: 0.3765 - auc: 0.9584 - prc: 0.8184 - val_loss: 0.0655 - val_cross entropy: 0.3586 - val_mean_squared_error: 0.0809 - val_root_mean_squared_error: 0.2844 - val_tp: 2.0000 - val_fp: 3.0000 - val_tn: 47.0000 - val_fn: 4.0000 - val_binary_accuracy: 0.8750 - val_f1_score: 0.3636 - val_precision: 0.4000 - val_recall: 0.3333 - val_auc: 0.6667 - val_prc: 0.4986\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0173 - cross entropy: 0.2337 - mean_squared_error: 0.0671 - root_mean_squared_error: 0.2590 - tp: 47.0000 - fp: 3.0000 - tn: 416.0000 - fn: 38.0000 - binary_accuracy: 0.9187 - f1_score: 0.6963 - precision: 0.9400 - recall: 0.5529 - auc: 0.9687 - prc: 0.8796 - val_loss: 0.0658 - val_cross entropy: 0.3681 - val_mean_squared_error: 0.0805 - val_root_mean_squared_error: 0.2838 - val_tp: 2.0000 - val_fp: 1.0000 - val_tn: 49.0000 - val_fn: 4.0000 - val_binary_accuracy: 0.9107 - val_f1_score: 0.4444 - val_precision: 0.6667 - val_recall: 0.3333 - val_auc: 0.6867 - val_prc: 0.5052\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0145 - cross entropy: 0.2035 - mean_squared_error: 0.0574 - root_mean_squared_error: 0.2396 - tp: 55.0000 - fp: 4.0000 - tn: 415.0000 - fn: 30.0000 - binary_accuracy: 0.9325 - f1_score: 0.7639 - precision: 0.9322 - recall: 0.6471 - auc: 0.9784 - prc: 0.9133 - val_loss: 0.0699 - val_cross entropy: 0.3934 - val_mean_squared_error: 0.0913 - val_root_mean_squared_error: 0.3022 - val_tp: 1.0000 - val_fp: 3.0000 - val_tn: 47.0000 - val_fn: 5.0000 - val_binary_accuracy: 0.8571 - val_f1_score: 0.2000 - val_precision: 0.2500 - val_recall: 0.1667 - val_auc: 0.6817 - val_prc: 0.3722\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0218 - cross entropy: 0.2207 - mean_squared_error: 0.0653 - root_mean_squared_error: 0.2556 - tp: 50.0000 - fp: 8.0000 - tn: 411.0000 - fn: 35.0000 - binary_accuracy: 0.9147 - f1_score: 0.6993 - precision: 0.8621 - recall: 0.5882 - auc: 0.9574 - prc: 0.8263 - val_loss: 0.0894 - val_cross entropy: 0.4838 - val_mean_squared_error: 0.0873 - val_root_mean_squared_error: 0.2955 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 50.0000 - val_fn: 5.0000 - val_binary_accuracy: 0.9107 - val_f1_score: 0.2857 - val_precision: 1.0000 - val_recall: 0.1667 - val_auc: 0.6950 - val_prc: 0.3530\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0260 - cross entropy: 0.2866 - mean_squared_error: 0.0866 - root_mean_squared_error: 0.2942 - tp: 22.0000 - fp: 2.0000 - tn: 417.0000 - fn: 63.0000 - binary_accuracy: 0.8710 - f1_score: 0.4037 - precision: 0.9167 - recall: 0.2588 - auc: 0.9348 - prc: 0.7761 - val_loss: 0.0710 - val_cross entropy: 0.4221 - val_mean_squared_error: 0.0860 - val_root_mean_squared_error: 0.2933 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 49.0000 - val_fn: 5.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.2500 - val_precision: 0.5000 - val_recall: 0.1667 - val_auc: 0.6883 - val_prc: 0.4538\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0217 - cross entropy: 0.2678 - mean_squared_error: 0.0783 - root_mean_squared_error: 0.2799 - tp: 47.0000 - fp: 9.0000 - tn: 410.0000 - fn: 38.0000 - binary_accuracy: 0.9067 - f1_score: 0.6667 - precision: 0.8393 - recall: 0.5529 - auc: 0.9520 - prc: 0.8044 - val_loss: 0.0568 - val_cross entropy: 0.3493 - val_mean_squared_error: 0.0936 - val_root_mean_squared_error: 0.3059 - val_tp: 0.0000e+00 - val_fp: 2.0000 - val_tn: 48.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8571 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6600 - val_prc: 0.2090\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0243 - cross entropy: 0.2700 - mean_squared_error: 0.0838 - root_mean_squared_error: 0.2895 - tp: 24.0000 - fp: 4.0000 - tn: 415.0000 - fn: 61.0000 - binary_accuracy: 0.8710 - f1_score: 0.4248 - precision: 0.8571 - recall: 0.2824 - auc: 0.9354 - prc: 0.7746 - val_loss: 0.0548 - val_cross entropy: 0.3492 - val_mean_squared_error: 0.0925 - val_root_mean_squared_error: 0.3042 - val_tp: 3.0000 - val_fp: 3.0000 - val_tn: 47.0000 - val_fn: 3.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000 - val_auc: 0.7217 - val_prc: 0.4160\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0196 - cross entropy: 0.2543 - mean_squared_error: 0.0755 - root_mean_squared_error: 0.2747 - tp: 42.0000 - fp: 6.0000 - tn: 413.0000 - fn: 43.0000 - binary_accuracy: 0.9028 - f1_score: 0.6316 - precision: 0.8750 - recall: 0.4941 - auc: 0.9626 - prc: 0.8353 - val_loss: 0.0516 - val_cross entropy: 0.3327 - val_mean_squared_error: 0.0934 - val_root_mean_squared_error: 0.3055 - val_tp: 2.0000 - val_fp: 4.0000 - val_tn: 46.0000 - val_fn: 4.0000 - val_binary_accuracy: 0.8571 - val_f1_score: 0.3333 - val_precision: 0.3333 - val_recall: 0.3333 - val_auc: 0.7167 - val_prc: 0.4845\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0177 - cross entropy: 0.2267 - mean_squared_error: 0.0664 - root_mean_squared_error: 0.2576 - tp: 43.0000 - fp: 6.0000 - tn: 413.0000 - fn: 42.0000 - binary_accuracy: 0.9048 - f1_score: 0.6418 - precision: 0.8776 - recall: 0.5059 - auc: 0.9700 - prc: 0.8628 - val_loss: 0.0904 - val_cross entropy: 0.4359 - val_mean_squared_error: 0.1103 - val_root_mean_squared_error: 0.3321 - val_tp: 2.0000 - val_fp: 4.0000 - val_tn: 46.0000 - val_fn: 4.0000 - val_binary_accuracy: 0.8571 - val_f1_score: 0.3333 - val_precision: 0.3333 - val_recall: 0.3333 - val_auc: 0.6567 - val_prc: 0.4067\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0171 - cross entropy: 0.2273 - mean_squared_error: 0.0669 - root_mean_squared_error: 0.2587 - tp: 39.0000 - fp: 5.0000 - tn: 414.0000 - fn: 46.0000 - binary_accuracy: 0.8988 - f1_score: 0.6047 - precision: 0.8864 - recall: 0.4588 - auc: 0.9713 - prc: 0.8706 - val_loss: 0.0823 - val_cross entropy: 0.4226 - val_mean_squared_error: 0.0981 - val_root_mean_squared_error: 0.3133 - val_tp: 1.0000 - val_fp: 3.0000 - val_tn: 47.0000 - val_fn: 5.0000 - val_binary_accuracy: 0.8571 - val_f1_score: 0.2000 - val_precision: 0.2500 - val_recall: 0.1667 - val_auc: 0.6717 - val_prc: 0.2859\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0223 - cross entropy: 0.2400 - mean_squared_error: 0.0708 - root_mean_squared_error: 0.2660 - tp: 44.0000 - fp: 6.0000 - tn: 413.0000 - fn: 41.0000 - binary_accuracy: 0.9067 - f1_score: 0.6519 - precision: 0.8800 - recall: 0.5176 - auc: 0.9484 - prc: 0.8357 - val_loss: 0.0714 - val_cross entropy: 0.4034 - val_mean_squared_error: 0.0979 - val_root_mean_squared_error: 0.3128 - val_tp: 2.0000 - val_fp: 3.0000 - val_tn: 47.0000 - val_fn: 4.0000 - val_binary_accuracy: 0.8750 - val_f1_score: 0.3636 - val_precision: 0.4000 - val_recall: 0.3333 - val_auc: 0.6433 - val_prc: 0.2584\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0208 - cross entropy: 0.2599 - mean_squared_error: 0.0749 - root_mean_squared_error: 0.2736 - tp: 42.0000 - fp: 5.0000 - tn: 414.0000 - fn: 43.0000 - binary_accuracy: 0.9048 - f1_score: 0.6364 - precision: 0.8936 - recall: 0.4941 - auc: 0.9507 - prc: 0.8333 - val_loss: 0.0990 - val_cross entropy: 0.4590 - val_mean_squared_error: 0.1006 - val_root_mean_squared_error: 0.3172 - val_tp: 3.0000 - val_fp: 4.0000 - val_tn: 46.0000 - val_fn: 3.0000 - val_binary_accuracy: 0.8750 - val_f1_score: 0.4615 - val_precision: 0.4286 - val_recall: 0.5000 - val_auc: 0.6550 - val_prc: 0.2805\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0156 - cross entropy: 0.2273 - mean_squared_error: 0.0628 - root_mean_squared_error: 0.2507 - tp: 52.0000 - fp: 3.0000 - tn: 416.0000 - fn: 33.0000 - binary_accuracy: 0.9286 - f1_score: 0.7429 - precision: 0.9455 - recall: 0.6118 - auc: 0.9754 - prc: 0.9106 - val_loss: 0.0567 - val_cross entropy: 0.3517 - val_mean_squared_error: 0.0935 - val_root_mean_squared_error: 0.3057 - val_tp: 0.0000e+00 - val_fp: 3.0000 - val_tn: 47.0000 - val_fn: 6.0000 - val_binary_accuracy: 0.8393 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6600 - val_prc: 0.2178\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0165 - cross entropy: 0.2127 - mean_squared_error: 0.0609 - root_mean_squared_error: 0.2469 - tp: 53.0000 - fp: 5.0000 - tn: 414.0000 - fn: 32.0000 - binary_accuracy: 0.9266 - f1_score: 0.7413 - precision: 0.9138 - recall: 0.6235 - auc: 0.9723 - prc: 0.8836 - val_loss: 0.0575 - val_cross entropy: 0.3378 - val_mean_squared_error: 0.0886 - val_root_mean_squared_error: 0.2976 - val_tp: 2.0000 - val_fp: 3.0000 - val_tn: 47.0000 - val_fn: 4.0000 - val_binary_accuracy: 0.8750 - val_f1_score: 0.3636 - val_precision: 0.4000 - val_recall: 0.3333 - val_auc: 0.7317 - val_prc: 0.4314\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0202 - cross entropy: 0.2255 - mean_squared_error: 0.0670 - root_mean_squared_error: 0.2588 - tp: 54.0000 - fp: 6.0000 - tn: 413.0000 - fn: 31.0000 - binary_accuracy: 0.9266 - f1_score: 0.7448 - precision: 0.9000 - recall: 0.6353 - auc: 0.9589 - prc: 0.8403 - val_loss: 0.0957 - val_cross entropy: 0.4214 - val_mean_squared_error: 0.1266 - val_root_mean_squared_error: 0.3559 - val_tp: 3.0000 - val_fp: 7.0000 - val_tn: 43.0000 - val_fn: 3.0000 - val_binary_accuracy: 0.8214 - val_f1_score: 0.3750 - val_precision: 0.3000 - val_recall: 0.5000 - val_auc: 0.6833 - val_prc: 0.2693\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0196 - cross entropy: 0.2350 - mean_squared_error: 0.0718 - root_mean_squared_error: 0.2679 - tp: 37.0000 - fp: 5.0000 - tn: 414.0000 - fn: 48.0000 - binary_accuracy: 0.8948 - f1_score: 0.5827 - precision: 0.8810 - recall: 0.4353 - auc: 0.9621 - prc: 0.8259 - val_loss: 0.0659 - val_cross entropy: 0.3777 - val_mean_squared_error: 0.0956 - val_root_mean_squared_error: 0.3091 - val_tp: 2.0000 - val_fp: 3.0000 - val_tn: 47.0000 - val_fn: 4.0000 - val_binary_accuracy: 0.8750 - val_f1_score: 0.3636 - val_precision: 0.4000 - val_recall: 0.3333 - val_auc: 0.6833 - val_prc: 0.3267\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0189 - cross entropy: 0.2508 - mean_squared_error: 0.0740 - root_mean_squared_error: 0.2721 - tp: 38.0000 - fp: 7.0000 - tn: 412.0000 - fn: 47.0000 - binary_accuracy: 0.8929 - f1_score: 0.5846 - precision: 0.8444 - recall: 0.4471 - auc: 0.9655 - prc: 0.8433 - val_loss: 0.0599 - val_cross entropy: 0.3674 - val_mean_squared_error: 0.0977 - val_root_mean_squared_error: 0.3126 - val_tp: 3.0000 - val_fp: 4.0000 - val_tn: 46.0000 - val_fn: 3.0000 - val_binary_accuracy: 0.8750 - val_f1_score: 0.4615 - val_precision: 0.4286 - val_recall: 0.5000 - val_auc: 0.6933 - val_prc: 0.2394\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0163 - cross entropy: 0.2173 - mean_squared_error: 0.0631 - root_mean_squared_error: 0.2512 - tp: 47.0000 - fp: 3.0000 - tn: 416.0000 - fn: 38.0000 - binary_accuracy: 0.9187 - f1_score: 0.6963 - precision: 0.9400 - recall: 0.5529 - auc: 0.9726 - prc: 0.8918 - val_loss: 0.0728 - val_cross entropy: 0.3853 - val_mean_squared_error: 0.0980 - val_root_mean_squared_error: 0.3131 - val_tp: 1.0000 - val_fp: 4.0000 - val_tn: 46.0000 - val_fn: 5.0000 - val_binary_accuracy: 0.8393 - val_f1_score: 0.1818 - val_precision: 0.2000 - val_recall: 0.1667 - val_auc: 0.7000 - val_prc: 0.3713\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0218 - cross entropy: 0.2217 - mean_squared_error: 0.0671 - root_mean_squared_error: 0.2590 - tp: 51.0000 - fp: 11.0000 - tn: 408.0000 - fn: 34.0000 - binary_accuracy: 0.9107 - f1_score: 0.6939 - precision: 0.8226 - recall: 0.6000 - auc: 0.9632 - prc: 0.7843 - val_loss: 0.0653 - val_cross entropy: 0.3771 - val_mean_squared_error: 0.0834 - val_root_mean_squared_error: 0.2888 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 48.0000 - val_fn: 5.0000 - val_binary_accuracy: 0.8750 - val_f1_score: 0.2222 - val_precision: 0.3333 - val_recall: 0.1667 - val_auc: 0.6900 - val_prc: 0.4291\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0192 - cross entropy: 0.2510 - mean_squared_error: 0.0747 - root_mean_squared_error: 0.2734 - tp: 35.0000 - fp: 4.0000 - tn: 415.0000 - fn: 50.0000 - binary_accuracy: 0.8929 - f1_score: 0.5645 - precision: 0.8974 - recall: 0.4118 - auc: 0.9639 - prc: 0.8500 - val_loss: 0.0517 - val_cross entropy: 0.3348 - val_mean_squared_error: 0.0925 - val_root_mean_squared_error: 0.3041 - val_tp: 2.0000 - val_fp: 3.0000 - val_tn: 47.0000 - val_fn: 4.0000 - val_binary_accuracy: 0.8750 - val_f1_score: 0.3636 - val_precision: 0.4000 - val_recall: 0.3333 - val_auc: 0.7450 - val_prc: 0.3299\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0171 - cross entropy: 0.2294 - mean_squared_error: 0.0681 - root_mean_squared_error: 0.2610 - tp: 41.0000 - fp: 4.0000 - tn: 415.0000 - fn: 44.0000 - binary_accuracy: 0.9048 - f1_score: 0.6308 - precision: 0.9111 - recall: 0.4824 - auc: 0.9742 - prc: 0.8710 - val_loss: 0.0746 - val_cross entropy: 0.4008 - val_mean_squared_error: 0.0867 - val_root_mean_squared_error: 0.2944 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 49.0000 - val_fn: 5.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.2500 - val_precision: 0.5000 - val_recall: 0.1667 - val_auc: 0.6633 - val_prc: 0.3764\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0168 - cross entropy: 0.1996 - mean_squared_error: 0.0592 - root_mean_squared_error: 0.2434 - tp: 51.0000 - fp: 4.0000 - tn: 415.0000 - fn: 34.0000 - binary_accuracy: 0.9246 - f1_score: 0.7286 - precision: 0.9273 - recall: 0.6000 - auc: 0.9716 - prc: 0.8849 - val_loss: 0.1018 - val_cross entropy: 0.4506 - val_mean_squared_error: 0.1127 - val_root_mean_squared_error: 0.3356 - val_tp: 3.0000 - val_fp: 4.0000 - val_tn: 46.0000 - val_fn: 3.0000 - val_binary_accuracy: 0.8750 - val_f1_score: 0.4615 - val_precision: 0.4286 - val_recall: 0.5000 - val_auc: 0.6500 - val_prc: 0.2866\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0199 - cross entropy: 0.2271 - mean_squared_error: 0.0705 - root_mean_squared_error: 0.2656 - tp: 33.0000 - fp: 8.0000 - tn: 411.0000 - fn: 52.0000 - binary_accuracy: 0.8810 - f1_score: 0.5238 - precision: 0.8049 - recall: 0.3882 - auc: 0.9640 - prc: 0.7901 - val_loss: 0.0682 - val_cross entropy: 0.3897 - val_mean_squared_error: 0.0822 - val_root_mean_squared_error: 0.2866 - val_tp: 2.0000 - val_fp: 2.0000 - val_tn: 48.0000 - val_fn: 4.0000 - val_binary_accuracy: 0.8929 - val_f1_score: 0.4000 - val_precision: 0.5000 - val_recall: 0.3333 - val_auc: 0.6800 - val_prc: 0.4489\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0174 - cross entropy: 0.2151 - mean_squared_error: 0.0636 - root_mean_squared_error: 0.2522 - tp: 45.0000 - fp: 1.0000 - tn: 418.0000 - fn: 40.0000 - binary_accuracy: 0.9187 - f1_score: 0.6870 - precision: 0.9783 - recall: 0.5294 - auc: 0.9728 - prc: 0.8792 - val_loss: 0.0699 - val_cross entropy: 0.3877 - val_mean_squared_error: 0.0906 - val_root_mean_squared_error: 0.3010 - val_tp: 2.0000 - val_fp: 4.0000 - val_tn: 46.0000 - val_fn: 4.0000 - val_binary_accuracy: 0.8571 - val_f1_score: 0.3333 - val_precision: 0.3333 - val_recall: 0.3333 - val_auc: 0.6850 - val_prc: 0.4884\n",
      "Epoch 78/100\n",
      " 5/16 [========>.....................] - ETA: 0s - loss: 0.0144 - cross entropy: 0.2215 - mean_squared_error: 0.0643 - root_mean_squared_error: 0.2536 - tp: 21.0000 - fp: 0.0000e+00 - tn: 127.0000 - fn: 12.0000 - binary_accuracy: 0.9250 - f1_score: 0.7778 - precision: 1.0000 - recall: 0.6364 - auc: 0.9841 - prc: 0.9525"
     ]
    }
   ],
   "source": [
    "# Begin the search\n",
    "EPOCHS = 100\n",
    "\n",
    "tuner.search(\n",
    "    input_train_scaled,\n",
    "    label_train_scaled,\n",
    "    epochs=EPOCHS,\n",
    "    validation_split=0.1\n",
    ")\n",
    "\n",
    "# Query the tuner object to grab the best models\n",
    "models = tuner.get_best_models(num_models=5)\n",
    "\n",
    "# Here is the best model from the tuner\n",
    "best_model = models[0]\n",
    "print(best_model.summary())\n",
    "\n",
    "# Get the top hyperparameters.\n",
    "best_hps = tuner.get_best_hyperparameters()\n",
    "\n",
    "# Build the model with the best hyperparameters.\n",
    "# Assuming your MyHyperModel has a build method that takes a hyperparameter object.\n",
    "model = MyHyperModel().build(best_hps[0])\n",
    "\n",
    "# Save the best model (architecture and weights)\n",
    "\n",
    "save_dir = \"/glade/derecho/scratch/rmandava/AEW_time_location_files/models\"\n",
    "model_save_path = os.path.join(save_dir, model_save_name)\n",
    "\n",
    "model.save(model_save_path)\n",
    "\n",
    "\n",
    "# Retrain using \"best\" model hyperparameters\n",
    "history = model.fit(\n",
    "    input_train_scaled,\n",
    "    label_train_scaled,\n",
    "    epochs=EPOCHS,\n",
    "    validation_split=0.1,\n",
    "    batch_size= 32,\n",
    "    # callbacks=keras.callbacks.EarlyStopping('val_loss', patience=3),\n",
    "    shuffle=True,\n",
    "    class_weight=class_weight,  # Ensure 'class_weight' is defined in your scope\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test data using `evaluate`\n",
    "results = model.evaluate(input_test_scaled, label_test_scaled, batch_size=label_test_scaled.shape[0])\n",
    "print(results)\n",
    "\n",
    "# Generate predictions (probabilities—the output of the last layer)\n",
    "predictions = model.predict(input_test_scaled)\n",
    "print(\"predictions shape:\", predictions.shape)\n",
    "\n",
    "# Compute confusion matrix elements\n",
    "tn, fp, fn, tp = sklearn.metrics.confusion_matrix(\n",
    "    label_test_scaled, np.round(predictions)\n",
    ").ravel()\n",
    "print(\"tn:\", tn)\n",
    "print(\"fp:\", fp)\n",
    "print(\"fn:\", fn)\n",
    "print(\"tp:\", tp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8883c1-4450-444a-88a5-18ed3d94d588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# —— Ensemble top K models —— \n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "# 1) Grab the top K hyperparameters\n",
    "top_hps = tuner.get_best_hyperparameters(num_trials=5)\n",
    "\n",
    "# 2) Rebuild each best model\n",
    "models = [ MyHyperModel().build(hp) for hp in top_hps ]\n",
    "# (Or, if you saved weights per trial, load them here onto each model.)\n",
    "\n",
    "# 3) Run each model on the test set\n",
    "all_preds = np.stack([m.predict(input_test_scaled).flatten() for m in models], axis=0)\n",
    "\n",
    "# 4) Average their probabilities & threshold\n",
    "ensemble_probs = all_preds.mean(axis=0)\n",
    "ensemble_preds = (ensemble_probs >= 0.5).astype(int)\n",
    "\n",
    "# 5) Compute & print ensemble F1\n",
    "print(\"Ensemble F1:\", f1_score(label_test_scaled, ensemble_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d463e2-12e7-474b-95c1-ae20c22a093c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = np.round(predictions.flatten())\n",
    "true_labels = label_test_scaled.flatten()\n",
    "false_neg_idx = np.where((true_labels == 1) & (pred_labels == 0))[0]\n",
    "false_pos_idx = np.where((true_labels == 0) & (pred_labels == 1))[0]\n",
    "true_pos_idx = np.where((true_labels == 1) & (pred_labels == 1))[0]\n",
    "true_neg_idx = np.where((true_labels == 0) & (pred_labels == 0))[0]\n",
    "\n",
    "print(\"Number of false negatives:\", len(false_neg_idx))\n",
    "print(\"Number of false positives:\", len(false_pos_idx))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6ddefd-a847-4a5c-a028-ca25e1e1d87c",
   "metadata": {
    "papermill": {
     "duration": 0.042059,
     "end_time": "2025-03-05T20:46:02.526276",
     "exception": false,
     "start_time": "2025-03-05T20:46:02.484217",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming lat_test and lon_test are arrays with shape (num_samples, height, width)\n",
    "#central_lat = lat_test[:, lat_test.shape[1]//2, lat_test.shape[2]//2]\n",
    "#central_lon = lon_test[:, lon_test.shape[1]//2, lon_test.shape[2]//2]\n",
    "\n",
    "#lats_false_neg = central_lat[false_neg_idx]\n",
    "#lons_false_neg = central_lon[false_neg_idx]\n",
    "\n",
    "#lats_false_pos = central_lat[false_pos_idx]\n",
    "#lons_false_pos = central_lon[false_pos_idx]\n",
    "# Assuming lat_test and lon_test are 1D arrays with one coordinate per sample\n",
    "lat_false_neg = lat_test[false_neg_idx]\n",
    "lon_false_neg = lon_test[false_neg_idx]\n",
    "\n",
    "lat_false_pos = lat_test[false_pos_idx]\n",
    "lon_false_pos = lon_test[false_pos_idx]\n",
    "\n",
    "lat_true_pos = lat_test[true_pos_idx]\n",
    "lon_true_pos = lon_test[true_pos_idx]\n",
    "\n",
    "lat_true_neg = lat_test[true_neg_idx]\n",
    "lon_true_neg = lon_test[true_neg_idx]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798796b5-b155-48c8-bd46-4c1a1f5fedba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Unique latitudes in test set:\", np.unique(lat_test))\n",
    "print(\"Unique longitudes in test set:\", np.unique(lon_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0f4581-4248-48f1-bd51-5d4bb476f030",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(lon_false_neg, lat_false_neg, marker='x', color='red', label='False Negatives')\n",
    "plt.scatter(lon_false_pos, lat_false_pos, marker='o', color='blue', label='False Positives')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.title('Geographic Distribution of Misclassifications')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f3eb33-d853-48b3-8416-46e48cd99444",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512e75d1-8ea6-4a7e-90c9-aaf6ad6d5a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "\n",
    "\n",
    "\n",
    "lon_min, lon_max = np.min(lon_test)-15, np.max(lon_test)+15\n",
    "lat_min, lat_max = np.min(lat_test)-15, np.max(lat_test)+15\n",
    "ax.set_extent([lon_min, lon_max, lat_min, lat_max], crs=ccrs.PlateCarree())\n",
    "\n",
    "# Add map features\n",
    "ax.add_feature(cfeature.COASTLINE, linewidth=0.5)\n",
    "ax.add_feature(cfeature.BORDERS, linestyle=':', linewidth=0.5)\n",
    "ax.add_feature(cfeature.LAND, edgecolor='black', facecolor='lightgray')\n",
    "ax.add_feature(cfeature.OCEAN, facecolor='lightblue')\n",
    "\n",
    "# Plot misclassified points:\n",
    "ax.scatter(lon_false_neg, lat_false_neg, color='red', marker='x', s=100,\n",
    "           transform=ccrs.PlateCarree(), label='False Negatives')\n",
    "ax.scatter(lon_false_pos, lat_false_pos, color='blue', marker='o', s=100,\n",
    "           transform=ccrs.PlateCarree(), label='False Positives')\n",
    "\n",
    "plt.title(\"Misclassified Test Samples on Map\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4561912c-9788-442a-a527-f125871dbce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "\n",
    "# Set map extent (adjust margins as desired)\n",
    "lon_min, lon_max = np.min(lon_test) - 10, np.max(lon_test) + 10\n",
    "lat_min, lat_max = np.min(lat_test) - 10, np.max(lat_test) + 10\n",
    "ax.set_extent([lon_min, lon_max, lat_min, lat_max], crs=ccrs.PlateCarree())\n",
    "\n",
    "# Add map features\n",
    "ax.add_feature(cfeature.COASTLINE, linewidth=0.5)\n",
    "ax.add_feature(cfeature.BORDERS, linestyle=':', linewidth=0.5)\n",
    "ax.add_feature(cfeature.LAND, facecolor='lightgray', edgecolor='black')\n",
    "ax.add_feature(cfeature.OCEAN, facecolor='lightblue')\n",
    "# Plot misclassified points\n",
    "ax.scatter(lon_false_neg, lat_false_neg, color='red', marker='x', s=100,\n",
    "           transform=ccrs.PlateCarree(), label='False Negatives')\n",
    "ax.scatter(lon_false_pos, lat_false_pos, color='blue', marker='o', s=100,\n",
    "           transform=ccrs.PlateCarree(), label='False Positives')\n",
    "\n",
    "\n",
    "\n",
    "# Plot correctly classified points\n",
    "ax.scatter(lon_true_pos, lat_true_pos, color='green', marker='^', s=100,\n",
    "           transform=ccrs.PlateCarree(), label='True Positives')\n",
    "ax.scatter(lon_true_neg, lat_true_neg, color='orange', marker='s', s=100,\n",
    "           transform=ccrs.PlateCarree(), label='True Negatives')\n",
    "\n",
    "plt.title(\"Test Set Classification Results on Map\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffe393f-a6c9-440d-b648-78010a1d0ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total samples:\", len(sample_lat))\n",
    "print(\"Unique latitudes:\", len(np.unique(sample_lat)))\n",
    "print(\"Unique longitudes:\", len(np.unique(sample_lon)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e932dda-37e1-4158-8655-7d2a041a1a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First 10 latitudes:\", sample_lat[:10])\n",
    "print(\"First 10 longitudes:\", sample_lon[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe686778-d179-4dec-8b2e-472700d70e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(sample_lon, sample_lat, c='green', marker='o')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.title('Per-Sample Weighted Centroid Coordinates')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5563a928-7d7f-402d-94e1-63dd0cff0982",
   "metadata": {
    "papermill": {
     "duration": 13.848113,
     "end_time": "2025-03-05T20:46:16.415723",
     "exception": false,
     "start_time": "2025-03-05T20:46:02.567610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# --- Permutation Importance ---\n",
    "# Evaluate baseline performance using your loss metric (here, the custom f1_loss_sigmoid)\n",
    "# model.metrics_names gives a list where index 0 is 'loss'\n",
    "baseline_results = model.evaluate(input_test_scaled, label_test_scaled,\n",
    "                                  batch_size=label_test_scaled.shape[0],\n",
    "                                  verbose=0)\n",
    "baseline_loss = baseline_results[model.metrics_names.index('loss')]\n",
    "print(\"Baseline loss:\", baseline_loss)\n",
    "\n",
    "# Set the number of repetitions for averaging\n",
    "n_repeats = 5\n",
    "n_features = input_test_scaled.shape[-1]\n",
    "permutation_importances = np.zeros(n_features)\n",
    "\n",
    "# Loop over each feature (channel)\n",
    "for feature_idx in range(n_features):\n",
    "    permuted_losses = []\n",
    "    for _ in range(n_repeats):\n",
    "        # Copy the test set to avoid modifying the original\n",
    "        X_permuted = np.copy(input_test_scaled)\n",
    "        # Permute the values of the selected feature across samples\n",
    "        perm = np.random.permutation(X_permuted.shape[0])\n",
    "        X_permuted[:, :, :, feature_idx] = X_permuted[perm, :, :, feature_idx]\n",
    "        \n",
    "        # Evaluate the model on the permuted test set\n",
    "        permuted_results = model.evaluate(X_permuted, label_test_scaled,\n",
    "                                          batch_size=label_test_scaled.shape[0],\n",
    "                                          verbose=0)\n",
    "        permuted_loss = permuted_results[model.metrics_names.index('loss')]\n",
    "        permuted_losses.append(permuted_loss)\n",
    "    \n",
    "    avg_permuted_loss = np.mean(permuted_losses)\n",
    "    # The difference between the permuted loss and baseline loss indicates feature importance:\n",
    "    # A larger increase means the feature is more important.\n",
    "    permutation_importances[feature_idx] = avg_permuted_loss - baseline_loss\n",
    "    print(f\"Feature {feature_idx} - Increase in Loss: {permutation_importances[feature_idx]}\")\n",
    "\n",
    "print(\"Permutation Importances (increase in loss) for all features:\", permutation_importances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23e4f15-e79e-4040-b328-2096906415f9",
   "metadata": {
    "papermill": {
     "duration": 0.467125,
     "end_time": "2025-03-05T20:46:16.925109",
     "exception": false,
     "start_time": "2025-03-05T20:46:16.457984",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Suppose permutation_importances is the numpy array you printed:\n",
    "# e.g., [0.0820, 0.0824, 0.0815, 0.0864, 0.0121, ...]\n",
    "\n",
    "feature_indices = np.arange(len(permutation_importances))\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(feature_indices, permutation_importances)\n",
    "plt.xlabel(\"Feature Index\")\n",
    "plt.ylabel(\"Increase in Loss (Permutation Importance)\")\n",
    "plt.title(\"Permutation Importance by Feature\")\n",
    "plt.xticks(feature_indices, [f\"F{i}\" for i in feature_indices], rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1765f8b0-69ed-4917-82f7-f15ef12cc837",
   "metadata": {
    "papermill": {
     "duration": 0.043518,
     "end_time": "2025-03-05T20:46:17.012058",
     "exception": false,
     "start_time": "2025-03-05T20:46:16.968540",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_index = 0\n",
    "sample_input = input_test_scaled[sample_index:sample_index+1]\n",
    "\n",
    "# Compute the saliency map for the selected test sample\n",
    "saliency_map = compute_saliency_map(model, sample_input)\n",
    "\n",
    "# Plot the saliency map\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(saliency_map, cmap='hot')\n",
    "plt.colorbar()\n",
    "plt.title(f\"Saliency Map for Sample Index {sample_index}\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa54c93-f08a-46e2-a610-95424eb79806",
   "metadata": {
    "papermill": {
     "duration": 0.042628,
     "end_time": "2025-03-05T20:46:17.098037",
     "exception": false,
     "start_time": "2025-03-05T20:46:17.055409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_index = 1\n",
    "sample_input = input_test_scaled[sample_index:sample_index+1]\n",
    "\n",
    "# Compute saliency maps per channel for the selected input sample\n",
    "saliency_maps, channel_importance = compute_saliency_per_channel(model, sample_input)\n",
    "\n",
    "# Plot the saliency maps for each channel\n",
    "num_channels = saliency_maps.shape[-1]\n",
    "cols = 5  # Set number of columns for plotting\n",
    "rows = int(np.ceil(num_channels / cols))\n",
    "plt.figure(figsize=(15, rows * 3))\n",
    "for c in range(num_channels):\n",
    "    plt.subplot(rows, cols, c + 1)\n",
    "    plt.imshow(saliency_maps[:, :, c], cmap='hot')\n",
    "    plt.title(f'Channel {c}\\nMean: {channel_importance[c]:.4f}')\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print aggregated channel importance values\n",
    "print(\"Channel importance (mean saliency per channel):\")\n",
    "for c, imp in enumerate(channel_importance):\n",
    "    print(f\"Channel {c}: {imp:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfec3979-63a3-4211-9475-3445ad530009",
   "metadata": {
    "papermill": {
     "duration": 0.043201,
     "end_time": "2025-03-05T20:46:17.184585",
     "exception": false,
     "start_time": "2025-03-05T20:46:17.141384",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1) Compute per‑sample, per‑channel saliency importances\n",
    "all_imps = []\n",
    "for x in input_test_scaled:             # each x has shape (32,32,channels)\n",
    "    _, imp = compute_saliency_per_channel(best_model, x[np.newaxis,...])\n",
    "    all_imps.append(imp)               # imp.shape == (channels,)\n",
    "all_imps = np.stack(all_imps)          # shape (N_samples, channels)\n",
    "\n",
    "# 2) Average importance across samples\n",
    "mean_imp = all_imps.mean(axis=0)       # shape (channels,)\n",
    "\n",
    "# 3) Build a DataFrame mapping feature→plevel→importance\n",
    "df = pd.DataFrame({\n",
    "    \"feature\": var_list,\n",
    "    \"plevel\": plevel_list,\n",
    "    \"importance\": mean_imp\n",
    "})\n",
    "\n",
    "# 4) Group by pressure level and plot\n",
    "grouped = df.groupby(\"plevel\")[\"importance\"].mean().reset_index()\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.bar(grouped[\"plevel\"].astype(str), grouped[\"importance\"])\n",
    "plt.xlabel(\"Pressure level (hPa or False=surface)\")\n",
    "plt.ylabel(\"Mean saliency importance\")\n",
    "plt.title(\"Average feature importance by pressure level\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f421b06b-75d2-4e23-beb0-dbb5f6c6240f",
   "metadata": {
    "papermill": {
     "duration": 0.041979,
     "end_time": "2025-03-05T20:46:17.268705",
     "exception": false,
     "start_time": "2025-03-05T20:46:17.226726",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1) Print out full test‐set metrics by name\n",
    "test_results = model.evaluate(\n",
    "    input_test_scaled,\n",
    "    label_test_scaled,\n",
    "    batch_size=label_test_scaled.shape[0],\n",
    "    verbose=0\n",
    ")\n",
    "print(dict(zip(model.metrics_names, test_results)))\n",
    "\n",
    "# 2) Peek at the end of your training history for F1 improvements\n",
    "import pandas as pd\n",
    "hist_df = pd.DataFrame(history.history)\n",
    "print(hist_df[['f1_score','val_f1_score']].tail())\n",
    "\n",
    "# 3) (Optional) Plot train vs. val F1 over epochs\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(hist_df['f1_score'],    label='train F1')\n",
    "plt.plot(hist_df['val_f1_score'],label='val F1')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.legend()\n",
    "plt.title('Focal‐Loss Training F1 Curves')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b46d58-ad34-4817-a519-c9152372b7d4",
   "metadata": {
    "papermill": {
     "duration": 0.047731,
     "end_time": "2025-03-05T20:46:17.359595",
     "exception": false,
     "start_time": "2025-03-05T20:46:17.311864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replace your rebuild logic:\n",
    "# top_hps = tuner.get_best_hyperparameters(num_trials=5)\n",
    "# models  = [MyHyperModel().build(hp) for hp in top_hps]\n",
    "\n",
    "# With this single line:\n",
    "models = tuner.get_best_models(num_models=5)\n",
    "\n",
    "# Then stack and average as before:\n",
    "all_preds     = np.stack([m.predict(input_test_scaled).flatten() for m in models], axis=0)\n",
    "ensemble_probs= all_preds.mean(axis=0)\n",
    "ensemble_preds= (ensemble_probs >= 0.5).astype(int)\n",
    "print(\"Ensemble F1:\", f1_score(label_test_scaled, ensemble_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae3ef17-24f6-4569-8095-2bdee2e67245",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa32367f-578a-4d6c-abda-25f517326f92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a400de0-e033-42a0-9271-eb725e4f2bb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7035.678234,
   "end_time": "2025-03-05T20:46:20.341478",
   "environment_variables": {},
   "exception": null,
   "input_path": "Hurricaneoriginal(300).ipynb",
   "output_path": "output_notebook_var(second)0.ipynb",
   "parameters": {
    "aew_subset": "12hr_before",
    "model_save_name": "best_model_var0.keras",
    "plevel_list": [
     false,
     false,
     300,
     false,
     false,
     false,
     300,
     300,
     850,
     300,
     850,
     false,
     false,
     false,
     false,
     300,
     850,
     false,
     300,
     850,
     300,
     850,
     300,
     300,
     850
    ],
    "tuner_project_name": "tuner_run(second)_0",
    "var_list": [
     "cape",
     "crr",
     "d",
     "ie",
     "ishf",
     "lsrr",
     "pv",
     "q",
     "q",
     "r",
     "r",
     "sp",
     "sstk",
     "tcw",
     "tcwv",
     "t",
     "t",
     "ttr",
     "u",
     "u",
     "v",
     "v",
     "vo",
     "w",
     "w"
    ]
   },
   "start_time": "2025-03-05T18:49:04.663244",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
