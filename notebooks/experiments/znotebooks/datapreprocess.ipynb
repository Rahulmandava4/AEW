{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9fba430-b220-434a-ac3a-fc3888f38e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-31 01:33:42.645899: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-31 01:33:42.665186: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1738312422.685882   49857 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1738312422.692118   49857 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-31 01:33:42.714669: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "# coding: utf-8\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import xarray as xr\n",
    "\n",
    "import sklearn\n",
    "\n",
    "import sklearn.model_selection\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras import layers\n",
    "\n",
    "import keras_tuner\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "keras.utils.set_random_seed(812)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70034f7d-9bd6-47c7-b052-8089f3cdf981",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_list = [\"cape\", \"crr\",  \"ie\", \"ishf\", \"lsrr\",  \"sp\", \"sstk\", \"tcw\", \"tcwv\", \"ttr\" ] #ERA5 variables\n",
    "\n",
    "aew_subset = \"12hr_before\" #time of interest\n",
    "\n",
    "plevel_list = [False, False,  False, False, False,   False, False, False, False,  False ] #pressure levels of variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f543c968-68f0-4e82-83b3-9602906cf7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_dim(ds):\n",
    "    \"\"\"\n",
    "    Preprocessing help when opening netcdf files.\n",
    "    \"\"\"\n",
    "    return ds.assign_coords({\"sample\": 1}).expand_dims(dim={\"sample\": 1}).drop_vars(\n",
    "        'utc_date').drop_vars(\"latitude\").drop_vars('longitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a6cb8f0-e3f0-4a83-9f1a-60d0184d12ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_files(list_of_vars, aew_subset=\"12hr_before\",\n",
    "\n",
    "              directory=\"/glade/derecho/scratch/rmandava/AEW_time_location_files/\",\n",
    "\n",
    "              plevel_list=None):\n",
    "\n",
    "   \"\"\"\n",
    "\n",
    "   Help opening variables for training.\n",
    "\n",
    "   \"\"\"\n",
    "\n",
    "   datas = {}\n",
    "\n",
    "\n",
    "   for num, var in enumerate(list_of_vars):\n",
    "\n",
    "\n",
    "         if not plevel_list:\n",
    "\n",
    "\n",
    "           datas[var] = xr.open_mfdataset(\n",
    "\n",
    "           f'{directory}/{var}/aew_{aew_subset}_*.nc',\n",
    "\n",
    "           preprocess=add_dim,\n",
    "\n",
    "           concat_dim=\"sample\",\n",
    "\n",
    "           combine=\"nested\",\n",
    "\n",
    "           )\n",
    "         if plevel_list:\n",
    "\n",
    "\n",
    "              if not plevel_list[num]:\n",
    "\n",
    "\n",
    "                 datas[var] = xr.open_mfdataset(\n",
    "\n",
    "                 f'{directory}/{var}/aew_{aew_subset}_*.nc',\n",
    "\n",
    "                 preprocess=add_dim,\n",
    "\n",
    "                 concat_dim=\"sample\",\n",
    "\n",
    "                 combine=\"nested\",\n",
    "\n",
    "                 )\n",
    "              if plevel_list[num]:\n",
    "\n",
    "\n",
    "                 datas[f'{var}_{int(plevel_list[num])}'] = xr.open_mfdataset(\n",
    "\n",
    "                 f'{directory}/{var}/aew_{aew_subset}_{int(plevel_list[num])}_*.nc',\n",
    "\n",
    "                 preprocess=add_dim,\n",
    "\n",
    "                 concat_dim=\"sample\",\n",
    "\n",
    "                 combine=\"nested\",\n",
    "\n",
    "                 )\n",
    "   return datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b40e6839-3d9d-479b-9ecd-18bc29e9ce29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: cape\n",
      "<xarray.Dataset> Size: 11MB\n",
      "Dimensions:  (sample: 2750, latitude: 32, longitude: 32)\n",
      "Coordinates:\n",
      "    time     (sample) datetime64[ns] 22kB 1979-06-02T18:00:00 ... 2023-10-27T...\n",
      "  * sample   (sample) int64 22kB 1 1 1 1 1 1 1 1 1 1 1 ... 1 1 1 1 1 1 1 1 1 1 1\n",
      "Dimensions without coordinates: latitude, longitude\n",
      "Data variables:\n",
      "    CAPE     (sample, latitude, longitude) float32 11MB dask.array<chunksize=(1, 32, 32), meta=np.ndarray>\n",
      "    label    (sample) float64 22kB 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0\n",
      "Attributes:\n",
      "    DATA_SOURCE:          ECMWF: https://cds.climate.copernicus.eu, Copernicu...\n",
      "    NETCDF_CONVERSION:    CISL RDA: Conversion from ECMWF GRIB1 data to netCDF4.\n",
      "    NETCDF_VERSION:       4.6.1\n",
      "    CONVERSION_PLATFORM:  Linux r2i5n6 3.12.62-60.64.8-default #1 SMP Tue Oct...\n",
      "    CONVERSION_DATE:      Thu May 16 09:28:20 MDT 2019\n",
      "    Conventions:          CF-1.6\n",
      "    NETCDF_COMPRESSION:   NCO: Precision-preserving compression to netCDF4/HD...\n",
      "    history:              Thu May 16 09:28:35 2019: ncks -4 --ppc default=7 e...\n",
      "    NCO:                  netCDF Operators version 4.7.4 (http://nco.sf.net)\n",
      "Dataset: crr\n",
      "<xarray.Dataset> Size: 11MB\n",
      "Dimensions:                (sample: 2750, latitude: 32, longitude: 32)\n",
      "Coordinates:\n",
      "    forecast_hour          (sample) int32 11kB 12 6 6 12 6 12 ... 12 12 12 12 6\n",
      "    forecast_initial_time  (sample) datetime64[ns] 22kB 1979-06-02T06:00:00 ....\n",
      "  * sample                 (sample) int64 22kB 1 1 1 1 1 1 1 1 ... 1 1 1 1 1 1 1\n",
      "Dimensions without coordinates: latitude, longitude\n",
      "Data variables:\n",
      "    CRR                    (sample, latitude, longitude) float32 11MB dask.array<chunksize=(1, 32, 32), meta=np.ndarray>\n",
      "    label                  (sample) float64 22kB 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0\n",
      "Attributes:\n",
      "    DATA_SOURCE:          ECMWF: https://cds.climate.copernicus.eu, Copernicu...\n",
      "    NETCDF_CONVERSION:    CISL RDA: Conversion from ECMWF GRIB1 data to netCDF4.\n",
      "    NETCDF_VERSION:       4.6.1\n",
      "    CONVERSION_PLATFORM:  Linux r11i4n26 3.12.62-60.64.8-default #1 SMP Tue O...\n",
      "    CONVERSION_DATE:      Thu May 16 08:59:19 MDT 2019\n",
      "    Conventions:          CF-1.6\n",
      "    NETCDF_COMPRESSION:   NCO: Precision-preserving compression to netCDF4/HD...\n",
      "    history:              Thu May 16 08:59:26 2019: ncks -4 --ppc default=7 e...\n",
      "    NCO:                  netCDF Operators version 4.7.4 (http://nco.sf.net)\n",
      "Dataset: ie\n",
      "<xarray.Dataset> Size: 11MB\n",
      "Dimensions:  (sample: 2750, latitude: 32, longitude: 32)\n",
      "Coordinates:\n",
      "    time     (sample) datetime64[ns] 22kB 1979-06-02T18:00:00 ... 2023-10-27T...\n",
      "  * sample   (sample) int64 22kB 1 1 1 1 1 1 1 1 1 1 1 ... 1 1 1 1 1 1 1 1 1 1 1\n",
      "Dimensions without coordinates: latitude, longitude\n",
      "Data variables:\n",
      "    IE       (sample, latitude, longitude) float32 11MB dask.array<chunksize=(1, 32, 32), meta=np.ndarray>\n",
      "    label    (sample) float64 22kB 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0\n",
      "Attributes:\n",
      "    DATA_SOURCE:          ECMWF: https://cds.climate.copernicus.eu, Copernicu...\n",
      "    NETCDF_CONVERSION:    CISL RDA: Conversion from ECMWF GRIB1 data to netCDF4.\n",
      "    NETCDF_VERSION:       4.6.1\n",
      "    CONVERSION_PLATFORM:  Linux r2i5n6 3.12.62-60.64.8-default #1 SMP Tue Oct...\n",
      "    CONVERSION_DATE:      Thu May 16 10:49:01 MDT 2019\n",
      "    Conventions:          CF-1.6\n",
      "    NETCDF_COMPRESSION:   NCO: Precision-preserving compression to netCDF4/HD...\n",
      "    history:              Thu May 16 10:49:16 2019: ncks -4 --ppc default=7 e...\n",
      "    NCO:                  netCDF Operators version 4.7.4 (http://nco.sf.net)\n",
      "Dataset: ishf\n",
      "<xarray.Dataset> Size: 11MB\n",
      "Dimensions:  (sample: 2750, latitude: 32, longitude: 32)\n",
      "Coordinates:\n",
      "    time     (sample) datetime64[ns] 22kB 1979-06-02T18:00:00 ... 2023-10-27T...\n",
      "  * sample   (sample) int64 22kB 1 1 1 1 1 1 1 1 1 1 1 ... 1 1 1 1 1 1 1 1 1 1 1\n",
      "Dimensions without coordinates: latitude, longitude\n",
      "Data variables:\n",
      "    ISHF     (sample, latitude, longitude) float32 11MB dask.array<chunksize=(1, 32, 32), meta=np.ndarray>\n",
      "    label    (sample) float64 22kB 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0\n",
      "Attributes:\n",
      "    DATA_SOURCE:          ECMWF: https://cds.climate.copernicus.eu, Copernicu...\n",
      "    NETCDF_CONVERSION:    CISL RDA: Conversion from ECMWF GRIB1 data to netCDF4.\n",
      "    NETCDF_VERSION:       4.6.1\n",
      "    CONVERSION_PLATFORM:  Linux r2i5n6 3.12.62-60.64.8-default #1 SMP Tue Oct...\n",
      "    CONVERSION_DATE:      Thu May 16 10:46:01 MDT 2019\n",
      "    Conventions:          CF-1.6\n",
      "    NETCDF_COMPRESSION:   NCO: Precision-preserving compression to netCDF4/HD...\n",
      "    history:              Thu May 16 10:46:15 2019: ncks -4 --ppc default=7 e...\n",
      "    NCO:                  netCDF Operators version 4.7.4 (http://nco.sf.net)\n",
      "Dataset: lsrr\n",
      "<xarray.Dataset> Size: 11MB\n",
      "Dimensions:                (sample: 2750, latitude: 32, longitude: 32)\n",
      "Coordinates:\n",
      "    forecast_hour          (sample) int32 11kB 12 6 6 12 6 12 ... 12 12 12 12 6\n",
      "    forecast_initial_time  (sample) datetime64[ns] 22kB 1979-06-02T06:00:00 ....\n",
      "  * sample                 (sample) int64 22kB 1 1 1 1 1 1 1 1 ... 1 1 1 1 1 1 1\n",
      "Dimensions without coordinates: latitude, longitude\n",
      "Data variables:\n",
      "    LSRR                   (sample, latitude, longitude) float32 11MB dask.array<chunksize=(1, 32, 32), meta=np.ndarray>\n",
      "    label                  (sample) float64 22kB 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0\n",
      "Attributes:\n",
      "    DATA_SOURCE:          ECMWF: https://cds.climate.copernicus.eu, Copernicu...\n",
      "    NETCDF_CONVERSION:    CISL RDA: Conversion from ECMWF GRIB1 data to netCDF4.\n",
      "    NETCDF_VERSION:       4.6.1\n",
      "    CONVERSION_PLATFORM:  Linux r11i4n26 3.12.62-60.64.8-default #1 SMP Tue O...\n",
      "    CONVERSION_DATE:      Thu May 16 09:00:03 MDT 2019\n",
      "    Conventions:          CF-1.6\n",
      "    NETCDF_COMPRESSION:   NCO: Precision-preserving compression to netCDF4/HD...\n",
      "    history:              Thu May 16 09:00:10 2019: ncks -4 --ppc default=7 e...\n",
      "    NCO:                  netCDF Operators version 4.7.4 (http://nco.sf.net)\n",
      "Dataset: sp\n",
      "<xarray.Dataset> Size: 11MB\n",
      "Dimensions:  (sample: 2750, latitude: 32, longitude: 32)\n",
      "Coordinates:\n",
      "    time     (sample) datetime64[ns] 22kB 1979-06-02T18:00:00 ... 2023-10-27T...\n",
      "  * sample   (sample) int64 22kB 1 1 1 1 1 1 1 1 1 1 1 ... 1 1 1 1 1 1 1 1 1 1 1\n",
      "Dimensions without coordinates: latitude, longitude\n",
      "Data variables:\n",
      "    SP       (sample, latitude, longitude) float32 11MB dask.array<chunksize=(1, 32, 32), meta=np.ndarray>\n",
      "    label    (sample) float64 22kB 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0\n",
      "Attributes:\n",
      "    DATA_SOURCE:          ECMWF: https://cds.climate.copernicus.eu, Copernicu...\n",
      "    NETCDF_CONVERSION:    CISL RDA: Conversion from ECMWF GRIB1 data to netCDF4.\n",
      "    NETCDF_VERSION:       4.6.1\n",
      "    CONVERSION_PLATFORM:  Linux r2i5n6 3.12.62-60.64.8-default #1 SMP Tue Oct...\n",
      "    CONVERSION_DATE:      Thu May 16 09:48:45 MDT 2019\n",
      "    Conventions:          CF-1.6\n",
      "    NETCDF_COMPRESSION:   NCO: Precision-preserving compression to netCDF4/HD...\n",
      "    history:              Thu May 16 09:49:00 2019: ncks -4 --ppc default=7 e...\n",
      "    NCO:                  netCDF Operators version 4.7.4 (http://nco.sf.net)\n",
      "Dataset: sstk\n",
      "<xarray.Dataset> Size: 11MB\n",
      "Dimensions:  (sample: 2750, latitude: 32, longitude: 32)\n",
      "Coordinates:\n",
      "    time     (sample) datetime64[ns] 22kB 1979-06-02T18:00:00 ... 2023-10-27T...\n",
      "  * sample   (sample) int64 22kB 1 1 1 1 1 1 1 1 1 1 1 ... 1 1 1 1 1 1 1 1 1 1 1\n",
      "Dimensions without coordinates: latitude, longitude\n",
      "Data variables:\n",
      "    SSTK     (sample, latitude, longitude) float32 11MB dask.array<chunksize=(1, 32, 32), meta=np.ndarray>\n",
      "    label    (sample) float64 22kB 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0\n",
      "Attributes:\n",
      "    DATA_SOURCE:          ECMWF: https://cds.climate.copernicus.eu, Copernicu...\n",
      "    NETCDF_CONVERSION:    CISL RDA: Conversion from ECMWF GRIB1 data to netCDF4.\n",
      "    NETCDF_VERSION:       4.6.1\n",
      "    CONVERSION_PLATFORM:  Linux r2i5n6 3.12.62-60.64.8-default #1 SMP Tue Oct...\n",
      "    CONVERSION_DATE:      Thu May 16 09:13:19 MDT 2019\n",
      "    Conventions:          CF-1.6\n",
      "    NETCDF_COMPRESSION:   NCO: Precision-preserving compression to netCDF4/HD...\n",
      "    history:              Thu May 16 09:13:34 2019: ncks -4 --ppc default=7 e...\n",
      "    NCO:                  netCDF Operators version 4.7.4 (http://nco.sf.net)\n",
      "Dataset: tcw\n",
      "<xarray.Dataset> Size: 11MB\n",
      "Dimensions:  (sample: 2750, latitude: 32, longitude: 32)\n",
      "Coordinates:\n",
      "    time     (sample) datetime64[ns] 22kB 1979-06-02T18:00:00 ... 2023-10-27T...\n",
      "  * sample   (sample) int64 22kB 1 1 1 1 1 1 1 1 1 1 1 ... 1 1 1 1 1 1 1 1 1 1 1\n",
      "Dimensions without coordinates: latitude, longitude\n",
      "Data variables:\n",
      "    TCW      (sample, latitude, longitude) float32 11MB dask.array<chunksize=(1, 32, 32), meta=np.ndarray>\n",
      "    label    (sample) float64 22kB 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0\n",
      "Attributes:\n",
      "    DATA_SOURCE:          ECMWF: https://cds.climate.copernicus.eu, Copernicu...\n",
      "    NETCDF_CONVERSION:    CISL RDA: Conversion from ECMWF GRIB1 data to netCDF4.\n",
      "    NETCDF_VERSION:       4.6.1\n",
      "    CONVERSION_PLATFORM:  Linux r2i5n6 3.12.62-60.64.8-default #1 SMP Tue Oct...\n",
      "    CONVERSION_DATE:      Thu May 16 09:51:26 MDT 2019\n",
      "    Conventions:          CF-1.6\n",
      "    NETCDF_COMPRESSION:   NCO: Precision-preserving compression to netCDF4/HD...\n",
      "    history:              Thu May 16 09:51:40 2019: ncks -4 --ppc default=7 e...\n",
      "    NCO:                  netCDF Operators version 4.7.4 (http://nco.sf.net)\n",
      "Dataset: tcwv\n",
      "<xarray.Dataset> Size: 11MB\n",
      "Dimensions:  (sample: 2750, latitude: 32, longitude: 32)\n",
      "Coordinates:\n",
      "    time     (sample) datetime64[ns] 22kB 1979-06-02T18:00:00 ... 2023-10-27T...\n",
      "  * sample   (sample) int64 22kB 1 1 1 1 1 1 1 1 1 1 1 ... 1 1 1 1 1 1 1 1 1 1 1\n",
      "Dimensions without coordinates: latitude, longitude\n",
      "Data variables:\n",
      "    TCWV     (sample, latitude, longitude) float32 11MB dask.array<chunksize=(1, 32, 32), meta=np.ndarray>\n",
      "    label    (sample) float64 22kB 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0\n",
      "Attributes:\n",
      "    DATA_SOURCE:          ECMWF: https://cds.climate.copernicus.eu, Copernicu...\n",
      "    NETCDF_CONVERSION:    CISL RDA: Conversion from ECMWF GRIB1 data to netCDF4.\n",
      "    NETCDF_VERSION:       4.6.1\n",
      "    CONVERSION_PLATFORM:  Linux r2i5n6 3.12.62-60.64.8-default #1 SMP Tue Oct...\n",
      "    CONVERSION_DATE:      Thu May 16 09:54:13 MDT 2019\n",
      "    Conventions:          CF-1.6\n",
      "    NETCDF_COMPRESSION:   NCO: Precision-preserving compression to netCDF4/HD...\n",
      "    history:              Thu May 16 09:54:28 2019: ncks -4 --ppc default=7 e...\n",
      "    NCO:                  netCDF Operators version 4.7.4 (http://nco.sf.net)\n",
      "Dataset: ttr\n",
      "<xarray.Dataset> Size: 11MB\n",
      "Dimensions:                (sample: 2750, latitude: 32, longitude: 32)\n",
      "Coordinates:\n",
      "    forecast_hour          (sample) int32 11kB 12 6 6 12 6 12 ... 12 12 12 12 6\n",
      "    forecast_initial_time  (sample) datetime64[ns] 22kB 1979-06-02T06:00:00 ....\n",
      "  * sample                 (sample) int64 22kB 1 1 1 1 1 1 1 1 ... 1 1 1 1 1 1 1\n",
      "Dimensions without coordinates: latitude, longitude\n",
      "Data variables:\n",
      "    TTR                    (sample, latitude, longitude) float32 11MB dask.array<chunksize=(1, 32, 32), meta=np.ndarray>\n",
      "    label                  (sample) float64 22kB 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0\n",
      "Attributes:\n",
      "    DATA_SOURCE:          ECMWF: https://cds.climate.copernicus.eu, Copernicu...\n",
      "    NETCDF_CONVERSION:    CISL RDA: Conversion from ECMWF GRIB1 data to netCDF4.\n",
      "    NETCDF_VERSION:       4.6.1\n",
      "    CONVERSION_PLATFORM:  Linux r11i1n35 3.12.62-60.64.8-default #1 SMP Tue O...\n",
      "    CONVERSION_DATE:      Thu May 16 09:00:24 MDT 2019\n",
      "    Conventions:          CF-1.6\n",
      "    NETCDF_COMPRESSION:   NCO: Precision-preserving compression to netCDF4/HD...\n",
      "    history:              Thu May 16 09:00:30 2019: ncks -4 --ppc default=7 e...\n",
      "    NCO:                  netCDF Operators version 4.7.4 (http://nco.sf.net)\n"
     ]
    }
   ],
   "source": [
    "for var_name, dataset in datas.items():\n",
    "    print(f\"Dataset: {var_name}\")\n",
    "    print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92291f0-5ae2-4e45-b780-bdf7ab0cf2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of possible temporal coordinates\n",
    "temporal_coords = ['time', 'forecast_initial_time', 'forecast_hour']\n",
    "\n",
    "# Open the datasets\n",
    "datas = open_files(\n",
    "    list_of_vars=var_list,\n",
    "    aew_subset=aew_subset,\n",
    "    directory=\"/glade/derecho/scratch/rmandava/AEW_time_location_files/\",\n",
    "    plevel_list=plevel_list\n",
    ")\n",
    "\n",
    "# Combine the datasets into a single DataFrame\n",
    "combined_data = pd.DataFrame()\n",
    "\n",
    "for var_name, dataset in datas.items():\n",
    "    # Identify the available temporal coordinate\n",
    "    temporal_var = None\n",
    "    for coord in temporal_coords:\n",
    "        if coord in dataset.coords:\n",
    "            temporal_var = coord\n",
    "            break\n",
    "    \n",
    "    if temporal_var is None:\n",
    "        raise KeyError(f\"No recognized temporal coordinate found in the dataset '{var_name}'.\")\n",
    "\n",
    "    # Rename the temporal coordinate to 'time' for consistency\n",
    "    dataset = dataset.rename({temporal_var: 'time'})\n",
    "\n",
    "    # Convert the dataset to a DataFrame\n",
    "    df = dataset.to_dataframe().reset_index()\n",
    "\n",
    "    # Merge the DataFrames\n",
    "    if combined_data.empty:\n",
    "        combined_data = df\n",
    "    else:\n",
    "        combined_data = pd.merge(combined_data, df, on=['sample', 'time'], how='outer')\n",
    "\n",
    "# Save the combined DataFrame to a CSV file\n",
    "combined_data.to_csv('combined_data.csv', index=False)\n",
    "\n",
    "print(\"Data has been successfully converted to CSV.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e26dfb-0623-4c1b-8197-8fa09f056d08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
